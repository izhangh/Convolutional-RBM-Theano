{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional RBM on the GPU (cRBM)\n",
    "In this notebook, a general implementation of the convolutional Restricted Boltzmann Machine is given.\n",
    "The code focusses on speed on GPUs (graphics cards) and therefore, the relevant parts are written in Theano.\n",
    "\n",
    "The first parts of the notebook provide methods to read in the DNA sequences while the actual training algorithm is given in section 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Importing all relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.0: cannot open shared object file: No such file or directory\n",
      "ERROR:theano.sandbox.cuda:Failed to compile cuda_ndarray.cu: libcublas.so.7.0: cannot open shared object file: No such file or directory\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n",
      "WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Theano imports\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet.conv as conv\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RS\n",
    "from theano import pp\n",
    "\n",
    "# numpy and python classics\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# biopython stuff\n",
    "import Bio.SeqIO as sio\n",
    "import Bio.motifs.matrix as mat\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading the data and converting it to various forms of matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes to read biological files (such as FASTA or JASPAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This class reads sequences from fasta files.\n",
    "To use it, create an instance of that object and use\n",
    "the function readSequencesFromFile.\n",
    "\"\"\"\n",
    "class FASTAReader:\n",
    "    \n",
    "    def __init__(self, _path):\n",
    "        self.path = _path\n",
    "        \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        dhsSequences = []\n",
    "        for dhs in sio.parse(open(filename), 'fasta', IUPAC.unambiguous_dna):\n",
    "            dhsSequences.append(dhs.seq)\n",
    "        return dhsSequences\n",
    "    \n",
    "    \n",
    "class JASPARReader:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        pass\n",
    "    \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        matrices = []\n",
    "        for mat in motifs.parse(open(filename), 'jaspar'):\n",
    "            matrices.append(mat.pwm)\n",
    "        return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading that information to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matReader = JASPARReader()\n",
    "pwms = matReader.readSequencesFromFile('data/jaspar_matrices.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply the two classes to calculate a forward pass in our algorithm\n",
    "seqReader = FASTAReader('.')\n",
    "allSeqs = seqReader.readSequencesFromFile('data/wgEncodeAwgDnaseUwAg10803UniPk.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the DNA sequences to matrices\n",
    "Each DNA sequence is transformed into a 4 x seqLength dimensional matrix. That way, each row represents one of the four letters in the genomic alphabet and in every column, exactly one of the four equals one, while the rest is set to zero.\n",
    "\n",
    "\n",
    "\n",
    "#### So, the sequence **ACGTGGGG** would look like this:\n",
    "| Letter | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n",
    "|--|------------------------------|\n",
    "| A | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| C | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| G | 0 | 0 | 1 | 0 | 1 | 1 | 1 | 1 |\n",
    "| T | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getIntToLetter (letter):\n",
    "    if letter == 'A' or letter == 'a':\n",
    "        return 0\n",
    "    elif letter == 'C' or letter == 'c':\n",
    "        return 1\n",
    "    elif letter == 'G' or letter == 'g':\n",
    "        return 2\n",
    "    elif letter == 'T' or letter == 't':\n",
    "        return 3\n",
    "    else:\n",
    "        print \"ERROR. LETTER \" + letter + \" DOES NOT EXIST!\"\n",
    "        return -1\n",
    "\n",
    "def getMatrixFromSeq (seq):\n",
    "    m = len(seq.alphabet.letters)\n",
    "    n = len(seq)\n",
    "    result = np.zeros((1, m, n), dtype=np.float32)\n",
    "    revSeq = seq.reverse_complement()\n",
    "    for i in range(len(seq)):\n",
    "        result[0,getIntToLetter(seq[i]),i] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 15000\n",
      "Test set size: 5000\n",
      "Conversion of test set in (in ms): 2966.04704857\n"
     ]
    }
   ],
   "source": [
    "data = [allSeqs[random.randrange(0,len(allSeqs))] for i in range(20000)]\n",
    "train_set, test_set = train_test_split(data, test_size=0.25)\n",
    "print \"Training set size: \" + str(len(train_set))\n",
    "print \"Test set size: \" + str(len(test_set))\n",
    "\n",
    "start = time.time()\n",
    "trainingData = np.array([getMatrixFromSeq(t) for t in train_set])\n",
    "testingData = np.array([getMatrixFromSeq(t) for t in test_set])\n",
    "print \"Conversion of test set in (in ms): \" + str((time.time()-start)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Borrowing Ian Goodfellow's implementation of the probabilistic max pooling layer\n",
    "This implementation is now part of the pylearn2 library which is licensed under the 3-claused BSD license.\n",
    "Source code is available here: https://github.com/lisa-lab/pylearn2/blob/master/pylearn2/expr/probabilistic_max_pooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from theano.gof.op import get_debug_values\n",
    "\n",
    "def max_pool(z, pool_shape, top_down=None, theano_rng=None):\n",
    "    \"\"\"\n",
    "    Probabilistic max-pooling\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : theano 4-tensor\n",
    "        a theano 4-tensor representing input from below\n",
    "    pool_shape : tuple\n",
    "        tuple of ints. the shape of regions to be pooled\n",
    "    top_down : theano 4-tensor, optional\n",
    "        a theano 4-tensor representing input from above\n",
    "        if None, assumes top-down input is 0\n",
    "    theano_rng : MRG_RandomStreams, optional\n",
    "        Used for random numbers for sampling\n",
    "    Returns\n",
    "    -------\n",
    "    p : theano 4-tensor\n",
    "        the expected value of the pooling layer p\n",
    "    h : theano 4-tensor\n",
    "        the expected value of the detector layer h\n",
    "    p_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the pooling layer\n",
    "    h_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the detector layer\n",
    "    Notes\n",
    "    ------\n",
    "    all 4-tensors are formatted with axes ('b', 'c', 0, 1).\n",
    "    This is for maximum speed when using theano's conv2d\n",
    "    to generate z and top_down, or when using it to infer conditionals of\n",
    "    other layers using the return values.\n",
    "    Detailed description:\n",
    "    Suppose you have a variable h that lives in a Conv2DSpace h_space and\n",
    "    you want to pool it down to a variable p that lives in a smaller\n",
    "    Conv2DSpace p.\n",
    "    This function does that, using non-overlapping pools.\n",
    "    Specifically, consider one channel of h. h must have a height that is a\n",
    "    multiple of pool_shape[0] and a width that is a multiple of pool_shape[1].\n",
    "    A channel of h can thus be broken down into non-overlapping rectangles\n",
    "    of shape pool_shape.\n",
    "    Now consider one rectangular pooled region within one channel of h.\n",
    "    I now use 'h' to refer just to this rectangle, and 'p' to refer to\n",
    "    just the one pooling unit associated with that rectangle.\n",
    "    We assume that the space that h and p live in is constrained such\n",
    "    that h and p are both binary and p = max(h). To reduce the state-space\n",
    "    in order to make probabilistic computations cheaper we also\n",
    "    constrain sum(h) <= 1.\n",
    "    Suppose h contains k different units. Suppose that the only term\n",
    "    in the model's energy function involving h is -(z*h).sum()\n",
    "    (elemwise multiplication) and the only term in\n",
    "    the model's energy function involving p is -(top_down*p).sum().\n",
    "    Then P(h[i] = 1) = softmax( [ z[1], z[2], ..., z[k], -top_down] )[i]\n",
    "    and P(p = 1) = 1-softmax( [z[1], z[2], ..., z[k], -top_down])[k]\n",
    "    This variation of the function assumes that z, top_down, and all\n",
    "    return values use Conv2D axes ('b', 'c', 0, 1).\n",
    "    This variation of the function implements the softmax using a\n",
    "    theano graph of exp, maximum, sub, and div operations.\n",
    "    \"\"\"\n",
    "\n",
    "    z_name = z.name\n",
    "    if z_name is None:\n",
    "        z_name = 'anon_z'\n",
    "\n",
    "    batch_size, ch, zr, zc = z.shape\n",
    "\n",
    "    r, c = pool_shape\n",
    "\n",
    "    zpart = []\n",
    "\n",
    "    mx = None\n",
    "\n",
    "    if top_down is None:\n",
    "        t = 0.\n",
    "    else:\n",
    "        t = - top_down\n",
    "        t.name = 'neg_top_down'\n",
    "\n",
    "    for i in xrange(r):\n",
    "        zpart.append([])\n",
    "        for j in xrange(c):\n",
    "            cur_part = z[:, :, i:zr:r, j:zc:c]\n",
    "            if z_name is not None:\n",
    "                cur_part.name = z_name + '[%d,%d]' % (i, j)\n",
    "            zpart[i].append(cur_part)\n",
    "            if mx is None:\n",
    "                mx = T.maximum(t, cur_part)\n",
    "                if cur_part.name is not None:\n",
    "                    mx.name = 'max(-top_down,' + cur_part.name + ')'\n",
    "            else:\n",
    "                max_name = None\n",
    "                if cur_part.name is not None:\n",
    "                    mx_name = 'max(' + cur_part.name + ',' + mx.name + ')'\n",
    "                mx = T.maximum(mx, cur_part)\n",
    "                mx.name = mx_name\n",
    "    mx.name = 'local_max(' + z_name + ')'\n",
    "\n",
    "    pt = []\n",
    "\n",
    "    for i in xrange(r):\n",
    "        pt.append([])\n",
    "        for j in xrange(c):\n",
    "            z_ij = zpart[i][j]\n",
    "            safe = z_ij - mx\n",
    "            safe.name = 'safe_z(%s)' % z_ij.name\n",
    "            cur_pt = T.exp(safe)\n",
    "            cur_pt.name = 'pt(%s)' % z_ij.name\n",
    "            pt[-1].append(cur_pt)\n",
    "\n",
    "    off_pt = T.exp(t - mx)\n",
    "    off_pt.name = 'p_tilde_off(%s)' % z_name\n",
    "    denom = off_pt\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            denom = denom + pt[i][j]\n",
    "    denom.name = 'denom(%s)' % z_name\n",
    "\n",
    "    off_prob = off_pt / denom\n",
    "    p = 1. - off_prob\n",
    "    p.name = 'p(%s)' % z_name\n",
    "\n",
    "    hpart = []\n",
    "    for i in xrange(r):\n",
    "        hpart.append([pt_ij / denom for pt_ij in pt[i]])\n",
    "\n",
    "    h = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            h.name = 'h_interm'\n",
    "            h = T.set_subtensor(h[:, :, i:zr:r, j:zc:c], hpart[i][j])\n",
    "\n",
    "    h.name = 'h(%s)' % z_name\n",
    "\n",
    "    if theano_rng is None:\n",
    "        return p, h\n",
    "    \n",
    "    ### --------------------- DONE IF NO SAMPLES ARE GENERATED ---------------------------###\n",
    "    else:\n",
    "        events = []\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                events.append(hpart[i][j])\n",
    "        events.append(off_prob)\n",
    "\n",
    "        events = [event.dimshuffle(0, 1, 2, 3, 'x') for event in events]\n",
    "\n",
    "        events = tuple(events)\n",
    "\n",
    "        stacked_events = T.concatenate(events, axis=4)\n",
    "\n",
    "        rows = zr // pool_shape[0]\n",
    "        cols = zc // pool_shape[1]\n",
    "        outcomes = pool_shape[0] * pool_shape[1] + 1\n",
    "        assert stacked_events.ndim == 5\n",
    "        for se, bs, r, c, chv in get_debug_values(stacked_events, batch_size,\n",
    "                                                  rows, cols, ch):\n",
    "            assert se.shape[0] == bs\n",
    "            assert se.shape[1] == r\n",
    "            assert se.shape[2] == c\n",
    "            assert se.shape[3] == chv\n",
    "            assert se.shape[4] == outcomes\n",
    "        reshaped_events = stacked_events.reshape((\n",
    "            batch_size * rows * cols * ch, outcomes))\n",
    "\n",
    "        multinomial = theano_rng.multinomial(pvals=reshaped_events,\n",
    "                                             dtype=p.dtype)\n",
    "\n",
    "        reshaped_multinomial = multinomial.reshape((batch_size, ch, rows,\n",
    "                                                    cols, outcomes))\n",
    "\n",
    "        h_sample = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "        idx = 0\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                h_sample = T.set_subtensor(h_sample[:, :, i:zr:r, j:zc:c],\n",
    "                                           reshaped_multinomial[:, :, :, :,\n",
    "                                           idx])\n",
    "                idx += 1\n",
    "\n",
    "        p_sample = 1 - reshaped_multinomial[:, :, :, :, -1]\n",
    "\n",
    "        return p, h, p_sample, h_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: The implementation of a convolutional RBM on the GPU\n",
    "And finally, here it is. A class that lets us train a cRBM on the GPU.\n",
    "The algorithm should feature various variantes of the classical learning algorithms such as:\n",
    "\n",
    "* Persistent Contrastive Divergence\n",
    "* Dropout to enforce sparsity\n",
    "* **Probabilistic Max-Pooling units in the hidden layer**\n",
    "* Regularization\n",
    "* Stochastic Gradient Descent with momentum & Simulated Annealing\n",
    "\n",
    "However, only the procedures printed in **bold** are allready functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PART 3: Optimizing theano to do it all on the GPU\n",
    "\n",
    "\"\"\"\n",
    "This is the actual implementation of our convolutional RBM.\n",
    "The class implements only contrastive divergence learning so far\n",
    "but the number of runs for Gibbs Sampling can be varied.\n",
    "Furthermore, the beforementioned implementation of probabilistic max pooling\n",
    "computes probabilities for and samples of the hidden layer distribution.\n",
    "\"\"\"\n",
    "class CRBM:\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize the cRBM. The parameters here are global params that should not change\n",
    "    during the execution of training or testing and characterize the network.\n",
    "    \n",
    "    Parameters:\n",
    "    _motifLength:    How long are the motifs (position weight matrices PWM). This\n",
    "                     This is equivalent to ask what the number of k-mers is.\n",
    "                     The current approach only deals with one fixed motif length.\n",
    "                     \n",
    "    _numMotifs:      How many motifs are applied to the sequence, that is how many\n",
    "                     hidden units does the network have. Each hidden unit consists\n",
    "                     of a vector of size (sequenceLength-motifLength+1)\n",
    "                     \n",
    "    _poolingFactor:  How many units from the hidden layer are pooled together.\n",
    "                     Note that the number has to divide evenly to the length of\n",
    "                     the hidden units, that is:\n",
    "                     mod(sequenceLength-motifLength+1, poolingFactor) == 0\n",
    "                     (1 = equivalent to sigmoid activation)\n",
    "    \"\"\"\n",
    "    def __init__ (self, _motifLength, _numMotifs, _learningRate=0.1, _poolingFactor=1, _alphabet=IUPAC.unambiguous_dna):\n",
    "        # parameters for the motifs\n",
    "        self.motifLength = _motifLength\n",
    "        self.numMotifs = _numMotifs\n",
    "        self.alphabet = _alphabet\n",
    "        self.initializeMotifs()\n",
    "        \n",
    "        # cRBM parameters (2*x to respect both strands of the DNA)\n",
    "        b = np.random.rand(1, 2*self.numMotifs).astype(np.float32)\n",
    "        c = np.random.rand(1, 4).astype(np.float32)\n",
    "        self.bias = theano.shared(value=b, name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=c, name='c', borrow=True)\n",
    "        self.poolingFactor = _poolingFactor\n",
    "        self.learningRate = _learningRate\n",
    "        \n",
    "        # infrastructural parameters\n",
    "        self.theano_rng = RS(seed=1234)\n",
    "        self.params = [self.motifs, self.bias, self.c]\n",
    "        self.debug = True\n",
    "    \n",
    "    \n",
    "    def initializeMotifs (self):\n",
    "        # create random motifs (2*self.numMotifs to respect both strands)\n",
    "        x = np.random.rand(2 * self.numMotifs, 1, 4, self.motifLength).astype(np.float32)\n",
    "        \n",
    "        # create reverse complement\n",
    "        for i in range(0, 2*self.numMotifs, 2):\n",
    "            print \"setting i: \" + str(i) + \" i+1: \" + str(i+1)\n",
    "            x[i+1] = x[i,:,::-1,::-1]\n",
    "            \n",
    "        self.motifs = theano.shared(value=x, name='W', borrow=True)\n",
    "        \n",
    "        \n",
    "    def setCustomKernels (self, customKernels):\n",
    "        if len(customKernels.shape) != 4 or customKernels.shape[1] != 1:\n",
    "            print \"New motifs must be a 4D matrix with dims: (K x 1 x numOfLetters(4) x numOfKMers)\"\n",
    "            return\n",
    "        \n",
    "        self.numMotifs = customKernels.shape[0]\n",
    "        self.motifLength = customKernels.shape[3]\n",
    "        #b = np.random.rand(1, self.numMotifs).astype(np.float32)\n",
    "        \n",
    "        if self.debug:\n",
    "            b = np.zeros((1, self.numMotifs)).astype(np.float32)\n",
    "            c = np.zeros((1, 4)).astype(np.float32)\n",
    "        else:\n",
    "            b = np.random.rand(1, self.numMotifs).astype(np.float32)\n",
    "            c = np.random.rand(1, 4).astype(np.float32)\n",
    "\n",
    "        self.bias = theano.shared(value=b, name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=c, name='c', borrow=True)\n",
    "        \n",
    "        self.motifs = theano.shared(value=customKernels.astype(np.float32))\n",
    "        self.params = [self.motifs, self.bias, self.c]\n",
    "        print \"New motifs set. # Motifs: \" + str(self.numMotifs) + \" K-mer-Length: \" + str(self.motifLength)\n",
    "\n",
    "        \n",
    "### ------------------------------THE TOUGH STUFF-------------------------------- ###\n",
    "### ----------------------------------------------------------------------------- ###\n",
    "\n",
    "    def forwardBatch (self, data):\n",
    "        out = conv.conv2d(data, self.motifs[:,:,::-1,::-1])\n",
    "        if self.debug:\n",
    "            out = theano.printing.Print('Convolution result forward: ')(out)\n",
    "        bMod = self.bias\n",
    "        bMod = bMod.dimshuffle('x', 1, 0, 'x') # add dims to the bias until it works\n",
    "        out = out + bMod\n",
    "        pooled = max_pool(out.dimshuffle(0,2,1,3), pool_shape=(2, self.poolingFactor), theano_rng=self.theano_rng)\n",
    "        H = pooled[1]\n",
    "        S = pooled[3]\n",
    "        if self.debug:\n",
    "            H = theano.printing.Print('Hidden Probabilites: ')(H)\n",
    "            S = theano.printing.Print('prob max pooled layer: ')(S)\n",
    "        return [H,S] #only return pooled layer and probs\n",
    "\n",
    "\n",
    "    def backwardBatch (self, H_sample):\n",
    "        K = self.motifs.dimshuffle(1, 0, 2, 3)[:,:,::-1,::-1] # kernel is flipped prior to convolution\n",
    "        H_shuffled = H_sample.dimshuffle(0, 2, 1, 3) # interpret the kernels as channels (will be summed automatically)\n",
    "        C = conv.conv2d(H_shuffled, K, border_mode='full')[:,:,::-1,:]\n",
    "        if self.debug:\n",
    "            C = theano.printing.Print('Pre sigmoid visible layer: ')(C)\n",
    "        out = T.sum(C, axis=1, keepdims=True) # sum over all K\n",
    "        c_bc = self.c\n",
    "        c_bc = c_bc.dimshuffle('x', 0, 1, 'x')\n",
    "        out = out + c_bc\n",
    "        res = self.softmax(out)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def expectedDerivative (self, hiddenProbs, data):\n",
    "        mean = T.mean(hiddenProbs, axis=0, keepdims=True) # sum over all training data to get avg (but keep dim)\n",
    "        p = theano.printing.Print('Shape of mean: ')(mean.shape)\n",
    "        H_reshaped = mean.dimshuffle(2, 0, 1, 3)\n",
    "        # TODO: Capture the 1 <-> 1 relation between samples in H and D\n",
    "        # Currently, this is done by mean (1st row) but that's not good at all\n",
    "        out = conv.conv2d(data, H_reshaped)\n",
    "        # TODO: perform scan here and sum even ones while setting unevens to 0.\n",
    "        # TODO: Don't mean over all then, but use sum and divide by K (not 2*K like in this case)\n",
    "        der_Motifs = T.mean(out, axis=0, keepdims=True) # mean over training examples\n",
    "        der_Motifs = der_Motifs.dimshuffle(1, 0, 2, 3) # bring back to former shape\n",
    "        der_bias = T.mean(T.sum(hiddenProbs, axis=3), axis=0)\n",
    "        der_c = T.mean(T.sum(data, axis=3), axis=0)\n",
    "        return (der_Motifs, der_bias, der_c, p)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def getTrainingFunction (self, numOfCDs):\n",
    "        D = T.tensor4('data')\n",
    "        # calculate the data gradient for weights (motifs) and bias\n",
    "        [H_data, S_data] = self.forwardBatch(D)\n",
    "        if self.debug:\n",
    "            H_data = theano.printing.Print('Hidden Layer Probabilities: ')(H_data)\n",
    "        # calculate data gradients\n",
    "        G_motif_data, G_bias_data, G_c_data, p = self.expectedDerivative(H_data, D)\n",
    "        \n",
    "        if self.debug:\n",
    "            G_motif_data = theano.printing.Print('Gradient for motifs (data): ')(G_motif_data)\n",
    "        # calculate model probs\n",
    "        S_H = S_data\n",
    "        for i in range(numOfCDs):\n",
    "            V_model = self.backwardBatch(S_H)\n",
    "            S_V_model = self.sampleVisibleLayer(V_model)\n",
    "            [H_model, S_H] = self.forwardBatch(S_V_model)\n",
    "        \n",
    "        # compute the model gradients\n",
    "        G_motif_model, G_bias_model, G_c_model,p = self.expectedDerivative(H_model, D)\n",
    "        \n",
    "        if self.debug:\n",
    "            G_motif_model = theano.printing.Print('Gradient for motifs (model): ')(G_motif_model)\n",
    "        \n",
    "        # update the parameters\n",
    "        new_motifs = self.motifs + self.learningRate * (G_motif_data - G_motif_model)\n",
    "        new_bias = self.bias + self.learningRate * (G_bias_data - G_bias_model)\n",
    "        new_c = self.c + self.learningRate * (G_c_data - G_c_model)\n",
    "        \n",
    "        #score = self.getDataReconstruction(D)\n",
    "        updates = [(self.motifs, new_motifs), (self.bias, new_bias), (self.c, new_c)]\n",
    "        fun = theano.function([D],\n",
    "                              [p],\n",
    "                              updates = updates,\n",
    "                              allow_input_downcast=True,\n",
    "                              on_unused_input='ignore')\n",
    "        return fun\n",
    "    \n",
    "    \n",
    "    def trainMinibatch (self, trainData, testData, epochs, batchSize, numOfCDs):\n",
    "        \n",
    "        # assert that pooling can be done without rest to the division\n",
    "        assert (((trainData.shape[3] - self.motifLength + 1) % self.poolingFactor) == 0)\n",
    "        assert (((testData.shape[3] - self.motifLength + 1) % self.poolingFactor) == 0)\n",
    "        \n",
    "        itPerEpoch = trainData.shape[0] / batchSize\n",
    "        print \"BatchSize: \" + str(batchSize)\n",
    "        print \"Num of iterations per epoch: \" + str(itPerEpoch)\n",
    "        start = time.time()\n",
    "        trainingFun = self.getTrainingFunction(numOfCDs)\n",
    "        reconFun = self.getFreeEnergyFunction()\n",
    "        #reconstructionFun = self.getDataReconstructionFunction()\n",
    "        print \"Compilation of theano function finished in \" + str(time.time()-start) + \" seconds\"\n",
    "        print \"Start training...\"\n",
    "        start = time.time()\n",
    "        allScores = []\n",
    "        allScores.append(reconFun(testData))\n",
    "        print \"Initial Reconstruction Error: \" + str(allScores[-1])\n",
    "        for epoch in range(epochs):\n",
    "            smallScores = []\n",
    "            for batch in range(itPerEpoch):\n",
    "                trainingFun(trainData[batch*batchSize:(batch+1)*batchSize])\n",
    "            allScores.append(reconFun(testData))\n",
    "            print \"[Epoch \" + str(epoch) + \"] Reconstruction Error: \" + str(allScores[-1])\n",
    "        print \"Training finished after: \" + str(time.time()-start) + \" seconds!\"\n",
    "        return allScores\n",
    "\n",
    "    def getReconFun (self):\n",
    "        D = T.tensor4('data')\n",
    "        score = self.getDataReconstruction(D)\n",
    "        return theano.function([D], score, allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "    def getDataReconstruction (self, D):\n",
    "        [H, S_H] = self.forwardBatch(D)\n",
    "        V = self.backwardBatch(S_H)\n",
    "        S_V = self.sampleVisibleLayer(V)\n",
    "        diff = (T.argmax(D, axis=3) - T.argmax(S_V, axis=3))\n",
    "        diff = abs(diff)\n",
    "        score = diff.mean(axis=0) # mean over all training samples\n",
    "        score = score.sum()\n",
    "        return score\n",
    "    \n",
    " \n",
    "    def getFreeEnergyFunction (self):\n",
    "        D = T.tensor4('data')\n",
    "        free_energy = self.calculateFreeEnergy(D)\n",
    "        return theano.function([D], free_energy, allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "    def calculateFreeEnergy (self, D):\n",
    "        # firstly, compute hidden part of free energy\n",
    "        C = conv.conv2d(D, self.motifs)\n",
    "        bMod = self.bias # to prevent member from being shuffled\n",
    "        bMod = bMod.dimshuffle('x', 1, 0, 'x') # add dims to the bias on both sides\n",
    "        C = C + bMod\n",
    "        hiddenPart = T.sum(T.log(1. + T.exp(C)), axis=1) # dim: N_batch x 1 x N_h after sum over K\n",
    "        hiddenPart = T.sum(T.mean(hiddenPart, axis=0)) # mean over all samples and sum over units\n",
    "        \n",
    "        # compute the visible part\n",
    "        cMod = self.c\n",
    "        cMod = cMod.dimshuffle('x', 0, 1, 'x') # make it 4D and broadcastable there\n",
    "        visiblePart = T.mean(D * cMod, axis=0) # dim: 1 x 4 x N_v\n",
    "        visiblePart = T.sum(visiblePart)\n",
    "        \n",
    "        return hiddenPart + visiblePart # don't return the negative because it's more difficult to plot\n",
    "        \n",
    "        \n",
    "    def sampleVisibleLayer (self, V):\n",
    "        reshaped = V.dimshuffle(0, 1, 3, 2).reshape((V.shape[0]*V.shape[3], V.shape[2]))\n",
    "        S_reshaped = self.theano_rng.multinomial(n=1,pvals=reshaped)\n",
    "        S = S_reshaped.reshape((V.shape[0], 1, V.shape[3], V.shape[2])).dimshuffle(0, 1, 3, 2)\n",
    "        S = S.astype('float32')\n",
    "        if self.debug:\n",
    "            S = theano.printing.Print('Visible Sample: ')(S)\n",
    "        return S\n",
    "    \n",
    "    def softmax (self, x):\n",
    "        return T.exp(x) / T.exp(x).sum(axis=2, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4b: Create the theano functions neccessary for training (compile to C)\n",
    "Theano optimizes the function graph heavily when aiming for maximum performance. Thus, the package spends a long time setting up the whole system and not so much time with the actual training of the data.\n",
    "\n",
    "By generating the function in it's own cell, we can do training seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set some config parameters to make debugging simpler\n",
    "debug = True\n",
    "if debug:\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    theano.config.exception_verbosity='high'\n",
    "    theano.config.optimizer='None'\n",
    "    theano.config.compute_test_value='ignore'\n",
    "    theano.config.profile=True\n",
    "else:\n",
    "    theano.config.exception_verbosity='low'\n",
    "    theano.config.mode='FAST_RUN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our solution on toy data to verify correctness of calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting i: 0 i+1: 1\n",
      "setting i: 2 i+1: 3\n",
      "Motifs:\n",
      "[[[[ 0.35  0.26  0.81  0.    0.86]\n",
      "   [ 0.23  0.71  0.41  0.26  0.23]\n",
      "   [ 0.01  0.8   0.37  0.27  0.93]\n",
      "   [ 0.33  0.34  0.56  0.49  0.05]]]\n",
      "\n",
      "\n",
      " [[[ 0.05  0.49  0.56  0.34  0.33]\n",
      "   [ 0.93  0.27  0.37  0.8   0.01]\n",
      "   [ 0.23  0.26  0.41  0.71  0.23]\n",
      "   [ 0.86  0.    0.81  0.26  0.35]]]\n",
      "\n",
      "\n",
      " [[[ 0.83  0.9   0.28  0.48  0.96]\n",
      "   [ 0.35  0.94  0.83  0.91  0.1 ]\n",
      "   [ 0.05  0.55  0.28  0.37  0.24]\n",
      "   [ 0.88  0.91  0.69  0.02  0.04]]]\n",
      "\n",
      "\n",
      " [[[ 0.04  0.02  0.69  0.91  0.88]\n",
      "   [ 0.24  0.37  0.28  0.55  0.05]\n",
      "   [ 0.1   0.91  0.83  0.94  0.35]\n",
      "   [ 0.96  0.48  0.28  0.9   0.83]]]]\n",
      "Kernel: [[[[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]]]\n",
      "Data shape: (1, 1, 4, 8)\n",
      "New motifs set. # Motifs: 2 K-mer-Length: 3\n",
      "[[[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  1.  0.  1.  1.  1.  1.]\n",
      "   [ 0.  0.  0.  1.  0.  0.  0.  0.]]]]\n",
      "BatchSize: 1\n",
      "Num of iterations per epoch: 1\n",
      "Compilation of theano function finished in 0.90313911438 seconds\n",
      "Start training...\n",
      "Initial Reconstruction Error: 17.3694477081\n",
      "Convolution result forward:  __str__ = [[[[ 3.  0.  1.  1.  1.  1.]]\n",
      "\n",
      "  [[ 0.  3.  0.  1.  1.  1.]]]]\n",
      "prob max pooled layer:  __str__ = [[[[ 1.  0.  0.  1.  0.  1.]\n",
      "   [ 0.  1.  1.  0.  1.  0.]]]]\n",
      "Pre sigmoid visible layer:  __str__ = [[[[ 0.  0.  1.  0.  0.  1.  0.  1.]\n",
      "   [ 0.  1.  0.  1.  2.  0.  2.  0.]\n",
      "   [ 1.  0.  1.  2.  0.  2.  0.  0.]\n",
      "   [ 0.  1.  1.  0.  1.  0.  0.  0.]]]]\n",
      "Visible Sample:  __str__ = [[[[ 1.  1.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  1.  0.  1.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  1.  0.  1.  1.  1.]\n",
      "   [ 0.  0.  0.  0.  0.  0.  0.  0.]]]]\n",
      "Convolution result forward:  __str__ = [[[[ 1.  3.  0.  2.  1.  1.]]\n",
      "\n",
      "  [[ 0.  0.  2.  0.  2.  1.]]]]\n",
      "Hidden Probabilites:  __str__ = [[[[ 0.58  0.91  0.11  0.79  0.24  0.42]\n",
      "   [ 0.21  0.05  0.79  0.11  0.67  0.42]]]]\n",
      "Shape of mean:  __str__ = [1 1 2 6]\n",
      "Hidden Probabilites:  __str__ = [[[[ 0.91  0.05  0.58  0.42  0.42  0.42]\n",
      "   [ 0.05  0.91  0.21  0.42  0.42  0.42]]]]\n",
      "Hidden Layer Probabilities:  __str__ = [[[[ 0.91  0.05  0.58  0.42  0.42  0.42]\n",
      "   [ 0.05  0.91  0.21  0.42  0.42  0.42]]]]\n",
      "Gradient for motifs (data):  __str__ = [[[[ 0.42  0.    0.  ]\n",
      "   [ 0.42  0.42  0.  ]\n",
      "   [ 1.38  1.95  2.38]\n",
      "   [ 0.58  0.42  0.42]]]\n",
      "\n",
      "\n",
      " [[[ 0.42  0.    0.  ]\n",
      "   [ 0.42  0.42  0.  ]\n",
      "   [ 1.38  1.59  2.01]\n",
      "   [ 0.21  0.42  0.42]]]]\n",
      "Gradient for motifs (model):  __str__ = [[[[ 0.42  0.    0.  ]\n",
      "   [ 0.24  0.42  0.  ]\n",
      "   [ 2.27  1.84  2.8 ]\n",
      "   [ 0.11  0.79  0.24]]]\n",
      "\n",
      "\n",
      " [[[ 0.42  0.    0.  ]\n",
      "   [ 0.67  0.42  0.  ]\n",
      "   [ 0.36  1.71  1.57]\n",
      "   [ 0.79  0.11  0.67]]]]\n",
      "[Epoch 0] Reconstruction Error: 17.2767009735\n",
      "Training finished after: 0.00742697715759 seconds!\n",
      "Training (with compilation) performed in: 0.911809206009 seconds.\n",
      "Result from training: \n",
      "----------------------\n",
      "Learned Motif: \n",
      "[[[[ 1.    0.    0.  ]\n",
      "   [ 0.02  1.    0.  ]\n",
      "   [-0.09  0.01  0.96]\n",
      "   [ 0.05 -0.04  0.02]]]\n",
      "\n",
      "\n",
      " [[[ 0.    0.    0.  ]\n",
      "   [ 0.98  0.    0.  ]\n",
      "   [ 0.1   0.99  0.04]\n",
      "   [-0.06  0.03  0.98]]]]\n",
      "Learned Bias (b): \n",
      "[[-0.02  0.02]]\n",
      "Learned Constant (c): \n",
      "[[ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEZCAYAAACw69OmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4fe8e29090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theano.config.profile=True\n",
    "\n",
    "#initialize the learner and set custom kernels\n",
    "x = CRBM(5, 2, .1, 1)\n",
    "print \"Motifs:\"\n",
    "print x.motifs.get_value()\n",
    "kernel1 = np.tile(np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,0]]), [1,1,1])\n",
    "kernel1_ = np.tile(np.flipud(np.fliplr(kernel1[0])),[1,1,1])\n",
    "kernel2 = np.tile(np.array([[0,0,0],[0,0,0],[1,1,1],[0,0,0]]), [1,1,1])\n",
    "kernel2_ = np.tile(np.flipud(np.fliplr(kernel2[0])), [1,1,1])\n",
    "kernel3 = np.random.rand(1,4,3)\n",
    "kernel3_ = np.tile(np.flipud(np.fliplr(kernel3[0])), [1,1,1])\n",
    "kernel = np.array([kernel1, kernel1_])#, kernel2, kernel2_, kernel3, kernel3_])\n",
    "#kernel = np.array([kernel3, kernel3_])\n",
    "print \"Kernel: \" + str(kernel)\n",
    "# initialize the data\n",
    "randSeq1 = getMatrixFromSeq(Seq(\"ACGTGGGG\", IUPAC.unambiguous_dna))\n",
    "randSeq2 = getMatrixFromSeq(Seq(\"ACGTACGT\", IUPAC.unambiguous_dna))\n",
    "data = np.array([randSeq1], dtype=np.float32)\n",
    "print \"Data shape: \" + str(data.shape)\n",
    "x.setCustomKernels(kernel)\n",
    "print data\n",
    "\n",
    "# perform training on our test data\n",
    "start = time.time()\n",
    "scores = x.trainMinibatch(data, data, 1, 1, 1)\n",
    "print \"Training (with compilation) performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "print \"Result from training: \"\n",
    "print \"----------------------\"\n",
    "print \"Learned Motif: \"\n",
    "print x.motifs.get_value()\n",
    "print \"Learned Bias (b): \"\n",
    "print x.bias.get_value()\n",
    "print \"Learned Constant (c): \"\n",
    "print x.c.get_value()\n",
    "plt.ylabel('Average Free Energy')\n",
    "plt.xlabel('Number Of Epoch')\n",
    "plt.title('Toy data')\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting i: 0 i+1: 1\n",
      "setting i: 2 i+1: 3\n",
      "setting i: 4 i+1: 5\n",
      "setting i: 6 i+1: 7\n",
      "setting i: 8 i+1: 9\n",
      "setting i: 10 i+1: 11\n",
      "setting i: 12 i+1: 13\n",
      "setting i: 14 i+1: 15\n",
      "setting i: 16 i+1: 17\n",
      "setting i: 18 i+1: 19\n",
      "setting i: 20 i+1: 21\n",
      "setting i: 22 i+1: 23\n",
      "setting i: 24 i+1: 25\n",
      "setting i: 26 i+1: 27\n",
      "setting i: 28 i+1: 29\n",
      "setting i: 30 i+1: 31\n",
      "setting i: 32 i+1: 33\n",
      "setting i: 34 i+1: 35\n",
      "setting i: 36 i+1: 37\n",
      "setting i: 38 i+1: 39\n",
      "(15000, 1, 4, 150)\n",
      "12797.4140625\n"
     ]
    }
   ],
   "source": [
    "theano.config.mode='FAST_RUN'\n",
    "learner = CRBM(3, 20, 0.0000001, 2)\n",
    "f = learner.getFreeEnergyFunction()\n",
    "x = f(trainingData)\n",
    "print trainingData.shape\n",
    "print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 4: Test our GPU solution on the \"real\" training set\n",
    "It's time now to test on some real data to see how good the training is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting i: 0 i+1: 1\n",
      "setting i: 2 i+1: 3\n",
      "setting i: 4 i+1: 5\n",
      "setting i: 6 i+1: 7\n",
      "setting i: 8 i+1: 9\n",
      "setting i: 10 i+1: 11\n",
      "setting i: 12 i+1: 13\n",
      "setting i: 14 i+1: 15\n",
      "setting i: 16 i+1: 17\n",
      "setting i: 18 i+1: 19\n",
      "setting i: 20 i+1: 21\n",
      "setting i: 22 i+1: 23\n",
      "setting i: 24 i+1: 25\n",
      "setting i: 26 i+1: 27\n",
      "setting i: 28 i+1: 29\n",
      "setting i: 30 i+1: 31\n",
      "setting i: 32 i+1: 33\n",
      "setting i: 34 i+1: 35\n",
      "setting i: 36 i+1: 37\n",
      "setting i: 38 i+1: 39\n",
      "Data mat shape: (15000, 1, 4, 150)\n",
      "BatchSize: 10\n",
      "Num of iterations per epoch: 1500\n",
      "Compilation of theano function finished in 2.05512499809 seconds\n",
      "Start training...\n",
      "Initial Reconstruction Error: 12825.0273438\n",
      "[Epoch 0] Reconstruction Error: 12763.0517578\n",
      "[Epoch 1] Reconstruction Error: 12717.9501953\n",
      "[Epoch 2] Reconstruction Error: 12688.2919922\n",
      "[Epoch 3] Reconstruction Error: 12663.9248047\n",
      "[Epoch 4] Reconstruction Error: 12643.8974609\n",
      "[Epoch 5] Reconstruction Error: 12624.5947266\n",
      "[Epoch 6] Reconstruction Error: 12608.3847656\n",
      "[Epoch 7] Reconstruction Error: 12591.8398438\n",
      "[Epoch 8] Reconstruction Error: 12576.5019531\n",
      "[Epoch 9] Reconstruction Error: 12562.7529297\n",
      "[Epoch 10] Reconstruction Error: 12550.9716797\n",
      "[Epoch 11] Reconstruction Error: 12541.9677734\n",
      "[Epoch 12] Reconstruction Error: 12534.0166016\n",
      "[Epoch 13] Reconstruction Error: 12525.5527344\n",
      "[Epoch 14] Reconstruction Error: 12518.9287109\n",
      "[Epoch 15] Reconstruction Error: 12514.7431641\n",
      "[Epoch 16] Reconstruction Error: 12513.8515625\n",
      "[Epoch 17] Reconstruction Error: 12514.484375\n",
      "[Epoch 18] Reconstruction Error: 12516.3408203\n",
      "[Epoch 19] Reconstruction Error: 12517.7958984\n",
      "[Epoch 20] Reconstruction Error: 12514.546875\n",
      "[Epoch 21] Reconstruction Error: 12516.515625\n",
      "[Epoch 22] Reconstruction Error: 12520.0439453\n",
      "[Epoch 23] Reconstruction Error: 12526.2509766\n",
      "[Epoch 24] Reconstruction Error: 12533.2236328\n",
      "[Epoch 25] Reconstruction Error: 12545.6972656\n",
      "[Epoch 26] Reconstruction Error: 12557.0810547\n",
      "[Epoch 27] Reconstruction Error: 12572.5126953\n",
      "[Epoch 28] Reconstruction Error: 12593.4267578\n",
      "[Epoch 29] Reconstruction Error: 12618.5820312\n",
      "Training finished after: 401.938897848 seconds!\n",
      "Training of 15000 performed in: 403.995334148 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEZCAYAAADolEC/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzhYYXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ff38a2a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theano.config.mode='FAST_RUN'\n",
    "theano.config.profile=True\n",
    "\n",
    "learner = CRBM(3, 20, 0.001, 2)\n",
    "print \"Data mat shape: \" + str(trainingData.shape)\n",
    "start = time.time()\n",
    "scores = learner.trainMinibatch(trainingData, testingData, 30, 10, 1)\n",
    "print \"Training of \" + str(trainingData.shape[0]) + \" performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "plt.plot(scores)\n",
    "plt.ylabel('Average free energy over test set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('The free energy over training time and training data (huge overfitting)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some dummy data to learn about plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

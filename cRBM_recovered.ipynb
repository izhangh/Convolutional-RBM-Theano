{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional RBM (cRBM)\n",
    "\n",
    "This notebook takes care of implementing the basic functionality for cRBMs.\n",
    "Or maybe it's just for the preliminaries, that is some simple stuff before it actually comes to the Boltzmann Machine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading the data and converting it to various forms of matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Theano imports\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet.conv as conv\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from theano import pp\n",
    "\n",
    "# numpy and python classics\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# biopython stuff\n",
    "import Bio.SeqIO as sio\n",
    "import Bio.motifs.matrix as mat\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes to read biological files (such as FASTA or JASPAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This class reads sequences from fasta files.\n",
    "To use it, create an instance of that object and use\n",
    "the function readSequencesFromFile.\n",
    "\"\"\"\n",
    "class FASTAReader:\n",
    "    \n",
    "    def __init__(self, _path):\n",
    "        self.path = _path\n",
    "        \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        dhsSequences = []\n",
    "        for dhs in sio.parse(open(filename), 'fasta', IUPAC.unambiguous_dna):\n",
    "            dhsSequences.append(dhs.seq)\n",
    "        return dhsSequences\n",
    "    \n",
    "    \n",
    "class JASPARReader:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        pass\n",
    "    \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        matrices = []\n",
    "        for mat in motifs.parse(open(filename), 'jaspar'):\n",
    "            matrices.append(mat.pwm)\n",
    "        return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matReader = JASPARReader()\n",
    "pwms = matReader.readSequencesFromFile('data/jaspar_matrices.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply the two classes to calculate a forward pass in our algorithm\n",
    "seqReader = FASTAReader('.')\n",
    "allSeqs = seqReader.readSequencesFromFile('data/wgEncodeAwgDnaseUwAg10803UniPk.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "test_set = [allSeqs[random.randrange(0,len(allSeqs))] for i in range(1000)]\n",
    "print len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion of test set in (in ms): 167.047023773\n"
     ]
    }
   ],
   "source": [
    "def getIntToLetter (letter):\n",
    "    if letter == 'A' or letter == 'a':\n",
    "        return 0\n",
    "    elif letter == 'C' or letter == 'c':\n",
    "        return 1\n",
    "    elif letter == 'G' or letter == 'g':\n",
    "        return 2\n",
    "    elif letter == 'T' or letter == 't':\n",
    "        return 3\n",
    "    else:\n",
    "        print \"ERROR. LETTER \" + letter + \" DOES NOT EXIST!\"\n",
    "        return -1\n",
    "\n",
    "def getMatrixFromSeq (seq):\n",
    "    m = len(seq.alphabet.letters)\n",
    "    n = len(seq)\n",
    "    result = np.zeros((1, m, n))\n",
    "    revSeq = seq.reverse_complement()\n",
    "    for i in range(len(seq)):\n",
    "        result[0,getIntToLetter(seq[i]),i] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dataMat = np.array([getMatrixFromSeq(t) for t in test_set])\n",
    "print \"Conversion of test set in (in ms): \" + str((time.time()-start)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Borrowing Ian Goodfellow's implementation of the probabilistic max pooling layer\n",
    "This implementation is now part of the pylearn2 library which is licensed under the 3-claused BSD license.\n",
    "Source code is available here: https://github.com/lisa-lab/pylearn2/blob/master/pylearn2/expr/probabilistic_max_pooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from theano.gof.op import get_debug_values\n",
    "\n",
    "def max_pool(z, pool_shape, top_down=None, theano_rng=None):\n",
    "    \"\"\"\n",
    "    Probabilistic max-pooling\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : theano 4-tensor\n",
    "        a theano 4-tensor representing input from below\n",
    "    pool_shape : tuple\n",
    "        tuple of ints. the shape of regions to be pooled\n",
    "    top_down : theano 4-tensor, optional\n",
    "        a theano 4-tensor representing input from above\n",
    "        if None, assumes top-down input is 0\n",
    "    theano_rng : MRG_RandomStreams, optional\n",
    "        Used for random numbers for sampling\n",
    "    Returns\n",
    "    -------\n",
    "    p : theano 4-tensor\n",
    "        the expected value of the pooling layer p\n",
    "    h : theano 4-tensor\n",
    "        the expected value of the detector layer h\n",
    "    p_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the pooling layer\n",
    "    h_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the detector layer\n",
    "    Notes\n",
    "    ------\n",
    "    all 4-tensors are formatted with axes ('b', 'c', 0, 1).\n",
    "    This is for maximum speed when using theano's conv2d\n",
    "    to generate z and top_down, or when using it to infer conditionals of\n",
    "    other layers using the return values.\n",
    "    Detailed description:\n",
    "    Suppose you have a variable h that lives in a Conv2DSpace h_space and\n",
    "    you want to pool it down to a variable p that lives in a smaller\n",
    "    Conv2DSpace p.\n",
    "    This function does that, using non-overlapping pools.\n",
    "    Specifically, consider one channel of h. h must have a height that is a\n",
    "    multiple of pool_shape[0] and a width that is a multiple of pool_shape[1].\n",
    "    A channel of h can thus be broken down into non-overlapping rectangles\n",
    "    of shape pool_shape.\n",
    "    Now consider one rectangular pooled region within one channel of h.\n",
    "    I now use 'h' to refer just to this rectangle, and 'p' to refer to\n",
    "    just the one pooling unit associated with that rectangle.\n",
    "    We assume that the space that h and p live in is constrained such\n",
    "    that h and p are both binary and p = max(h). To reduce the state-space\n",
    "    in order to make probabilistic computations cheaper we also\n",
    "    constrain sum(h) <= 1.\n",
    "    Suppose h contains k different units. Suppose that the only term\n",
    "    in the model's energy function involving h is -(z*h).sum()\n",
    "    (elemwise multiplication) and the only term in\n",
    "    the model's energy function involving p is -(top_down*p).sum().\n",
    "    Then P(h[i] = 1) = softmax( [ z[1], z[2], ..., z[k], -top_down] )[i]\n",
    "    and P(p = 1) = 1-softmax( [z[1], z[2], ..., z[k], -top_down])[k]\n",
    "    This variation of the function assumes that z, top_down, and all\n",
    "    return values use Conv2D axes ('b', 'c', 0, 1).\n",
    "    This variation of the function implements the softmax using a\n",
    "    theano graph of exp, maximum, sub, and div operations.\n",
    "    Performance notes:\n",
    "    It might be possible to make a faster implementation with different\n",
    "    theano ops. rather than using set_subtensor, it might be possible\n",
    "    to use the stuff in theano.sandbox.neighbours. Probably not possible,\n",
    "    or at least nasty, because that code isn't written with multiple\n",
    "    channels in mind, and I don't think just a reshape can fix it.\n",
    "    Some work on this in galatea.cond.neighbs.py\n",
    "    At some point images2neighbs' gradient was broken so check that\n",
    "    it has been fixed before sinking too much time into this.\n",
    "    Stabilizing the softmax is also another source of slowness.\n",
    "    Here it is stabilized with several calls to maximum and sub.\n",
    "    It might also be possible to stabilize it with\n",
    "    T.maximum(-top_down,T.signal.downsample.max_pool(z)).\n",
    "    Don't know if that would be faster or slower.\n",
    "    Elsewhere in this file I implemented the softmax with a reshape\n",
    "    and call to Softmax / SoftmaxWithBias.\n",
    "    This is slower, even though Softmax is faster on the GPU than the\n",
    "    equivalent max/sub/exp/div graph. Maybe the reshape is too expensive.\n",
    "    Benchmarks show that most of the time is spent in GpuIncSubtensor\n",
    "    when running on gpu. So it is mostly that which needs a faster\n",
    "    implementation. One other way to implement this would be with\n",
    "    a linear.Conv2D.lmul_T, where the convolution stride is equal to\n",
    "    the pool width, and the thing to multiply with is the hparts stacked\n",
    "    along the channel axis. Unfortunately, conv2D doesn't work right\n",
    "    with stride > 2 and is pretty slow for stride 2. Conv3D is used to\n",
    "    mitigate some of this, but only has CPU code.\n",
    "    \"\"\"\n",
    "\n",
    "    z_name = z.name\n",
    "    if z_name is None:\n",
    "        z_name = 'anon_z'\n",
    "\n",
    "    batch_size, ch, zr, zc = z.shape\n",
    "\n",
    "    r, c = pool_shape\n",
    "\n",
    "    zpart = []\n",
    "\n",
    "    mx = None\n",
    "\n",
    "    if top_down is None:\n",
    "        t = 0.\n",
    "    else:\n",
    "        t = - top_down\n",
    "        t.name = 'neg_top_down'\n",
    "\n",
    "    for i in xrange(r):\n",
    "        zpart.append([])\n",
    "        for j in xrange(c):\n",
    "            cur_part = z[:, :, i:zr:r, j:zc:c]\n",
    "            if z_name is not None:\n",
    "                cur_part.name = z_name + '[%d,%d]' % (i, j)\n",
    "            zpart[i].append(cur_part)\n",
    "            if mx is None:\n",
    "                mx = T.maximum(t, cur_part)\n",
    "                if cur_part.name is not None:\n",
    "                    mx.name = 'max(-top_down,' + cur_part.name + ')'\n",
    "            else:\n",
    "                max_name = None\n",
    "                if cur_part.name is not None:\n",
    "                    mx_name = 'max(' + cur_part.name + ',' + mx.name + ')'\n",
    "                mx = T.maximum(mx, cur_part)\n",
    "                mx.name = mx_name\n",
    "    mx.name = 'local_max(' + z_name + ')'\n",
    "\n",
    "    pt = []\n",
    "\n",
    "    for i in xrange(r):\n",
    "        pt.append([])\n",
    "        for j in xrange(c):\n",
    "            z_ij = zpart[i][j]\n",
    "            safe = z_ij - mx\n",
    "            safe.name = 'safe_z(%s)' % z_ij.name\n",
    "            cur_pt = T.exp(safe)\n",
    "            cur_pt.name = 'pt(%s)' % z_ij.name\n",
    "            pt[-1].append(cur_pt)\n",
    "\n",
    "    off_pt = T.exp(t - mx)\n",
    "    off_pt.name = 'p_tilde_off(%s)' % z_name\n",
    "    denom = off_pt\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            denom = denom + pt[i][j]\n",
    "    denom.name = 'denom(%s)' % z_name\n",
    "\n",
    "    off_prob = off_pt / denom\n",
    "    p = 1. - off_prob\n",
    "    p.name = 'p(%s)' % z_name\n",
    "\n",
    "    hpart = []\n",
    "    for i in xrange(r):\n",
    "        hpart.append([pt_ij / denom for pt_ij in pt[i]])\n",
    "\n",
    "    h = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            h.name = 'h_interm'\n",
    "            h = T.set_subtensor(h[:, :, i:zr:r, j:zc:c], hpart[i][j])\n",
    "\n",
    "    h.name = 'h(%s)' % z_name\n",
    "\n",
    "    if theano_rng is None:\n",
    "        return p, h\n",
    "    \n",
    "    ### --------------------- DONE IF NO SAMPLES ARE GENERATED ---------------------------###\n",
    "    else:\n",
    "        events = []\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                events.append(hpart[i][j])\n",
    "        events.append(off_prob)\n",
    "\n",
    "        events = [event.dimshuffle(0, 1, 2, 3, 'x') for event in events]\n",
    "\n",
    "        events = tuple(events)\n",
    "\n",
    "        stacked_events = T.concatenate(events, axis=4)\n",
    "\n",
    "        rows = zr // pool_shape[0]\n",
    "        cols = zc // pool_shape[1]\n",
    "        outcomes = pool_shape[0] * pool_shape[1] + 1\n",
    "        assert stacked_events.ndim == 5\n",
    "        for se, bs, r, c, chv in get_debug_values(stacked_events, batch_size,\n",
    "                                                  rows, cols, ch):\n",
    "            assert se.shape[0] == bs\n",
    "            assert se.shape[1] == r\n",
    "            assert se.shape[2] == c\n",
    "            assert se.shape[3] == chv\n",
    "            assert se.shape[4] == outcomes\n",
    "        reshaped_events = stacked_events.reshape((\n",
    "            batch_size * rows * cols * ch, outcomes))\n",
    "\n",
    "        multinomial = theano_rng.multinomial(pvals=reshaped_events,\n",
    "                                             dtype=p.dtype)\n",
    "\n",
    "        reshaped_multinomial = multinomial.reshape((batch_size, ch, rows,\n",
    "                                                    cols, outcomes))\n",
    "\n",
    "        h_sample = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "        idx = 0\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                h_sample = T.set_subtensor(h_sample[:, :, i:zr:r, j:zc:c],\n",
    "                                           reshaped_multinomial[:, :, :, :,\n",
    "                                           idx])\n",
    "                idx += 1\n",
    "\n",
    "        p_sample = 1 - reshaped_multinomial[:, :, :, :, -1]\n",
    "\n",
    "        return p, h, p_sample, h_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PART 3: Optimizing theano to do it all on the GPU\n",
    "\n",
    "class CRBM:\n",
    "\n",
    "    def __init__ (self, _motifLength, _numMotifs, _learningRate=0.1, _poolingFactor=1, _alphabet=IUPAC.unambiguous_dna):\n",
    "        # parameters for the motifs\n",
    "        self.motifLength = _motifLength\n",
    "        self.numMotifs = _numMotifs\n",
    "        self.alphabet = _alphabet\n",
    "        self.initializeMotifs()\n",
    "        \n",
    "        # cRBM parameters (2*x to respect both strands of the DNA)\n",
    "        self.bias = theano.shared(value=np.random.rand(2*self.numMotifs), name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=np.array([random.random()]), name='c', borrow=True)\n",
    "        self.poolingFactor = _poolingFactor\n",
    "        self.learningRate = _learningRate\n",
    "        \n",
    "        # infrastructural parameters\n",
    "        self.rng = np.random.RandomState()\n",
    "        self.theano_rng = RandomStreams(self.rng.randint(2**30))\n",
    "    \n",
    "    \n",
    "    def initializeMotifs (self):\n",
    "        # create random motifs (2*self.numMotifs to respect both strands)\n",
    "        x = np.random.rand(2 * self.numMotifs, 1, 4, self.motifLength).astype(np.float32)\n",
    "        \n",
    "        # create reverse complement\n",
    "        for i in range(self.numMotifs):\n",
    "            x[self.numMotifs+i] = np.flipud(np.fliplr(x[self.numMotifs+i]))\n",
    "            \n",
    "        self.motifs = theano.shared(value=x, name='W', borrow=True)\n",
    "        \n",
    "        \n",
    "    def setCustomKernels (self, customKernels):\n",
    "        if len(customKernels.shape) != 4 or customKernels.shape[1] != 1:\n",
    "            print \"New motifs must be a 4D matrix with dims: (K x 1 x numOfLetters(4) x numOfKMers)\"\n",
    "            return\n",
    "        \n",
    "        self.numMotifs = customKernels.shape[0]\n",
    "        self.motifLength = customKernels.shape[3]\n",
    "        self.bias = theano.shared(value=np.random.rand(self.numMotifs), name='bias', borrow=True)\n",
    "        self.motifs = theano.shared(value=customKernels.astype(np.float32))\n",
    "        print \"New motifs set. # Motifs: \" + str(self.numMotifs) + \" K-mer-Length: \" + str(self.motifLength)\n",
    "\n",
    "        \n",
    "### ------------------------------THE TOUGH STUFF-------------------------------- ###\n",
    "### ----------------------------------------------------------------------------- ###\n",
    "\n",
    "    def forwardBatch (self, data):\n",
    "        out = conv.conv2d(data, self.motifs)[:,:,::-1,::-1] # flip, because conv reverts H\n",
    "        out = out.mean(axis=2, keepdims=True)\n",
    "        #bMod = self.bias.dimshuffle('x', 0, 'x', 'x') # add dims to the bias until it works\n",
    "        pooled = max_pool(out.dimshuffle(0,2,1,3), pool_shape=(2, self.poolingFactor), theano_rng=self.theano_rng)\n",
    "        H = pooled[1]\n",
    "        S = pooled[3]\n",
    "        return [H,S] #only return pooled layer and probs\n",
    "\n",
    "\n",
    "    def backwardBatch (self, H_sample):\n",
    "        K = self.motifs.dimshuffle(1, 0, 2, 3)[:,:,::-1,::-1]\n",
    "        H_shuffled = H_sample.dimshuffle(0, 2, 1, 3) # interpret the kernels as channels (will be summed automatically)\n",
    "        C = conv.conv2d(H_shuffled, K, border_mode='full')\n",
    "        out = T.sum(C, axis=1, keepdims=True) # sum over all K\n",
    "        #out = out + self.c\n",
    "        \n",
    "        # add fourth dimension (the strands) that was lost during forward pass\n",
    "        res = self.softmax(out)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def gradient (self, hiddenProbs, data):\n",
    "        mean = T.mean(hiddenProbs, axis=0, keepdims=True) # sum over all training data to get avg (but keep dim)\n",
    "        #mean = T.tile(mean, [2,1,1,1])\n",
    "        H_reshaped = mean.dimshuffle(2, 0, 1, 3)\n",
    "        out = conv.conv2d(data, H_reshaped)\n",
    "        return T.mean(out, axis=0, keepdims=True).dimshuffle(1, 0, 2, 3) #mean over all training samples\n",
    "\n",
    "    \n",
    "    def getTrainingFunction (self, numOfCDs):\n",
    "        # calculate the data gradient for weights (motifs) and bias\n",
    "        D_batch = T.tensor4('data')\n",
    "        [H_data, S_data] = self.forwardBatch(D_batch)\n",
    "        G_data = self.gradient(H_data, D_batch)\n",
    "        bias_data = T.mean(T.sum(H_data, axis=3), axis=0)\n",
    "        \n",
    "        # calculate the model gradient (only CD-1 for now)\n",
    "        for i in range(numOfCDs):\n",
    "            V_model = self.backwardBatch(S_data)\n",
    "            S_v = self.sampleVisibleLayer(V_model)\n",
    "            [H_model, S_model] = self.forwardBatch(S_v)\n",
    "            G_model = self.gradient(H_model, D_batch)\n",
    "            bias_model = T.mean(T.sum(H_model, axis=3), axis=0)\n",
    "        \n",
    "        self.motifs = self.motifs + self.learningRate * (G_data - G_model)\n",
    "        self.bias = self.bias + self.learningRate * (bias_data - bias_model)\n",
    "        \n",
    "        fun = theano.function([D_batch], [self.motifs,self.bias], allow_input_downcast=True)\n",
    "        return fun\n",
    "    \n",
    "    \n",
    "    def batchTraining (self, data, epochs, batchSize, numOfCDs):\n",
    "        \n",
    "        trainingFun = self.getTrainingFunction(numOfCDs)\n",
    "        pp(trainingFun.maker.fgraph)\n",
    "        # after we got the theano function for everything, let's apply it!\n",
    "        itPerEpoch = data.shape[0] / batchSize\n",
    "        for epoch in range(epochs):\n",
    "            for batch in range(itPerEpoch):\n",
    "                #print batch*batchSize, (batch+1)*batchSize\n",
    "                res = trainingFun(data[batch*batchSize:(batch+1)*batchSize])\n",
    "            #print \"Epoch done: \" + str(epoch)\n",
    "        return res\n",
    "        \n",
    "        \n",
    "    def getDataReconstructionFunction (self):\n",
    "        D = T.tensor4('testData')\n",
    "        [H, S_H] = self.forwardBatch(D)\n",
    "        V = self.sampleVisibleLayer(self.backwardBatch(S_H))\n",
    "        diff = T.abs_(D - V)\n",
    "        scorePerSample = diff.sum(axis=3) # sum over errors for each letter\n",
    "        score = scorePerSample.mean(axis=0) # mean over all training samples\n",
    "        f = theano.function([D], score, allow_input_downcast=True)\n",
    "        return f\n",
    "        \n",
    " \n",
    "    def sampleVisibleLayer (self, V):\n",
    "        S = self.theano_rng.multinomial(n=1,pvals=V.dimshuffle(0,1,3,2)).dimshuffle(0,1,3,2)\n",
    "        S = S.astype('float32')\n",
    "        return S\n",
    "    \n",
    "    def softmax (self, x):\n",
    "        return T.exp(x) / T.exp(x).sum(axis=2, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel shape: (6, 1, 4, 3)\n",
      "Data shape: (2, 1, 4, 8)\n",
      "Data mat shape: (1000, 1, 4, 150)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FunctionGraph' object has no attribute 'owner'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8bac371abfef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Data mat shape: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchTraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Training performed in: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" seconds.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#print \"Result from training: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-b178bf5225a9>\u001b[0m in \u001b[0;36mbatchTraining\u001b[1;34m(self, data, epochs, batchSize, numOfCDs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mtrainingFun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrainingFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumOfCDs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mpp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingFun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;31m# after we got the theano function for everything, let's apply it!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mitPerEpoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/printing.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mPrinterState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/printing.pyc\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, r, pstate)\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mpstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrinterState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpprinter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprinter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprinters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/printing.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(pstate, r)\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             condition = (lambda pstate, r: r.owner is not None\n\u001b[0m\u001b[0;32m    424\u001b[0m                          and r.owner.op == op)\n\u001b[0;32m    425\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprinters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FunctionGraph' object has no attribute 'owner'"
     ]
    }
   ],
   "source": [
    "\n",
    "# set some config parameters to make debugging simpler\n",
    "debug = False\n",
    "if debug:\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    theano.config.exception_verbosity='high'\n",
    "    theano.config.optimizer='None'\n",
    "    theano.config.compute_test_value='ignore'\n",
    "\n",
    "#initialize the learner and set custom kernels\n",
    "x = CRBM(3, 2, 1.5, 3)\n",
    "kernel1 = np.tile(np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,0]]), [1,1,1])\n",
    "kernel1_ = np.tile(np.flipud(np.fliplr(kernel1[0])),[1,1,1])\n",
    "kernel2 = np.tile(np.array([[0,0,0],[0,0,0],[1,1,1],[0,0,0]]), [1,1,1])\n",
    "kernel2_ = np.tile(np.flipud(np.fliplr(kernel2[0])), [1,1,1])\n",
    "kernel3 = np.random.rand(1,4,3)\n",
    "kernel3_ = np.tile(np.flipud(np.fliplr(kernel3[0])), [1,1,1])\n",
    "kernel = np.array([kernel1, kernel1_, kernel2, kernel2_, kernel3, kernel3_])\n",
    "#kernel = np.array([kernel3, kernel3_])\n",
    "print \"Kernel shape: \" + str(kernel.shape)\n",
    "\n",
    "# initialize the data\n",
    "randSeq1 = getMatrixFromSeq(Seq(\"ACGTGGGG\", IUPAC.unambiguous_dna))\n",
    "randSeq2 = getMatrixFromSeq(Seq(\"ACGTACGT\", IUPAC.unambiguous_dna))\n",
    "data = np.array([randSeq1, randSeq2], dtype=np.float32)\n",
    "print \"Data shape: \" + str(data.shape)\n",
    "#x.setCustomKernels(kernel)\n",
    "#print x.motifs.shape\n",
    "\n",
    "\n",
    "# function to do the reconstruction\n",
    "D = T.tensor4('data')\n",
    "[H,S] = x.forwardBatch(D)\n",
    "P_V = x.softmax(x.backwardBatch(S))\n",
    "V = x.sampleVisibleLayer(P_V)\n",
    "test = theano.function([D], V, allow_input_downcast=True)\n",
    "\n",
    "# perform training on our test data\n",
    "start = time.time()\n",
    "print \"Data mat shape: \" + str(dataMat.shape)\n",
    "res = x.batchTraining(data, 100, 2, 10)\n",
    "print \"Training performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "#print \"Result from training: \"\n",
    "print res[0]\n",
    "print res[1]\n",
    "\n",
    "\n",
    "\n",
    "# now validate how well we are recognizing the training data\n",
    "result = test(data)\n",
    "print result.shape\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 4: Test our GPU solution on the \"real\" training set\n",
    "It's time now to test on some real data to see how good the training is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Score: [[ 53.87  54.28  49.41  66.63]]\n",
      "Training of 1000 performed in: 162.078318119 seconds.\n",
      "(20, 1, 4, 4)\n",
      "(1, 20)\n",
      "Final Score: [[ 53.73  54.56  49.31  66.97]]\n"
     ]
    }
   ],
   "source": [
    "learner = CRBM(4, 10, 0.3, 3)\n",
    "reconFun = learner.getDataReconstructionFunction()\n",
    "print \"Initial Score: \" + str(reconFun(dataMat))\n",
    "start = time.time()\n",
    "[motifs, bias] = learner.batchTraining(dataMat, 1, 1000, 10)\n",
    "scoreAfterTraining = reconFun(dataMat)\n",
    "print \"Training of \" + str(dataMat.shape[0]) + \" performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "print motifs.shape\n",
    "print bias.shape\n",
    "print \"Final Score: \" + str(scoreAfterTraining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4b: Why is it so slow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MissingInputError",
     "evalue": "A variable that is an input to the graph was neither provided as an input to the function nor given a value. A chain of variables leading from this input to an output is [data, ConvOp{('imshp', (None, None, None)),('kshp', (None, None)),('nkern', None),('bsize', None),('dx', 1),('dy', 1),('out_mode', 'valid'),('unroll_batch', None),('unroll_kern', None),('unroll_patch', True),('imshp_logical', (None, None, None)),('kshp_logical', (None, None)),('kshp_logical_top_aligned', True)}.0, Sum{axis=[0], acc_dtype=float64}.0, DimShuffle{x,0,1,2}.0, Elemwise{true_div,no_inplace}.0, DimShuffle{1,0,2,3}.0, Elemwise{sub,no_inplace}.0, Elemwise{mul,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0]. This chain may not be unique\nBacktrace when the variable is created:\n  File \"<ipython-input-74-4c78b74c948e>\", line 81, in getTrainingFunction\n    D_batch = T.tensor4('data')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingInputError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-4fae77e25db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrainingFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-4c78b74c948e>\u001b[0m in \u001b[0;36mgetTrainingFunction\u001b[1;34m(self, numOfCDs)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearningRate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbias_data\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbias_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mfun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotifs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    509\u001b[0m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[0;32m    510\u001b[0m             \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             on_unused_input=on_unused_input)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input)\u001b[0m\n\u001b[0;32m   1463\u001b[0m                    \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1466\u001b[0m                        defaults)\n\u001b[0;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph)\u001b[0m\n\u001b[0;32m   1131\u001b[0m             \u001b[0mneed_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m             \u001b[1;31m# make the fgraph (copies the graph, creates NEW INPUT AND OUTPUT VARIABLES)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m             \u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madditional_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd_fgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_inplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mstd_fgraph\u001b[1;34m(input_specs, output_specs, accept_inplace)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0morig_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_specs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mfgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctionGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, features, clone)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"init\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import_r__\u001b[1;34m(self, variables, reason)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mapply_node\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mapply_node\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapply_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-11-21/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import__\u001b[1;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[0;32m    351\u001b[0m                                 \u001b[1;34m'leading from this input to an output is %s. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                                 \u001b[1;34m'This chain may not be unique'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                                 detailed_err_msg)\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                         \u001b[1;31m#Standard error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingInputError\u001b[0m: A variable that is an input to the graph was neither provided as an input to the function nor given a value. A chain of variables leading from this input to an output is [data, ConvOp{('imshp', (None, None, None)),('kshp', (None, None)),('nkern', None),('bsize', None),('dx', 1),('dy', 1),('out_mode', 'valid'),('unroll_batch', None),('unroll_kern', None),('unroll_patch', True),('imshp_logical', (None, None, None)),('kshp_logical', (None, None)),('kshp_logical_top_aligned', True)}.0, Sum{axis=[0], acc_dtype=float64}.0, DimShuffle{x,0,1,2}.0, Elemwise{true_div,no_inplace}.0, DimShuffle{1,0,2,3}.0, Elemwise{sub,no_inplace}.0, Elemwise{mul,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0]. This chain may not be unique\nBacktrace when the variable is created:\n  File \"<ipython-input-74-4c78b74c948e>\", line 81, in getTrainingFunction\n    D_batch = T.tensor4('data')\n"
     ]
    }
   ],
   "source": [
    "tf = learner.getTrainingFunction(10)\n",
    "tf.pp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional RBM (cRBM)\n",
    "\n",
    "This notebook takes care of implementing the basic functionality for cRBMs.\n",
    "Or maybe it's just for the preliminaries, that is some simple stuff before it actually comes to the Boltzmann Machine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initializing the weight matrices and applying them to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import theano\n",
    "import numpy as np\n",
    "import Bio.SeqIO as sio\n",
    "import Bio.motifs.matrix as mat\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs\n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FASTAReader:\n",
    "    \n",
    "    def __init__(self, _path):\n",
    "        self.path = _path\n",
    "        \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        dhsSequences = []\n",
    "        for dhs in sio.parse(open(filename), 'fasta', IUPAC.unambiguous_dna):\n",
    "            dhsSequences.append(dhs)\n",
    "        return dhsSequences\n",
    "    \n",
    "    \n",
    "class JASPARReader:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        pass\n",
    "    \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        matrices = []\n",
    "        for mat in motifs.parse(open(filename), 'jaspar'):\n",
    "            matrices.append(mat.pwm)\n",
    "        return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<class 'Bio.motifs.matrix.PositionWeightMatrix'>\n"
     ]
    }
   ],
   "source": [
    "matReader = JASPARReader()\n",
    "pwms = matReader.readSequencesFromFile('../data/jaspar_matrices.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply the two classes to calculate a forward pass in our algorithm\n",
    "seqReader = FASTAReader('.')\n",
    "allSeqs = seqReader.readSequencesFromFile('../data/wgEncodeAwgDnaseUwAg10803UniPk.fa')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The implementation of our convRBM so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvRBM:\n",
    "    \n",
    "    def __init__ (self, _motifLength, _numMotifs, _poolingFactor=1, _alphabet=IUPAC.unambiguous_dna):\n",
    "        # parameters for the motifs\n",
    "        self.motifLength = _motifLength\n",
    "        self.numMotifs = _numMotifs\n",
    "        self.motifs = []\n",
    "        self.alphabet = _alphabet\n",
    "        self.poolingFactor = _poolingFactor\n",
    "        \n",
    "        # cRBM parameters\n",
    "        self.bias = np.random.rand(self.numMotifs)\n",
    "        self.c = random.random()\n",
    "        \n",
    "    def initializePWMs (self):\n",
    "        # set up PWMs\n",
    "        for m in range(self.numMotifs):\n",
    "            self.motifs.append(self._createRandomMotif(self.motifLength, self.alphabet))\n",
    "        \n",
    "    def forwardPass (self, seq):\n",
    "        \n",
    "        # check that we actually have some motifs to do convolution on\n",
    "        if self.motifs == []:\n",
    "            print 'Error: No motifs created so far. Try executing initializePWMs before!'\n",
    "            return\n",
    "        if (len(seq)-self.motifLength+1) % self.poolingFactor != 0:\n",
    "            print 'Dimension mismatch: cannot create pooling layer because it would not fit!'\n",
    "\n",
    "        # perform convolution of motif and sequence (that is, apply the motif to the sequence)\n",
    "        hiddenActivation = np.zeros((2*self.numMotifs, len(seq)-self.motifLength+1))\n",
    "        motifCount = 0\n",
    "        for motif in self.motifs:\n",
    "            pssm = motif.log_odds()\n",
    "            \n",
    "            # apply convolution on both strands\n",
    "            hiddenActivation[motifCount*2,:] = pssm.calculate(seq) + self.bias[motifCount]\n",
    "            hiddenActivation[motifCount*2+1,:] = pssm.calculate(seq.reverse_complement()) + self.bias[motifCount]\n",
    "            hiddenActivation[motifCount*2:motifCount*2+2,:] = self._probMaxPooling(hiddenActivation[motifCount*2:motifCount*2+2,:])\n",
    "            motifCount += 1\n",
    "\n",
    "        return hiddenActivation\n",
    "    \n",
    "    def backwardPass (self, hiddenActivation):\n",
    "        \n",
    "        # apply convolution on all of the filters\n",
    "        restoredLength = hiddenActivation.shape[1] + self.motifLength - 1\n",
    "        numOfLetters = len(self.alphabet.letters)\n",
    "        reConv = np.zeros((numOfLetters, restoredLength))\n",
    "\n",
    "        #start = time.time()\n",
    "        reConv = np.zeros((numOfLetters, restoredLength))\n",
    "        for k in range(len(self.motifs)):\n",
    "            # apply convolution on each of the channels (A, C, G, T) seperately\n",
    "            matrix = self._convertPWM2Array(self.motifs[k])\n",
    "            for i in range(numOfLetters):\n",
    "                conv1 = np.convolve(hiddenActivation[k], matrix[i])\n",
    "                conv2 = np.convolve(hiddenActivation[k+1], matrix[i])\n",
    "                reConv[i,:] = reConv[i,:] + conv1 + conv2 + self.c\n",
    "\n",
    "        #convTime = time.time()\n",
    "        # perform softmax and select index of the most promising one (results in visibleActivation)\n",
    "        visibleActivation = np.zeros((1, restoredLength))\n",
    "        \n",
    "        # calculate exp for whole matrix\n",
    "        reConv = np.exp(reConv)\n",
    "        \n",
    "        # calculate the sum (over all four letters for whole sequence)\n",
    "        sums = np.sum(reConv, 0)\n",
    "\n",
    "        # divide by the sum\n",
    "        for i in range(numOfLetters):\n",
    "            reConv[i,:] = reConv[i,:] / sums[i]\n",
    "            \n",
    "        # and the maximum is our letter...\n",
    "        visibleActivation = np.argmax(reConv, 0)\n",
    "        \n",
    "        #print \"Done with Softmax in: \" + str((time.time()-convTime)*1000)\n",
    "        # convert the resulting sequence to actual letters (A, C, G, T instead of 0, 1, 2, 3)\n",
    "        return self._getDNASeqFromNumericals(visibleActivation)\n",
    "\n",
    "    def _probMaxPooling (self, h_k):\n",
    "\n",
    "        # first of all some easy definitions\n",
    "        l = h_k.shape[1]\n",
    "        numOfGroups = l/self.poolingFactor\n",
    "        P = np.zeros((2, l))\n",
    "\n",
    "        # exponent of everything\n",
    "        ex = np.exp(h_k)\n",
    "        \n",
    "        # reshape s.t. each group forms one row\n",
    "        newDim = (numOfGroups, -1)\n",
    "        reordered = np.append(ex[0].reshape(newDim), ex[1].reshape(newDim), 1)\n",
    "        #print \"Shape of reordered: \" + str(reordered.shape)\n",
    "        # calculate denominators (sum of all rows)\n",
    "        denoms = np.sum(reordered, 1) + 1 # denoms for all groups (add 1 to have log. unit)\n",
    "        res = np.argmax(reordered.T / denoms, 0)\n",
    "\n",
    "        # calculate the actual values of the pooling layer P\n",
    "        for group in range(numOfGroups):\n",
    "            if reordered[group,res[group]] > 1: # check if really any element from P should be active\n",
    "                # we don't care about strands so just set res = res/2 for the index\n",
    "                idx = group * self.poolingFactor + int(res[group]/2)\n",
    "                P[res[group] % 2, idx] = reordered[group,res[group]] / denoms[group]\n",
    "        return P\n",
    "        \n",
    "    def _createRandomMotif (self, motifLength, alphabet):\n",
    "        counts = {}\n",
    "        for letter in alphabet.letters:\n",
    "            counts[letter] = [random.randint(0,100) for x in xrange(motifLength)]\n",
    "        return mat.PositionWeightMatrix(alphabet, counts)\n",
    "        \n",
    "    def _sigmoid (self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def _softmaxActivation (self, col, idx):\n",
    "        p_all = np.sum(np.exp(col))\n",
    "        p_x = np.exp(col[idx])\n",
    "        return p_x / p_all\n",
    "\n",
    "    def _getLetterToInt (self, num):\n",
    "        if num == 0:\n",
    "            return 'A'\n",
    "        elif num == 1:\n",
    "            return 'C'\n",
    "        elif num == 2:\n",
    "            return 'G'\n",
    "        elif num == 3:\n",
    "            return 'T'\n",
    "        else:\n",
    "            print 'ERROR: Num ' + str(num) + \" not a valid char in DNA alphabet\"\n",
    "            return -1\n",
    "\n",
    "    def _getDNASeqFromNumericals (self, seq):\n",
    "        dna_seq = []\n",
    "        for num in range(seq.shape[0]):\n",
    "            dna_seq.append(self._getLetterToInt(seq[num]))\n",
    "        return dna_seq\n",
    "\n",
    "    def _convertPWM2Array (self, pwm):\n",
    "        result = np.zeros((len(self.alphabet.letters), self.motifLength))\n",
    "        for letter in range(len(pwm)):\n",
    "            result[letter] = pwm[self._getLetterToInt(letter)]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with a simple test sequence to verify that forward and backward pass work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:\n",
      "[[ 0.          0.          0.          0.          0.99966465]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.99966465  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.99966465]]\n",
      "Kernel:\n",
      "        0      1      2      3\n",
      "A:   0.00   0.00   0.00   0.00\n",
      "C:   0.00   0.00   0.00   0.00\n",
      "G:   1.00   1.00   1.00   1.00\n",
      "T:   0.00   0.00   0.00   0.00\n",
      "\n",
      "ReConv\n",
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.99966465  0.99966465\n",
      "   0.99966465  0.99966465]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "Kernel:\n",
      "        0      1      2      3\n",
      "A:   1.00   0.00   0.00   0.00\n",
      "C:   0.00   1.00   0.00   0.00\n",
      "G:   0.00   0.00   1.00   0.00\n",
      "T:   0.00   0.00   0.00   1.00\n",
      "\n",
      "ReConv\n",
      "[[ 0.99966465  0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.99966465  0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.99966465  0.          0.99966465  0.99966465\n",
      "   0.99966465  0.99966465]\n",
      " [ 0.          0.          0.          0.99966465  0.          0.          0.\n",
      "   0.        ]]\n",
      "[[ 0.99966465  0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.99966465  0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.99966465  0.          0.99966465  0.99966465\n",
      "   0.99966465  0.99966465]\n",
      " [ 0.          0.          0.          0.99966465  0.          0.          0.\n",
      "   0.        ]]\n",
      "Reconstruction:\n",
      "['A', 'C', 'G', 'T', 'G', 'G', 'G', 'G']\n"
     ]
    }
   ],
   "source": [
    "learner = ConvRBM(4, 2)\n",
    "learner.bias = np.zeros(2)\n",
    "learner.c = 0\n",
    "# create PWM (that will look for a sequence of 4 Gs)\n",
    "counts = {}\n",
    "for letter in learner.alphabet.letters:\n",
    "    if letter != 'G':\n",
    "        counts[letter] = [0 for x in xrange(learner.motifLength)]\n",
    "    else:\n",
    "        counts[letter] = [1 for x in xrange(learner.motifLength)]\n",
    "kernel = mat.PositionWeightMatrix(learner.alphabet, counts)\n",
    "learner.motifs.append(kernel)\n",
    "\n",
    "# create second kernel that will look for ACGT\n",
    "counts = {}\n",
    "for letter in range(len(learner.alphabet.letters)):\n",
    "    counts[learner._getLetterToInt(letter)] = [int(x == letter) for x in xrange(learner.motifLength)]\n",
    "\n",
    "kernel = mat.PositionWeightMatrix(learner.alphabet, counts)\n",
    "learner.motifs.append(kernel)\n",
    "\n",
    "# set the cRBMs other params to 0\n",
    "learner.bias = np.zeros(learner.numMotifs)\n",
    "learner.c = 0\n",
    "\n",
    "# now test forward pass on a simple sequence\n",
    "testSeq = Seq(\"ACGTGGGG\", learner.alphabet)\n",
    "h = learner.forwardPass(testSeq)\n",
    "print \"Hidden Layer:\"\n",
    "print h\n",
    "\n",
    "maxPooled = learner._probMaxPooling(h[:2])\n",
    "reconstructed = learner.backwardPass(h)\n",
    "print \"Reconstruction:\"\n",
    "print reconstructed\n",
    "\n",
    "# Should be able to completely reconstruct the sequence because we gave two kernels\n",
    "# which both can be hold responsible for a portion of the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for forward: 4.74905967712\n",
      "[[ 1.04656108  1.10687229  1.31539531  1.24481858  1.01337031  1.19850955\n",
      "   0.99809353  1.08133924  0.9355967   1.02087126  1.00491989  1.18249696\n",
      "   0.94825204  0.91475632  0.99470206  1.05607144  1.17882425  1.12515563\n",
      "   0.93792129  0.91475632  0.91475632  0.98534288  1.05243474  1.15887679\n",
      "   1.13309008  1.01367436  0.9779646   1.10245326  0.93823817  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  1.01890371  1.12510975  1.2810758\n",
      "   1.25510241  0.95322257  1.00247143  0.98928595  1.136072    1.18212841\n",
      "   1.11841094  1.63183429  1.3052495   1.51823862  1.61733624  1.32123926\n",
      "   1.084475    1.15196197  1.45245753  1.37055601  1.29276287  1.06939996\n",
      "   1.21985951  1.28672282  1.32520894  1.32955776  1.2765966   1.03116855\n",
      "   1.29952017  1.16936517  1.45343614  1.45678056  1.59484131  1.37188838\n",
      "   1.51684181  0.98661925  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   1.06456716  1.11270637  1.35278434  1.26797008  1.11120742  1.40520526\n",
      "   1.2912133   1.3494371   1.27355973  1.29719628  1.2391656   1.25456046\n",
      "   0.95417897  0.91475632  0.91475632  0.91475632  1.04191607  1.02280121\n",
      "   1.2355955   0.95489494  1.14581373  1.11108081  1.49774168  1.09687503\n",
      "   1.13863217  1.39841016  1.43029332  1.43902861  1.27071691  1.39265839\n",
      "   0.97185682  0.91475632  0.9797518   0.96998158  1.07874766  0.93527248\n",
      "   1.03991962  1.02110487  1.23055823  0.95426476  1.04009051  1.02125007\n",
      "   1.33035879  1.03875072  1.16547712  0.94612278  1.03146098  1.01391774\n",
      "   1.33171223  1.05567708  1.22382872  0.95342286  1.01943967  1.0037035\n",
      "   1.28018717  1.03387451  1.26242323  1.08927536  1.20170346  1.18514121\n",
      "   1.00222657  1.21485398  1.0990834   1.2314385   1.24209758  1.030863\n",
      "   1.2567552   1.11672862  1.176775    1.21588699  0.94980498  0.91475632]\n",
      " [ 1.21821378  1.51401248  1.32744986  1.66273954  1.46091562  1.17187321\n",
      "   1.41826673  0.99517566  1.14102328  1.15906747  1.24869549  1.04401042\n",
      "   1.27842422  0.91475632  1.09881745  1.3353028   1.24308042  1.27812893\n",
      "   1.16626171  0.91475632  0.91475632  1.07726958  1.31578575  1.24526135\n",
      "   1.25131061  1.35232362  1.14886109  1.00536863  1.16970212  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  1.15453753  1.52306887  1.42510717\n",
      "   1.42011568  1.33238992  1.11670507  1.19079201  1.02159837  1.76719736\n",
      "   1.66903269  1.4653162   2.59478435  2.04972102  1.98755447  1.82944761\n",
      "   1.66642476  1.61273297  1.72065399  1.84375341  1.64426961  1.64011202\n",
      "   1.37616016  1.76264863  1.81835409  1.60739549  1.69187202  1.54025568\n",
      "   1.31840207  1.92716937  1.74772424  2.09702585  2.28917716  2.20000157\n",
      "   1.49242701  1.69498246  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   1.25966965  1.54888466  1.31959542  1.80811997  1.70984481  1.53613692\n",
      "   1.95862535  1.66513811  1.78059948  1.78552986  1.63055282  1.33492185\n",
      "   1.3427737   0.91475632  0.91475632  0.91475632  1.20751946  1.31492257\n",
      "   1.0696442   1.35054713  1.44672572  1.64188406  1.19619753  1.95799387\n",
      "   1.56019936  1.68313042  1.90985942  2.11258626  1.89857084  1.3683296\n",
      "   1.5347046   0.91475632  1.06439709  1.11929431  0.99392455  1.13750318\n",
      "   1.20292299  1.30863985  1.06721241  1.34370509  1.20331643  1.30917762\n",
      "   1.29620125  1.65700194  1.03579394  1.25530644  1.18344845  1.28202086\n",
      "   1.33893535  1.70020652  1.06396368  1.3345645   1.15577149  1.24419034\n",
      "   1.27549749  1.59231191  1.2501216   1.69973853  1.22929293  1.49063037\n",
      "   1.38394082  1.24274875  1.67244105  1.26978509  1.6010557   1.51156673\n",
      "   1.20077931  1.75379297  1.34512416  1.27775314  1.29528466  0.91475632]\n",
      " [ 1.1630397   1.17767982  1.35744301  1.5427766   1.13260238  1.28438428\n",
      "   1.12650698  1.10240145  1.03384419  1.11464726  1.00491989  1.21634922\n",
      "   1.10616048  0.91475632  1.06535179  1.12092503  1.20432815  1.26753351\n",
      "   1.04712757  0.91475632  0.91475632  1.04772171  1.12110209  1.18139497\n",
      "   1.26291742  1.19504336  0.9779646   1.12618506  1.04893832  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  1.11094095  1.23280144  1.31430038\n",
      "   1.44895865  1.13456348  1.07998712  0.98928595  1.16405444  1.52447035\n",
      "   1.11841094  1.80756187  1.8558048   1.6721868   1.8544772   1.69035637\n",
      "   1.39606737  1.2658264   1.58721429  1.6014352   1.57921067  1.28315491\n",
      "   1.31110259  1.52000307  1.51948725  1.48634067  1.58378362  1.15924515\n",
      "   1.43885514  1.43144837  1.61078275  1.75062251  2.01717084  1.60047293\n",
      "   1.71989102  1.32540166  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   1.19695814  1.17514922  1.40057626  1.62624491  1.27440663  1.54540759\n",
      "   1.56819119  1.54176688  1.53404646  1.54000713  1.36290001  1.41078873\n",
      "   1.14002863  0.91475632  0.91475632  0.91475632  1.1542898   1.02280121\n",
      "   1.27616137  1.1441199   1.35000401  1.11108081  1.57145247  1.53719733\n",
      "   1.25449182  1.51876141  1.69473513  1.82485623  1.43643346  1.5516387\n",
      "   1.24104489  0.91475632  1.03718967  0.96998158  1.0994822   1.03199151\n",
      "   1.15052905  1.02110487  1.27048721  1.14051883  1.15085096  1.02125007\n",
      "   1.45815709  1.22525909  1.19717745  1.09399322  1.13459533  1.01391774\n",
      "   1.4771952   1.22934395  1.26290684  1.13570799  1.11195055  1.0037035\n",
      "   1.40310568  1.18965261  1.37610366  1.29685708  1.23107492  1.41252584\n",
      "   1.09793038  1.32900897  1.28199583  1.26354356  1.51192848  1.1407787\n",
      "   1.35032207  1.37736267  1.19797528  1.35020027  1.11503439  0.91475632]\n",
      " [ 1.20595288  1.42775011  1.22602652  1.41415592  1.28286016  1.13069446\n",
      "   1.24259428  0.96836921  1.03682139  1.14919632  1.18524705  1.00092572\n",
      "   1.11094558  0.91475632  1.09138063  1.2806748   1.16674126  1.122156\n",
      "   1.05043686  0.91475632  0.91475632  1.07070338  1.26635236  1.17014181\n",
      "   1.10835683  1.22276751  1.10438118  0.97516453  1.05229287  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   0.91475632  0.91475632  0.91475632  1.1448494   1.4494609   1.3099576\n",
      "   1.20626422  1.14005866  1.10854553  1.13834523  0.98598435  1.60646251\n",
      "   1.52572018  1.35755085  2.12892549  1.86050056  1.6412791   1.4289153\n",
      "   1.44361563  1.52449457  1.58193197  1.52651317  1.39129797  1.42517177\n",
      "   1.30350434  1.57013813  1.6045558   1.38114912  1.44891841  1.3416152\n",
      "   1.2646168   1.67866014  1.61498767  1.77065645  1.97193044  1.81550802\n",
      "   1.26166588  1.33566779  0.91475632  0.91475632  0.91475632  0.91475632\n",
      "   1.24573376  1.45273655  1.21652078  1.53111438  1.51589344  1.43456122\n",
      "   1.65623166  1.46487186  1.52560497  1.58218707  1.4193514   1.1607738\n",
      "   1.14566043  0.91475632  0.91475632  0.91475632  1.19569065  1.23889098\n",
      "   1.0180149   1.14985399  1.42523201  1.50372979  1.10238379  1.5831649\n",
      "   1.48271996  1.55140728  1.62011263  1.8088569   1.61004439  1.18747296\n",
      "   1.2492021   0.91475632  1.058351    1.08043209  0.96753514  1.03492239\n",
      "   1.1912799   1.23380198  1.01639371  1.14616289  1.19165744  1.23423758\n",
      "   1.23606951  1.3997749   0.99544807  1.09847414  1.1725922   1.2122406\n",
      "   1.28015603  1.44277126  1.01422789  1.14123178  1.1460335   1.18159787\n",
      "   1.22357057  1.36652187  1.20042636  1.47882279  1.15345677  1.31185363\n",
      "   1.23516939  1.20129012  1.48062922  1.1847594   1.40207219  1.32969194\n",
      "   1.15025708  1.53136951  1.25175193  1.12778597  1.12004134  0.91475632]]\n",
      "Time for backward: 14.0240192413\n"
     ]
    }
   ],
   "source": [
    "x = ConvRBM(4, 10, 1)\n",
    "x.initializePWMs()\n",
    "\n",
    "testSeq = allSeqs[7190]\n",
    "startForward = time.time()\n",
    "h = x.forwardPass(testSeq.seq)\n",
    "print \"Time for forward: \" + str((time.time()-startForward)*1000)\n",
    "startBackward = time.time()\n",
    "x.backwardPass(h)\n",
    "print \"Time for backward: \" + str((time.time()-startBackward)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the JASPAR data and see whether the sequences can be reproduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of JASPAR matrices: 593\n",
      "Average motif length (k-mer length): 10.7993254637\n",
      "\n",
      "Number of motifs with length 6 : 37\n",
      "Verfication: 6.0\n",
      "average correct: 29.037\n",
      "average error: 120.963\n",
      "var of error: 223.937631\n",
      "average time for forward and backward pass (in ms): 0.833179235458\n"
     ]
    }
   ],
   "source": [
    "l = 6\n",
    "numMats = len(pwms)\n",
    "avgLength = np.mean([len(x[0]) for x in pwms])\n",
    "matsOfSpecificLength = [x for x in pwms if len(x[0]) == l]\n",
    "avgRedLength = np.mean([len(x[0]) for x in matsOfSpecificLength])\n",
    "print \"Total number of JASPAR matrices: \" + str(numMats)\n",
    "print \"Average motif length (k-mer length): \" + str(avgLength)\n",
    "print\n",
    "print \"Number of motifs with length \" + str(l) + \" : \" + str(len(matsOfSpecificLength))\n",
    "print \"Verfication: \" + str(avgRedLength)\n",
    "\n",
    "cRBM = ConvRBM(11, len(matsOfSpecificLength))\n",
    "cRBM.bias = np.zeros(len(matsOfSpecificLength))\n",
    "cRBM.c = 0\n",
    "# insert our pwms\n",
    "cRBM.motifs = matsOfSpecificLength\n",
    "\n",
    "# perform forward and backward pass\n",
    "correct = []\n",
    "errors = []\n",
    "times = []\n",
    "for i in range(1000):\n",
    "    testSeq = allSeqs[random.randrange(0, len(allSeqs))].seq\n",
    "    start = time.time()\n",
    "    hiddenActivation = learner.forwardPass(testSeq)\n",
    "    restored = learner.backwardPass(hiddenActivation)\n",
    "    times.append(time.time()-start)\n",
    "    \n",
    "    # count the differences between the two sequences\n",
    "    differences = 0\n",
    "    for elem in range(len(string)):\n",
    "        if string[elem] != testSeq[elem]:\n",
    "            differences += 1\n",
    "\n",
    "    #print \"Correct: \" + str(len(string)-differences)\n",
    "    #print \"Errors: \" + str(differences)\n",
    "    correct.append(len(string)-differences)\n",
    "    errors.append(differences)\n",
    "    \n",
    "print \"average correct: \" + str(np.mean(correct))\n",
    "print \"average error: \" + str(np.mean(errors))\n",
    "print \"var of error: \" + str(np.var(errors))\n",
    "print \"average time for forward and backward pass (in ms): \" + str(np.mean(times)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the forward and backward pass do anything meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15859031  0.20731707  0.26315789  0.25748503  0.38125     0.20588235]\n",
      " [ 0.34801762  0.22560976  0.07894737  0.20658683  0.46875     0.25490196]\n",
      " [ 0.37885463  0.27439024  0.26315789  0.2754491   0.1         0.12254902]\n",
      " [ 0.11453744  0.29268293  0.39473684  0.26047904  0.05        0.41666667]]\n",
      "Restored:\n",
      "['A', 'A', 'G', 'T', 'T', 'G', 'C', 'T', 'G', 'C', 'T', 'T', 'C', 'T', 'T', 'T', 'G', 'C', 'T', 'G']\n",
      "\n",
      "Original:\n",
      "TTTATCCTGCAGCTCGCCTG\n",
      "Now the real implementation:\n",
      "Restored:\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A']\n"
     ]
    }
   ],
   "source": [
    "learner = ConvRBM(6, 1)\n",
    "learner.initializePWMs()\n",
    "\n",
    "hiddenActivation = learner.forwardPass(allSeqs[246].seq)\n",
    "restoredLength = hiddenActivation.shape[1] + learner.motifLength - 1\n",
    "reConv = np.zeros((len(learner.alphabet.letters), restoredLength))\n",
    "matrix = learner._convertPWM2Array(learner.motifs[0])\n",
    "print matrix\n",
    "for i in range(len(learner.alphabet.letters)):\n",
    "    reConv[i,:] = np.convolve(hiddenActivation[0], matrix[i])\n",
    "    \n",
    "#print reConv\n",
    "\n",
    "def softmaxActivation(col, idx):\n",
    "    p_all = np.sum(np.exp(col))\n",
    "    p_x = np.exp(col[idx])\n",
    "    return p_x / p_all\n",
    "\n",
    "visibleActivation = np.zeros((1, 150))\n",
    "for i in range(150):\n",
    "    visibleActivation[0,i] = np.argmax([softmaxActivation(reConv[:,i], x) for x in range(4)])\n",
    "    \n",
    "def convertNumericalToLetter(seq):\n",
    "    dna_seq = []\n",
    "    for num in range(seq.shape[1]):\n",
    "        dna_seq.append(learner._getLetterToInt(seq[0,num]))\n",
    "    return dna_seq\n",
    "\n",
    "print \"Restored:\"\n",
    "print convertNumericalToLetter(visibleActivation)[:20]\n",
    "print\n",
    "print \"Original:\"\n",
    "print allSeqs[246].seq[:20]\n",
    "\n",
    "print \"Now the real implementation:\"\n",
    "print \"Restored:\"\n",
    "print learner.backwardPass(hiddenActivation)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the forward pass on the whole set of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 1.97112977416\n",
      "5000 -> 0.0\n",
      "10000 -> 0.0\n",
      "15000 -> 0.0\n",
      "20000 -> 0.0\n",
      "25000 -> 0.0\n",
      "30000 -> 3.55622096338\n",
      "35000 -> 1.45209852838\n",
      "40000 -> 0.0\n",
      "45000 -> 0.0\n",
      "50000 -> 29.8636840454\n",
      "55000 -> 0.0\n",
      "60000 -> 1.19763432774\n",
      "65000 -> 0.0\n",
      "70000 -> 10.3491168534\n",
      "75000 -> 7.82986486681\n",
      "80000 -> 9.85699920243\n",
      "85000 -> 3.7478067675\n",
      "90000 -> 0.0\n",
      "95000 -> 1.76197531167\n",
      "100000 -> 0.0\n",
      "105000 -> 20.3408063244\n",
      "110000 -> 4.61055759714\n",
      "115000 -> 9.64909205092\n",
      "120000 -> 2.14293706454\n",
      "125000 -> 0.0\n",
      "130000 -> 1.22137467903\n",
      "135000 -> 0.0\n",
      "140000 -> 0.0\n",
      "145000 -> 0.0\n",
      "150000 -> 1.53264213495\n",
      "155000 -> 0.0\n",
      "160000 -> 10.960086437\n",
      "165000 -> 11.8790462602\n",
      "170000 -> 7.42613369813\n",
      "\n",
      "\n",
      "Number of filters: 1\n",
      "Number of DHSs: 171275\n",
      "Average Length of Sequences: 150.0\n",
      "Execution Time: 67.5745389462\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "i = 0\n",
    "lengthes = []\n",
    "someScores = []\n",
    "for seq in allSeqs:\n",
    "    convoluted = learner.forwardPass(seq.seq)\n",
    "    lengthes.append(len(seq))\n",
    "    if i % 5000 == 0:\n",
    "        someScores.append(convoluted[0][random.randint(0, len(convoluted))])\n",
    "        print str(i) + \" -> \" + str(someScores[-1])\n",
    "    i += 1\n",
    "    \n",
    "print\n",
    "print\n",
    "print \"Number of filters: \" + str(learner.numMotifs)\n",
    "print \"Number of DHSs: \" + str(i)\n",
    "print \"Average Length of Sequences: \" + str(np.array(lengthes).mean())\n",
    "print \"Execution Time: \" + str(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test both passes on all sequences using parallelization (just CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVAILABLE CPUs: 4\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5c582c38f323>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"AVAILABLE CPUs: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msizePerCPU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallSeqs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0msublists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-09-11/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         self._worker_handler = threading.Thread(\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-09-11/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Process'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PoolWorker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'added worker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-09-11/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mforking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0m_current_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/package/ddbtools/python2/2015-09-11/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'random'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "\n",
    "def calculatePassesForSeqs(seqs):\n",
    "    print \"Started thread with \" + str(len(seqs)) + \" Sequences!\"\n",
    "    lengthes = []\n",
    "    for seq in seqs:\n",
    "        hiddenActivation = learner.forwardPass(seq.seq)\n",
    "        reconstruction = learner.backwardPass(hiddenActivation)\n",
    "        lengthes.append(len(seq))\n",
    "    return np.mean(lengthes)\n",
    "\n",
    "\n",
    "cpu_count = 4\n",
    "print \"AVAILABLE CPUs: \" + str(cpu_count)\n",
    "sizePerCPU = len(allSeqs) / cpu_count\n",
    "p = Pool(processes = cpu_count)\n",
    "sublists = []\n",
    "for i in range(cpu_count):\n",
    "    if not i == cpu_count-1:\n",
    "        sublists.append(allSeqs[i*sizePerCPU:(i+1)*sizePerCPU])\n",
    "    else:\n",
    "        sublists.append(allSeqs[i*sizePerCPU:])\n",
    "start = time.time()\n",
    "result = p.map(calculatePassesForSeqs, sublists)\n",
    "print result\n",
    "print\n",
    "print\n",
    "print \"Number of filters: \" + str(learner.numMotifs)\n",
    "print \"Number of DHSs: \" + str(len(allSeqs))\n",
    "print \"Execution Time: \" + str(time.time()-start)\n",
    "\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3fd54ce79a77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tests to learn how to do things with Biopython and Theano\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do all DHS sequences have the same length by default?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 171275\n",
      "Number of seqs with length != 150: 0\n"
     ]
    }
   ],
   "source": [
    "fasta_seqs = sio.parse(open('../data/wgEncodeAwgDnaseUwAg10803UniPk.fa'), 'fasta')\n",
    "count = 0\n",
    "countNotSameLength = 0\n",
    "for seq in fasta_seqs:\n",
    "    if len(seq) != 150:\n",
    "        print 'not length 150'\n",
    "        countNotSameLength += 1\n",
    "    count += 1\n",
    "\n",
    "print 'Number of sequences: ' + str(count)\n",
    "print 'Number of seqs with length != 150: ' + str(countNotSameLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we generate random motif matrices (PWMs or PSSMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Bio.NeuralNetwork.Gene.Schema as schema\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGCGAT\n",
      "CGTGACCA\n",
      "GTACACCGA\n"
     ]
    }
   ],
   "source": [
    "alphabet = IUPAC.unambiguous_dna\n",
    "generator = schema.RandomMotifGenerator(alphabet, 6, 10)\n",
    "for i in range(3):\n",
    "    x = generator.random_motif()\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphabet.letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Bio.motifs.matrix as mat\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createRandomMotif (motifLength, alphabet):\n",
    "    counts = {}\n",
    "    for letter in alphabet.letters:\n",
    "        counts[letter] = [random.randint(0,100) for x in xrange(motifLength)]\n",
    "    return mat.PositionWeightMatrix(alphabet, counts)\n",
    "#x = mat.PositionWeightMatrix(alphabet, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1      2      3      4      5      6      7      8      9\n",
      "A:   0.24   0.18   0.19   0.25   0.41   0.47   0.09   0.07   0.21   0.29\n",
      "C:   0.28   0.26   0.16   0.42   0.13   0.24   0.39   0.49   0.16   0.38\n",
      "G:   0.20   0.24   0.22   0.00   0.14   0.15   0.46   0.43   0.63   0.18\n",
      "T:   0.29   0.32   0.43   0.32   0.32   0.14   0.06   0.02   0.00   0.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = createRandomMotif(10, alphabet)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.24,  0.18,  0.19,  0.25,  0.41,  0.47,  0.09,  0.07,  0.21,\n",
       "         0.29],\n",
       "       [ 0.28,  0.26,  0.16,  0.42,  0.13,  0.24,  0.39,  0.49,  0.16,\n",
       "         0.38],\n",
       "       [ 0.2 ,  0.24,  0.22,  0.  ,  0.14,  0.15,  0.46,  0.43,  0.63,\n",
       "         0.18],\n",
       "       [ 0.29,  0.32,  0.43,  0.32,  0.32,  0.14,  0.06,  0.02,  0.  ,\n",
       "         0.14]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((len(alphabet.letters), 10))\n",
    "\n",
    "def getLetterToInt (num):\n",
    "    if num == 0:\n",
    "        return 'A'\n",
    "    elif num == 1:\n",
    "        return 'C'\n",
    "    elif num == 2:\n",
    "        return 'G'\n",
    "    elif num == 3:\n",
    "        return 'T'\n",
    "    else:\n",
    "        print 'ERROR: Num ' + str(num) + \" not a valid char in DNA alphabet\"\n",
    "        return -1\n",
    "\n",
    "\n",
    "for letter in range(len(x)):\n",
    "    print letter\n",
    "    y[letter] = x[getLetterToInt(letter)]\n",
    "    letterCount += 1\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the elements of a PWM interpretable as probabilites?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 1.0\n",
      "1 -> 1.0\n",
      "2 -> 1.0\n",
      "3 -> 1.0\n",
      "4 -> 1.0\n",
      "5 -> 1.0\n",
      "6 -> 1.0\n",
      "7 -> 1.0\n",
      "8 -> 1.0\n",
      "9 -> 1.0\n"
     ]
    }
   ],
   "source": [
    "# verify that we're dealing with probabilities by summing up over all letters for each position\n",
    "for pos in range(x.length):\n",
    "    c = 0\n",
    "    for letter in alphabet.letters:\n",
    "        c += x[letter][pos]\n",
    "    print str(pos) + \" -> \" + str(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

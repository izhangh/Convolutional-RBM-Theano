{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional RBM on the GPU (cRBM)\n",
    "In this notebook, a general implementation of the convolutional Restricted Boltzmann Machine is given.\n",
    "The code focusses on speed on GPUs (graphics cards) and therefore, the relevant parts are written in Theano.\n",
    "\n",
    "The first parts of the notebook provide methods to read in the DNA sequences while the actual training algorithm is given in section 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Importing all relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.0: cannot open shared object file: No such file or directory\n",
      "ERROR:theano.sandbox.cuda:Failed to compile cuda_ndarray.cu: libcublas.so.7.0: cannot open shared object file: No such file or directory\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n",
      "WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Theano imports\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet.conv as conv\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RS\n",
    "from theano import pp\n",
    "\n",
    "# numpy and python classics\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import cPickle\n",
    "\n",
    "# biopython stuff\n",
    "import Bio.SeqIO as sio\n",
    "import Bio.motifs.matrix as mat\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading the data and converting it to various forms of matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes to read biological files (such as FASTA or JASPAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This class reads sequences from fasta files.\n",
    "To use it, create an instance of that object and use\n",
    "the function readSequencesFromFile.\n",
    "\"\"\"\n",
    "class FASTAReader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        dhsSequences = []\n",
    "        for dhs in sio.parse(open(filename), 'fasta', IUPAC.unambiguous_dna):\n",
    "            dhsSequences.append(dhs.seq)\n",
    "        return dhsSequences\n",
    "    \n",
    "    \n",
    "class JASPARReader:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        pass\n",
    "    \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        matrices = []\n",
    "        for mat in motifs.parse(open(filename), 'jaspar'):\n",
    "            matrices.append(mat.pwm)\n",
    "        return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading that information to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matReader = JASPARReader()\n",
    "pwms = matReader.readSequencesFromFile('../data/jaspar_matrices.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqReader = FASTAReader()\n",
    "allSeqs = seqReader.readSequencesFromFile('../data/wgEncodeAwgDnaseUwAg10803UniPk.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the DNA sequences to matrices\n",
    "Each DNA sequence is transformed into a 4 x seqLength dimensional matrix. That way, each row represents one of the four letters in the genomic alphabet and in every column, exactly one of the four equals one, while the rest is set to zero.\n",
    "\n",
    "\n",
    "\n",
    "#### So, the sequence **ACGTGGGG** would look like this:\n",
    "| Letter | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n",
    "|--|------------------------------|\n",
    "| A | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| C | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| G | 0 | 0 | 1 | 0 | 1 | 1 | 1 | 1 |\n",
    "| T | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getIntToLetter (letter):\n",
    "    if letter == 'A' or letter == 'a':\n",
    "        return 0\n",
    "    elif letter == 'C' or letter == 'c':\n",
    "        return 1\n",
    "    elif letter == 'G' or letter == 'g':\n",
    "        return 2\n",
    "    elif letter == 'T' or letter == 't':\n",
    "        return 3\n",
    "    else:\n",
    "        print \"ERROR. LETTER \" + letter + \" DOES NOT EXIST!\"\n",
    "        return -1\n",
    "\n",
    "def getMatrixFromSeq (seq):\n",
    "    m = len(seq.alphabet.letters)\n",
    "    n = len(seq)\n",
    "    result = np.zeros((1, m, n), dtype=np.float32)\n",
    "    revSeq = seq.reverse_complement()\n",
    "    for i in range(len(seq)):\n",
    "        result[0,getIntToLetter(seq[i]),i] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 15000\n",
      "Test set size: 5000\n",
      "Conversion of test set in (in ms): 2959.2499733\n"
     ]
    }
   ],
   "source": [
    "data = [allSeqs[random.randrange(0,len(allSeqs))] for i in range(20000)]\n",
    "train_set, test_set = train_test_split(data, test_size=0.25)\n",
    "print \"Training set size: \" + str(len(train_set))\n",
    "print \"Test set size: \" + str(len(test_set))\n",
    "\n",
    "start = time.time()\n",
    "trainingData = np.array([getMatrixFromSeq(t) for t in train_set])\n",
    "testingData = np.array([getMatrixFromSeq(t) for t in test_set])\n",
    "print \"Conversion of test set in (in ms): \" + str((time.time()-start)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Borrowing Ian Goodfellow's implementation of the probabilistic max pooling layer\n",
    "This implementation is now part of the pylearn2 library which is licensed under the 3-claused BSD license.\n",
    "Source code is available here: https://github.com/lisa-lab/pylearn2/blob/master/pylearn2/expr/probabilistic_max_pooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from theano.gof.op import get_debug_values\n",
    "\n",
    "def max_pool(z, pool_shape, top_down=None, theano_rng=None):\n",
    "    \"\"\"\n",
    "    Probabilistic max-pooling\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : theano 4-tensor\n",
    "        a theano 4-tensor representing input from below\n",
    "    pool_shape : tuple\n",
    "        tuple of ints. the shape of regions to be pooled\n",
    "    top_down : theano 4-tensor, optional\n",
    "        a theano 4-tensor representing input from above\n",
    "        if None, assumes top-down input is 0\n",
    "    theano_rng : MRG_RandomStreams, optional\n",
    "        Used for random numbers for sampling\n",
    "    Returns\n",
    "    -------\n",
    "    p : theano 4-tensor\n",
    "        the expected value of the pooling layer p\n",
    "    h : theano 4-tensor\n",
    "        the expected value of the detector layer h\n",
    "    p_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the pooling layer\n",
    "    h_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the detector layer\n",
    "    Notes\n",
    "    ------\n",
    "    all 4-tensors are formatted with axes ('b', 'c', 0, 1).\n",
    "    This is for maximum speed when using theano's conv2d\n",
    "    to generate z and top_down, or when using it to infer conditionals of\n",
    "    other layers using the return values.\n",
    "    Detailed description:\n",
    "    Suppose you have a variable h that lives in a Conv2DSpace h_space and\n",
    "    you want to pool it down to a variable p that lives in a smaller\n",
    "    Conv2DSpace p.\n",
    "    This function does that, using non-overlapping pools.\n",
    "    Specifically, consider one channel of h. h must have a height that is a\n",
    "    multiple of pool_shape[0] and a width that is a multiple of pool_shape[1].\n",
    "    A channel of h can thus be broken down into non-overlapping rectangles\n",
    "    of shape pool_shape.\n",
    "    Now consider one rectangular pooled region within one channel of h.\n",
    "    I now use 'h' to refer just to this rectangle, and 'p' to refer to\n",
    "    just the one pooling unit associated with that rectangle.\n",
    "    We assume that the space that h and p live in is constrained such\n",
    "    that h and p are both binary and p = max(h). To reduce the state-space\n",
    "    in order to make probabilistic computations cheaper we also\n",
    "    constrain sum(h) <= 1.\n",
    "    Suppose h contains k different units. Suppose that the only term\n",
    "    in the model's energy function involving h is -(z*h).sum()\n",
    "    (elemwise multiplication) and the only term in\n",
    "    the model's energy function involving p is -(top_down*p).sum().\n",
    "    Then P(h[i] = 1) = softmax( [ z[1], z[2], ..., z[k], -top_down] )[i]\n",
    "    and P(p = 1) = 1-softmax( [z[1], z[2], ..., z[k], -top_down])[k]\n",
    "    This variation of the function assumes that z, top_down, and all\n",
    "    return values use Conv2D axes ('b', 'c', 0, 1).\n",
    "    This variation of the function implements the softmax using a\n",
    "    theano graph of exp, maximum, sub, and div operations.\n",
    "    \"\"\"\n",
    "\n",
    "    z_name = z.name\n",
    "    if z_name is None:\n",
    "        z_name = 'anon_z'\n",
    "\n",
    "    batch_size, ch, zr, zc = z.shape\n",
    "\n",
    "    r, c = pool_shape\n",
    "\n",
    "    zpart = []\n",
    "\n",
    "    mx = None\n",
    "\n",
    "    if top_down is None:\n",
    "        t = 0.\n",
    "    else:\n",
    "        t = - top_down\n",
    "        t.name = 'neg_top_down'\n",
    "\n",
    "    for i in xrange(r):\n",
    "        zpart.append([])\n",
    "        for j in xrange(c):\n",
    "            cur_part = z[:, :, i:zr:r, j:zc:c]\n",
    "            if z_name is not None:\n",
    "                cur_part.name = z_name + '[%d,%d]' % (i, j)\n",
    "            zpart[i].append(cur_part)\n",
    "            if mx is None:\n",
    "                mx = T.maximum(t, cur_part)\n",
    "                if cur_part.name is not None:\n",
    "                    mx.name = 'max(-top_down,' + cur_part.name + ')'\n",
    "            else:\n",
    "                max_name = None\n",
    "                if cur_part.name is not None:\n",
    "                    mx_name = 'max(' + cur_part.name + ',' + mx.name + ')'\n",
    "                mx = T.maximum(mx, cur_part)\n",
    "                mx.name = mx_name\n",
    "    mx.name = 'local_max(' + z_name + ')'\n",
    "\n",
    "    pt = []\n",
    "\n",
    "    for i in xrange(r):\n",
    "        pt.append([])\n",
    "        for j in xrange(c):\n",
    "            z_ij = zpart[i][j]\n",
    "            safe = z_ij - mx\n",
    "            safe.name = 'safe_z(%s)' % z_ij.name\n",
    "            cur_pt = T.exp(safe)\n",
    "            cur_pt.name = 'pt(%s)' % z_ij.name\n",
    "            pt[-1].append(cur_pt)\n",
    "\n",
    "    off_pt = T.exp(t - mx)\n",
    "    off_pt.name = 'p_tilde_off(%s)' % z_name\n",
    "    denom = off_pt\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            denom = denom + pt[i][j]\n",
    "    denom.name = 'denom(%s)' % z_name\n",
    "\n",
    "    off_prob = off_pt / denom\n",
    "    p = 1. - off_prob\n",
    "    p.name = 'p(%s)' % z_name\n",
    "\n",
    "    hpart = []\n",
    "    for i in xrange(r):\n",
    "        hpart.append([pt_ij / denom for pt_ij in pt[i]])\n",
    "\n",
    "    h = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            h.name = 'h_interm'\n",
    "            h = T.set_subtensor(h[:, :, i:zr:r, j:zc:c], hpart[i][j])\n",
    "\n",
    "    h.name = 'h(%s)' % z_name\n",
    "\n",
    "    if theano_rng is None:\n",
    "        return p, h\n",
    "    \n",
    "    ### --------------------- DONE IF NO SAMPLES ARE GENERATED ---------------------------###\n",
    "    else:\n",
    "        events = []\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                events.append(hpart[i][j])\n",
    "        events.append(off_prob)\n",
    "\n",
    "        events = [event.dimshuffle(0, 1, 2, 3, 'x') for event in events]\n",
    "\n",
    "        events = tuple(events)\n",
    "\n",
    "        stacked_events = T.concatenate(events, axis=4)\n",
    "\n",
    "        rows = zr // pool_shape[0]\n",
    "        cols = zc // pool_shape[1]\n",
    "        outcomes = pool_shape[0] * pool_shape[1] + 1\n",
    "        assert stacked_events.ndim == 5\n",
    "        for se, bs, r, c, chv in get_debug_values(stacked_events, batch_size,\n",
    "                                                  rows, cols, ch):\n",
    "            assert se.shape[0] == bs\n",
    "            assert se.shape[1] == r\n",
    "            assert se.shape[2] == c\n",
    "            assert se.shape[3] == chv\n",
    "            assert se.shape[4] == outcomes\n",
    "        reshaped_events = stacked_events.reshape((\n",
    "            batch_size * rows * cols * ch, outcomes))\n",
    "\n",
    "        multinomial = theano_rng.multinomial(pvals=reshaped_events,\n",
    "                                             dtype=p.dtype)\n",
    "\n",
    "        reshaped_multinomial = multinomial.reshape((batch_size, ch, rows,\n",
    "                                                    cols, outcomes))\n",
    "\n",
    "        h_sample = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "        idx = 0\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                h_sample = T.set_subtensor(h_sample[:, :, i:zr:r, j:zc:c],\n",
    "                                           reshaped_multinomial[:, :, :, :,\n",
    "                                           idx])\n",
    "                idx += 1\n",
    "\n",
    "        p_sample = 1 - reshaped_multinomial[:, :, :, :, -1]\n",
    "\n",
    "        return p, h, p_sample, h_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: The implementation of a convolutional RBM on the GPU\n",
    "And finally, here it is. A class that lets us train a cRBM on the GPU.\n",
    "The algorithm should feature various variantes of the classical learning algorithms such as:\n",
    "\n",
    "* Persistent Contrastive Divergence\n",
    "* Dropout to enforce sparsity\n",
    "* **Probabilistic Max-Pooling units in the hidden layer**\n",
    "* Regularization\n",
    "* Stochastic Gradient Descent with momentum & Simulated Annealing\n",
    "\n",
    "However, only the procedures printed in **bold** are allready functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of observer objects that track the process of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainingObserver:\n",
    "\n",
    "    def __init__ (self, _model, _data):\n",
    "        self.model = _model\n",
    "        self.data = _data\n",
    "        print \"data shape: \" + str(_data.shape)\n",
    "        self.batchSize = np.min([_data.shape[0], 1000])\n",
    "        self.scores = []\n",
    "        self.scoringFunction = self.getScoringFunction()\n",
    "\n",
    "    def calculateScore (self):\n",
    "        raise NotImplementedError(\"Abstract class not callable\")\n",
    "\n",
    "    def getScoringFunction (self):\n",
    "        raise NotImplementedError(\"Abstract class not callable\")\n",
    "\n",
    "\n",
    "class FreeEnergyObserver (TrainingObserver):\n",
    "\n",
    "    def __init__ (self, _model, _data):\n",
    "        TrainingObserver.__init__(self, _model, _data)\n",
    "\n",
    "    def calculateScore (self):\n",
    "        iterations = self.data.shape[0] / self.batchSize\n",
    "        sumOfScores = 0\n",
    "        for batchIdx in xrange(iterations):\n",
    "            sumOfScores += self.scoringFunction(batchIdx)\n",
    "        score = sumOfScores / iterations # mean\n",
    "        self.scores.append(score)\n",
    "        return score\n",
    "\n",
    "    def getScoringFunction(self):\n",
    "        dataS = theano.shared(value=self.data, borrow=True, name='data')\n",
    "\n",
    "        D = T.tensor4('data')\n",
    "        index = T.lscalar()\n",
    "        score = self.getFreeEnergy(D)\n",
    "        scoringFun = theano.function([index],\n",
    "                     score,\n",
    "                     allow_input_downcast=True,\n",
    "                     givens={D: dataS[index*self.batchSize:(index+1)*self.batchSize]},\n",
    "                     name='freeEnergyObservation'\n",
    "        )\n",
    "        return scoringFun\n",
    "\n",
    "\n",
    "    def getFreeEnergy (self, D):\n",
    "        # firstly, compute hidden part of free energy\n",
    "        C = conv.conv2d(D, self.model.motifs)\n",
    "        bMod = self.model.bias # to prevent member from being shuffled\n",
    "        bMod = bMod.dimshuffle('x', 1, 0, 'x') # add dims to the bias on both sides\n",
    "\n",
    "        C = C + bMod\n",
    "        hiddenPart = T.sum(T.log(1. + T.exp(C)), axis=1) # dim: N_batch x 1 x N_h after sum over K\n",
    "        hiddenPart = T.sum(T.mean(hiddenPart, axis=0)) # mean over all samples and sum over units\n",
    "\n",
    "        # compute the visible part\n",
    "        cMod = self.model.c\n",
    "        cMod = cMod.dimshuffle('x', 0, 1, 'x') # make it 4D and broadcastable there\n",
    "        visiblePart = T.mean(D * cMod, axis=0) # dim: 1 x 4 x N_v\n",
    "        visiblePart = T.sum(visiblePart)\n",
    "\n",
    "        free_energy = hiddenPart + visiblePart # don't return the negative because it's more difficult to plot\n",
    "\n",
    "        return free_energy\n",
    "\n",
    "\n",
    "class ReconstructionErrorObserver (TrainingObserver):\n",
    "\n",
    "    def __init__(self, _model, _data):\n",
    "        TrainingObserver.__init__(self, _model, _data)\n",
    "\n",
    "\n",
    "    def calculateScore (self):\n",
    "        iterations = self.data.shape[0] / self.batchSize\n",
    "        sumOfScores = 0\n",
    "        for batchIdx in xrange(iterations):\n",
    "            sumOfScores += self.scoringFunction(batchIdx)\n",
    "        count = sumOfScores / iterations # mean\n",
    "\n",
    "        # got the count of correct letters for all seqs\n",
    "        # now, make it percentage of sequence (prob. to get all correct)\n",
    "        count /= self.data.shape[3]\n",
    "        error = 1 - count # how much error do we have\n",
    "\n",
    "        self.scores.append(error)\n",
    "        return error\n",
    "\n",
    "\n",
    "    def getScoringFunction(self):\n",
    "        dataS = theano.shared(value=self.data, borrow=True, name='data')\n",
    "\n",
    "        D = T.tensor4('data')\n",
    "        index = T.lscalar()\n",
    "        score = self.getReconstructionError(D)\n",
    "        scoringFun = theano.function([index],\n",
    "                     score,\n",
    "                     allow_input_downcast=True,\n",
    "                     givens={D: dataS[index*self.batchSize:(index+1)*self.batchSize]},\n",
    "                     name='ReconstructioinErrorObservation'\n",
    "        )\n",
    "        return scoringFun\n",
    "\n",
    "\n",
    "    def getReconstructionError (self, D):\n",
    "        [H, S_H] = self.model.forwardBatch(D)\n",
    "        V = self.model.backwardBatch(S_H)\n",
    "        S_V = self.model.sampleVisibleLayer(V)\n",
    "        sames = S_V * D # elements are 1 if they have the same letter...\n",
    "        count = T.sum(T.mean(sames, axis=0)) # mean over samples, sum over rest\n",
    "        return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PART 3: Optimizing theano to do it all on the GPU\n",
    "\n",
    "\"\"\"\n",
    "This is the actual implementation of our convolutional RBM.\n",
    "The class implements only contrastive divergence learning so far\n",
    "but the number of runs for Gibbs Sampling can be varied.\n",
    "Furthermore, the beforementioned implementation of probabilistic max pooling\n",
    "computes probabilities for and samples of the hidden layer distribution.\n",
    "\"\"\"\n",
    "class CRBM:\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize the cRBM. The parameters here are global params that should not change\n",
    "    during the execution of training or testing and characterize the network.\n",
    "    \n",
    "    Parameters:\n",
    "    _motifLength:    How long are the motifs (position weight matrices PWM). This\n",
    "                     This is equivalent to ask what the number of k-mers is.\n",
    "                     The current approach only deals with one fixed motif length.\n",
    "                     \n",
    "    _numMotifs:      How many motifs are applied to the sequence, that is how many\n",
    "                     hidden units does the network have. Each hidden unit consists\n",
    "                     of a vector of size (sequenceLength-motifLength+1)\n",
    "                     \n",
    "    _poolingFactor:  How many units from the hidden layer are pooled together.\n",
    "                     Note that the number has to divide evenly to the length of\n",
    "                     the hidden units, that is:\n",
    "                     mod(sequenceLength-motifLength+1, poolingFactor) == 0\n",
    "                     (1 = equivalent to sigmoid activation)\n",
    "    \"\"\"\n",
    "    def __init__ (self, _motifLength, _numMotifs, _learningRate=0.1, _poolingFactor=1):\n",
    "        # parameters for the motifs\n",
    "        self.motifLength = _motifLength\n",
    "        self.numMotifs = _numMotifs\n",
    "        self.initializeMotifs()\n",
    "        \n",
    "        # cRBM parameters (2*x to respect both strands of the DNA)\n",
    "        b = np.random.rand(1, 2*self.numMotifs).astype(np.float32)\n",
    "        c = np.random.rand(1, 4).astype(np.float32)\n",
    "        self.bias = theano.shared(value=b, name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=c, name='c', borrow=True)\n",
    "        self.poolingFactor = _poolingFactor\n",
    "        self.learningRate = _learningRate\n",
    "        \n",
    "        # infrastructural parameters\n",
    "        self.theano_rng = RS(seed=1234)\n",
    "        self.params = [self.motifs, self.bias, self.c]\n",
    "        self.debug = True\n",
    "        self.observers = []\n",
    "    \n",
    "    \n",
    "    def initializeMotifs (self):\n",
    "        # create random motifs (2*self.numMotifs to respect both strands)\n",
    "        x = np.random.rand(2 * self.numMotifs, 1, 4, self.motifLength).astype(np.float32)\n",
    "        \n",
    "        # create reverse complement\n",
    "        for i in range(0, 2*self.numMotifs, 2):\n",
    "            x[i+1] = x[i,:,::-1,::-1]\n",
    "            \n",
    "        self.motifs = theano.shared(value=x, name='W', borrow=True)\n",
    "        \n",
    "        \n",
    "    def setCustomKernels (self, customKernels):\n",
    "        if len(customKernels.shape) != 4 or customKernels.shape[1] != 1:\n",
    "            print \"New motifs must be a 4D matrix with dims: (K x 1 x numOfLetters(4) x numOfKMers)\"\n",
    "            return\n",
    "        \n",
    "        self.numMotifs = (customKernels.shape[0] / 2)\n",
    "        self.motifLength = customKernels.shape[3]\n",
    "        #b = np.random.rand(1, self.numMotifs).astype(np.float32)\n",
    "        \n",
    "        if self.debug:\n",
    "            b = np.zeros((1, 2*self.numMotifs)).astype(np.float32)\n",
    "            c = np.zeros((1, 4)).astype(np.float32)\n",
    "        else:\n",
    "            b = np.random.rand(1, 2*self.numMotifs).astype(np.float32)\n",
    "            c = np.random.rand(1, 4).astype(np.float32)\n",
    "\n",
    "        self.bias = theano.shared(value=b, name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=c, name='c', borrow=True)\n",
    "        \n",
    "        self.motifs = theano.shared(value=customKernels.astype(np.float32))\n",
    "        self.params = [self.motifs, self.bias, self.c]\n",
    "        print \"New motifs set. # Motifs: \" + str(self.numMotifs) + \" K-mer-Length: \" + str(self.motifLength)\n",
    "\n",
    "    def addObserver (self, _observer):\n",
    "        self.observers.append(_observer)\n",
    "        \n",
    "        \n",
    "    def saveModel (self, _filename):\n",
    "        numpyParams = []\n",
    "        for param in self.params:\n",
    "            numpyParams.append(param.get_value())\n",
    "\n",
    "        with open(_filename, 'w') as f:\n",
    "            cPickle.dump(numpyParams, f)\n",
    "\n",
    "    def loadModel (self, filename):\n",
    "        numpyParams = []\n",
    "        with open(filename, 'r') as f:\n",
    "            numpyParams = cPickle.load(f)\n",
    "\n",
    "        if numpyParams == []:\n",
    "            raise IOError(\"Something went wrong loading the model!\")\n",
    "        motifs, bias, c = numpyParams\n",
    "        self.motifs = theano.shared(value=motifs, name='W', borrow=True)\n",
    "        self.bias = theano.shared(value=bias, name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=c, name='c', borrow=True)\n",
    "\n",
    "        self.params = [self.motifs, self.bias, self.c]\n",
    "        return\n",
    "    \n",
    "    \n",
    "### ------------------------------THE TOUGH STUFF-------------------------------- ###\n",
    "### ----------------------------------------------------------------------------- ###\n",
    "\n",
    "    def forwardBatch (self, data):\n",
    "        # calculate filter(D, W) + b\n",
    "        out = conv.conv2d(data, self.motifs[:,:,::-1,::-1]) #cross-correlation\n",
    "        if self.debug:\n",
    "            out = theano.printing.Print('Convolution result forward: ')(out)\n",
    "        bMod = self.bias\n",
    "        bMod = bMod.dimshuffle('x', 1, 0, 'x') # add dims to the bias until it works\n",
    "        out = out + bMod\n",
    "        \n",
    "        # perform prob. max pooling g(filter(D,W) + b) and sampling\n",
    "        pooled = max_pool(out.dimshuffle(0,2,1,3), pool_shape=(2, self.poolingFactor), theano_rng=self.theano_rng)\n",
    "        H = pooled[1].dimshuffle(0,2,1,3)\n",
    "        S = pooled[3].dimshuffle(0,2,1,3)\n",
    "        if self.debug:\n",
    "            H = theano.printing.Print('Hidden Probabilites: ')(H)\n",
    "            S = theano.printing.Print('prob max pooled layer: ')(S)\n",
    "        return [H,S] #only return pooled layer and probs\n",
    "\n",
    "\n",
    "    def backwardBatch (self, H_sample):\n",
    "        # dimshuffle the motifs to have K as channels (will be summed automatically)\n",
    "        W = self.motifs.dimshuffle(1, 0, 2, 3)[:,:,::-1,:] # needs that due to miraculous reasons\n",
    "        C = conv.conv2d(H_sample, W, border_mode='full')\n",
    "\n",
    "        if self.debug:\n",
    "            C = theano.printing.Print('Pre sigmoid visible layer: ')(C)\n",
    "        out = T.sum(C, axis=1, keepdims=True) # sum over all K\n",
    "        c_bc = self.c\n",
    "        c_bc = c_bc.dimshuffle('x', 0, 1, 'x')\n",
    "        out = out + c_bc\n",
    "        res = self.softmax(out)\n",
    "        return res\n",
    "\n",
    "        \n",
    "    def makeDerivativesStrandCompliant (self, derivatives):\n",
    "        # reshape such that even kernels form one matrix, while the uneven form the other\n",
    "        N_batch, K, letters, length = derivatives.shape\n",
    "        D_reshaped = derivatives.reshape((N_batch, K//2, 2, letters, length))\n",
    "        \n",
    "        # sum together the even and uneven ones and construct the reverse thing\n",
    "        D_summed = D_reshaped[:,:,0,:,:] + D_reshaped[:,:,1,:,:]\n",
    "        D_summed_reverse = D_summed[:,:,::-1,::-1] # just invert cols and rows of kernel\n",
    "        \n",
    "        # melt it all back together by first adding yet another dimension\n",
    "        D_restored = T.stack(D_summed, D_summed_reverse)\n",
    "        D_result = D_restored.dimshuffle(1, 2, 0, 3, 4).reshape((N_batch, K, letters, length))\n",
    "        \n",
    "        if self.debug:\n",
    "            D_result = theano.printing.Print('Derivatives strand compliant')(D_result)\n",
    "\n",
    "        return D_result\n",
    "        \n",
    "\n",
    "    def expectedDerivative (self, hiddenProbs, data):\n",
    "        \n",
    "        # new code to capture 1 <-> 1 relationship\n",
    "        #assert data.shape[0] == hiddenProbs.shape[0]\n",
    "        N_batch = data.shape[0]\n",
    "        result = T.zeros((N_batch, 2*self.numMotifs, 4, self.motifLength))\n",
    "        \n",
    "        for seq in range(self.batchSize):\n",
    "            d_i = data[seq,:,:,:].dimshuffle('x',0,1,2)\n",
    "            h_i = hiddenProbs[seq,:,:,:].dimshuffle(0,'x',1,2)\n",
    "            subT_result = result[seq,:,:,:]\n",
    "            localResult = conv.conv2d(d_i, h_i).sum(axis=0)\n",
    "            result = T.set_subtensor(subT_result, localResult)\n",
    "\n",
    "        # end of new code\n",
    "        \n",
    "        #mean = T.mean(hiddenProbs, axis=0, keepdims=True) # mean over H so only one mean datapoint\n",
    "        #H_reshaped = mean.dimshuffle(1, 0, 2, 3)\n",
    "        # TODO: Capture the 1 <-> 1 relation between samples in H and D\n",
    "        # Currently, this is done by mean (1st row) but that's not good at all\n",
    "        #out = conv.conv2d(data, H_reshaped)\n",
    "        \n",
    "        out = result\n",
    "        \n",
    "        # make the kernels respect the strand structure\n",
    "        #out = self.makeDerivativesStrandCompliant(out)\n",
    "        \n",
    "        der_Motifs = T.sum(out, axis=0, keepdims=True) / self.numMotifs # mean over training examples\n",
    "        der_Motifs = der_Motifs.dimshuffle(1, 0, 2, 3) # bring back to former shape\n",
    "        der_bias = T.mean(T.sum(hiddenProbs, axis=3), axis=0).dimshuffle(1,0)\n",
    "        der_c = T.mean(T.sum(data, axis=3), axis=0)\n",
    "        return (der_Motifs, der_bias, der_c)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def train_model (self, D, numOfCDs):\n",
    "        # calculate the data gradient for weights (motifs) and bias\n",
    "        [H_data, S_data] = self.forwardBatch(D)\n",
    "        if self.debug:\n",
    "            H_data = theano.printing.Print('Hidden Layer Probabilities: ')(H_data)\n",
    "        # calculate data gradients\n",
    "        G_motif_data, G_bias_data, G_c_data = self.expectedDerivative(H_data, D)\n",
    "        \n",
    "        if self.debug:\n",
    "            G_motif_data = theano.printing.Print('Gradient for motifs (data): ')(G_motif_data)\n",
    "        # calculate model probs\n",
    "        S_H = S_data\n",
    "        for i in range(numOfCDs):\n",
    "            V_model = self.backwardBatch(S_H)\n",
    "            S_V_model = self.sampleVisibleLayer(V_model)\n",
    "            [H_model, S_H] = self.forwardBatch(S_V_model)\n",
    "        \n",
    "        # compute the model gradients\n",
    "        G_motif_model, G_bias_model, G_c_model = self.expectedDerivative(H_model, D)\n",
    "        \n",
    "        if self.debug:\n",
    "            G_motif_model = theano.printing.Print('Gradient for motifs (model): ')(G_motif_model)\n",
    "        \n",
    "        # update the parameters\n",
    "        new_motifs = self.motifs + self.learningRate * (G_motif_data - G_motif_model)\n",
    "        new_bias = self.bias + self.learningRate * (G_bias_data - G_bias_model)\n",
    "        new_c = self.c + self.learningRate * (G_c_data - G_c_model)\n",
    "        \n",
    "        #score = self.getDataReconstruction(D)\n",
    "        updates = [(self.motifs, new_motifs), (self.bias, new_bias), (self.c, new_c)]\n",
    "\n",
    "        return updates\n",
    "    \n",
    "    \n",
    "    def trainMinibatch (self, trainData, testData, epochs, batchSize, numOfCDs):\n",
    "\n",
    "        # assert that pooling can be done without rest to the division\n",
    "        assert (((trainData.shape[3] - self.motifLength + 1) % self.poolingFactor) == 0)\n",
    "        assert (((testData.shape[3] - self.motifLength + 1) % self.poolingFactor) == 0)\n",
    "\n",
    "        self.batchSize = batchSize\n",
    "        # some debug printing\n",
    "        itPerEpoch = trainData.shape[0] / batchSize\n",
    "        print \"BatchSize: \" + str(batchSize)\n",
    "        print \"Num of iterations per epoch: \" + str(itPerEpoch)\n",
    "        start = time.time()\n",
    "\n",
    "        # compile training function\n",
    "        print \"Start compiling Theano training function...\"\n",
    "        train_set = theano.shared(value=trainData, borrow=True, name='trainData')\n",
    "        index = T.lscalar()\n",
    "        D = T.tensor4('data')\n",
    "        updates = self.train_model(D, numOfCDs)\n",
    "        trainingFun = theano.function(\n",
    "              [index],\n",
    "              None,\n",
    "              updates = updates,\n",
    "              allow_input_downcast=True,\n",
    "              givens={\n",
    "                D: train_set[index*batchSize:(index+1)*batchSize]\n",
    "              },\n",
    "              name='train_CRBM'\n",
    "        )\n",
    "        print \"Compilation of Theano training function finished in \" + str(time.time()-start) + \" seconds\"\n",
    "\n",
    "        # now perform training\n",
    "        print \"Start training the model...\"\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batchIdx in range(itPerEpoch):\n",
    "                trainingFun(batchIdx)\n",
    "            for obs in self.observers:\n",
    "                print \"Score of function: \" + str(obs.calculateScore())\n",
    "            print \"[Epoch \" + str(epoch) + \"] done!\"\n",
    "\n",
    "        # done with training\n",
    "        print \"Training finished after: \" + str(time.time()-start) + \" seconds!\"\n",
    "\n",
    "\n",
    "    def getReconFun (self):\n",
    "        D = T.tensor4('data')\n",
    "        score = self.getDataReconstruction(D)\n",
    "        return theano.function([D], score, allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "    def getDataReconstruction (self, D):\n",
    "        [H, S_H] = self.forwardBatch(D)\n",
    "        V = self.backwardBatch(S_H)\n",
    "        S_V = self.sampleVisibleLayer(V)\n",
    "        sames = S_V * D # elements are 1 if they have the same letter...\n",
    "        count = T.sum(T.mean(sames, axis=0)) # mean over samples, sum over rest\n",
    "        return count\n",
    "    \n",
    " \n",
    "    def getFreeEnergyFunction (self):\n",
    "        D = T.tensor4('data')\n",
    "        free_energy = self.calculateFreeEnergy(D)\n",
    "        return theano.function([D], free_energy, allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "    def calculateFreeEnergy (self, D):\n",
    "        # firstly, compute hidden part of free energy\n",
    "        C = conv.conv2d(D, self.motifs)\n",
    "        bMod = self.bias # to prevent member from being shuffled\n",
    "        bMod = bMod.dimshuffle('x', 1, 0, 'x') # add dims to the bias on both sides\n",
    "        C = C + bMod\n",
    "        hiddenPart = T.sum(T.log(1. + T.exp(C)), axis=1) # dim: N_batch x 1 x N_h after sum over K\n",
    "        hiddenPart = T.sum(T.mean(hiddenPart, axis=0)) # mean over all samples and sum over units\n",
    "        \n",
    "        # compute the visible part\n",
    "        cMod = self.c\n",
    "        cMod = cMod.dimshuffle('x', 0, 1, 'x') # make it 4D and broadcastable there\n",
    "        visiblePart = T.mean(D * cMod, axis=0) # dim: 1 x 4 x N_v\n",
    "        visiblePart = T.sum(visiblePart)\n",
    "        \n",
    "        return hiddenPart + visiblePart # don't return the negative because it's more difficult to plot\n",
    "        \n",
    "        \n",
    "    def sampleVisibleLayer (self, V):\n",
    "        reshaped = V.dimshuffle(0, 1, 3, 2).reshape((V.shape[0]*V.shape[3], V.shape[2]))\n",
    "        S_reshaped = self.theano_rng.multinomial(n=1,pvals=reshaped)\n",
    "        S = S_reshaped.reshape((V.shape[0], 1, V.shape[3], V.shape[2])).dimshuffle(0, 1, 3, 2)\n",
    "        S = S.astype('float32')\n",
    "        if self.debug:\n",
    "            S = theano.printing.Print('Visible Sample: ')(S)\n",
    "        return S\n",
    "    \n",
    "    def softmax (self, x):\n",
    "        return T.exp(x) / T.exp(x).sum(axis=2, keepdims=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4b: Create the theano functions neccessary for training (compile to C)\n",
    "Theano optimizes the function graph heavily when aiming for maximum performance. Thus, the package spends a long time setting up the whole system and not so much time with the actual training of the data.\n",
    "\n",
    "By generating the function in it's own cell, we can do training seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set some config parameters to make debugging simpler\n",
    "debug = True\n",
    "if debug:\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    theano.config.exception_verbosity='high'\n",
    "    theano.config.optimizer='None'\n",
    "    theano.config.compute_test_value='ignore'\n",
    "    theano.config.profile=True\n",
    "else:\n",
    "    theano.config.exception_verbosity='low'\n",
    "    theano.config.mode='FAST_RUN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our solution on toy data to verify correctness of calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: [[[[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]]]\n",
      "Data shape: (1, 1, 4, 8)\n",
      "New motifs set. # Motifs: 1 K-mer-Length: 3\n",
      "[[[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  1.  0.  1.  1.  1.  1.]\n",
      "   [ 0.  0.  0.  1.  0.  0.  0.  0.]]]]\n",
      "BatchSize: 1\n",
      "Num of iterations per epoch: 1\n",
      "Start compiling Theano training function...\n",
      "Compilation of Theano training function finished in 1.91754817963 seconds\n",
      "Start training the model...\n",
      "Convolution result forward:  __str__ = [[[[ 3.  0.  1.  1.  1.  1.]]\n",
      "\n",
      "  [[ 0.  3.  0.  1.  1.  1.]]]]\n",
      "prob max pooled layer:  __str__ = [[[[ 1.  0.  0.  1.  0.  1.]]\n",
      "\n",
      "  [[ 0.  1.  1.  0.  1.  0.]]]]\n",
      "Pre sigmoid visible layer:  __str__ = [[[[ 0.  0.  0.  1.  1.  0.  1.  0.]\n",
      "   [ 0.  0.  2.  1.  0.  2.  0.  1.]\n",
      "   [ 0.  2.  1.  0.  2.  0.  1.  0.]\n",
      "   [ 1.  0.  0.  1.  0.  1.  0.  0.]]]]\n",
      "Visible Sample:  __str__ = [[[[ 1.  1.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  1.  0.  1.  1.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "   [ 0.  0.  0.  1.  0.  0.  1.  0.]]]]\n",
      "Convolution result forward:  __str__ = [[[[ 1.  2.  0.  1.  1.  1.]]\n",
      "\n",
      "  [[ 0.  1.  1.  0.  2.  1.]]]]\n",
      "Hidden Probabilites:  __str__ = [[[[ 0.58  0.67  0.21  0.58  0.24  0.42]]\n",
      "\n",
      "  [[ 0.21  0.24  0.58  0.21  0.67  0.42]]]]\n",
      "Hidden Probabilites:  __str__ = [[[[ 0.91  0.05  0.58  0.42  0.42  0.42]]\n",
      "\n",
      "  [[ 0.05  0.91  0.21  0.42  0.42  0.42]]]]\n",
      "Hidden Layer Probabilities:  __str__ = [[[[ 0.91  0.05  0.58  0.42  0.42  0.42]]\n",
      "\n",
      "  [[ 0.05  0.91  0.21  0.42  0.42  0.42]]]]\n",
      "Gradient for motifs (data):  __str__ = [[[[ 0.42  0.    0.  ]\n",
      "   [ 0.42  0.42  0.  ]\n",
      "   [ 1.38  1.95  2.38]\n",
      "   [ 0.58  0.42  0.42]]]\n",
      "\n",
      "\n",
      " [[[ 0.42  0.    0.  ]\n",
      "   [ 0.42  0.42  0.  ]\n",
      "   [ 1.38  1.59  2.01]\n",
      "   [ 0.21  0.42  0.42]]]]\n",
      "Gradient for motifs (model):  __str__ = [[[[ 0.42  0.    0.  ]\n",
      "   [ 0.24  0.42  0.  ]\n",
      "   [ 1.82  1.7   2.45]\n",
      "   [ 0.21  0.58  0.24]]]\n",
      "\n",
      "\n",
      " [[[ 0.42  0.    0.  ]\n",
      "   [ 0.67  0.42  0.  ]\n",
      "   [ 0.67  1.7   1.67]\n",
      "   [ 0.58  0.21  0.67]]]]\n",
      "[Epoch 0] done!\n",
      "Training finished after: 0.00703692436218 seconds!\n",
      "Training (with compilation) performed in: 1.92582011223 seconds.\n",
      "Result from training: \n",
      "----------------------\n",
      "Learned Motif: \n",
      "[[[[ 1.    0.    0.  ]\n",
      "   [ 0.18  1.    0.  ]\n",
      "   [-0.44  0.26  0.92]\n",
      "   [ 0.36 -0.15  0.18]]]\n",
      "\n",
      "\n",
      " [[[ 0.    0.    0.  ]\n",
      "   [ 0.76  0.    0.  ]\n",
      "   [ 0.71  0.89  0.34]\n",
      "   [-0.36  0.21  0.76]]]]\n",
      "Learned Bias (b): \n",
      "[[ 0.1  0.1]]\n",
      "Learned Constant (c): \n",
      "[[ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8c2915d250>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEZCAYAAACuIuMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c2b49fb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theano.config.profile=True\n",
    "\n",
    "#initialize the learner and set custom kernels\n",
    "x = CRBM(5, 2, 1, 1)\n",
    "\n",
    "# design data\n",
    "#print \"Motifs:\"\n",
    "#print x.motifs.get_value()\n",
    "kernel1 = np.tile(np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,0]]), [1,1,1])\n",
    "kernel1_ = np.tile(np.flipud(np.fliplr(kernel1[0])),[1,1,1])\n",
    "kernel2 = np.tile(np.array([[0,0,0],[0,0,0],[1,1,1],[0,0,0]]), [1,1,1])\n",
    "kernel2_ = np.tile(np.flipud(np.fliplr(kernel2[0])), [1,1,1])\n",
    "kernel3 = np.random.rand(1,4,3)\n",
    "kernel3_ = np.tile(np.flipud(np.fliplr(kernel3[0])), [1,1,1])\n",
    "kernel = np.array([kernel1, kernel1_])#, kernel2, kernel2_, kernel3, kernel3_])\n",
    "#kernel = np.array([kernel3, kernel3_])\n",
    "print \"Kernel: \" + str(kernel)\n",
    "\n",
    "# initialize the data\n",
    "randSeq1 = getMatrixFromSeq(Seq(\"ACGTGGGG\", IUPAC.unambiguous_dna))\n",
    "randSeq2 = getMatrixFromSeq(Seq(\"ACGTACGT\", IUPAC.unambiguous_dna))\n",
    "data = np.array([randSeq1], dtype=np.float32)\n",
    "print \"Data shape: \" + str(data.shape)\n",
    "x.setCustomKernels(kernel)\n",
    "print data\n",
    "\n",
    "# add the observers for free energy (test and train)\n",
    "#free_energy_observer = FreeEnergyObserver(x, data)\n",
    "#x.addObserver(free_energy_observer)\n",
    "\n",
    "# add the observers for reconstruction error (test and train)\n",
    "#reconstruction_observer = ReconstructionErrorObserver(x, data)\n",
    "#x.addObserver(reconstruction_observer)\n",
    "\n",
    "\n",
    "# perform training on our test data\n",
    "start = time.time()\n",
    "scores = x.trainMinibatch(data, data, 1, 1, 1)\n",
    "print \"Training (with compilation) performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "print \"Result from training: \"\n",
    "print \"----------------------\"\n",
    "print \"Learned Motif: \"\n",
    "print x.motifs.get_value()\n",
    "print \"Learned Bias (b): \"\n",
    "print x.bias.get_value()\n",
    "print \"Learned Constant (c): \"\n",
    "print x.c.get_value()\n",
    "\n",
    "with open('test.pkl', 'w') as f:\n",
    "    cPickle.dump(x, f)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.ylabel('Free energy function')\n",
    "plt.xlabel('Number Of Epoch')\n",
    "plt.title('Free Energy')\n",
    "plt.plot(free_energy_observer.scores)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.ylabel('Reconstruction error on dataset')\n",
    "plt.xlabel('Number Of Epoch')\n",
    "plt.title('Reconstruction Error')\n",
    "plt.plot(reconstruction_observer.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 1, 4, 150)\n",
      "12254.5634766\n"
     ]
    }
   ],
   "source": [
    "theano.config.mode='FAST_RUN'\n",
    "learner = CRBM(3, 20, 0.0000001, 2)\n",
    "f = learner.getFreeEnergyFunction()\n",
    "x = f(trainingData)\n",
    "print trainingData.shape\n",
    "print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 4: Test our GPU solution on the \"real\" training set\n",
    "It's time now to test on some real data to see how good the training is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (5000, 1, 4, 150)\n",
      "data shape: (15000, 1, 4, 150)\n",
      "data shape: (5000, 1, 4, 150)\n",
      "data shape: (15000, 1, 4, 150)\n",
      "Data mat shape: (15000, 1, 4, 150)\n",
      "BatchSize: 50\n",
      "Num of iterations per epoch: 300\n",
      "Start compiling Theano training function...\n",
      "Compilation of Theano training function finished in 7.32704401016 seconds\n",
      "Start training the model...\n",
      "Score of function: 12517.0162109\n",
      "Score of function: 12517.1202474\n",
      "Score of function: 0.610805333455\n",
      "Score of function: 0.610690221151\n",
      "[Epoch 0] done!\n",
      "Score of function: 12498.7357422\n",
      "Score of function: 12498.8302083\n",
      "Score of function: 0.610761332194\n",
      "Score of function: 0.610985334608\n",
      "[Epoch 1] done!\n",
      "Score of function: 12487.7808594\n",
      "Score of function: 12487.8660807\n",
      "Score of function: 0.611029337565\n",
      "Score of function: 0.61004844496\n",
      "[Epoch 2] done!\n",
      "Score of function: 12480.5978516\n",
      "Score of function: 12480.6723958\n",
      "Score of function: 0.610948003133\n",
      "Score of function: 0.610447553847\n",
      "[Epoch 3] done!\n",
      "Score of function: 12487.1794922\n",
      "Score of function: 12487.2440755\n",
      "Score of function: 0.617692001343\n",
      "Score of function: 0.617052444458\n",
      "[Epoch 4] done!\n",
      "Score of function: 12519.4425781\n",
      "Score of function: 12519.5000651\n",
      "Score of function: 0.629326670329\n",
      "Score of function: 0.629120444404\n",
      "[Epoch 5] done!\n",
      "Score of function: 12565.0070312\n",
      "Score of function: 12565.0563151\n",
      "Score of function: 0.638227996826\n",
      "Score of function: 0.638846669515\n",
      "[Epoch 6] done!\n",
      "Score of function: 12614.4380859\n",
      "Score of function: 12614.4806641\n",
      "Score of function: 0.65358400472\n",
      "Score of function: 0.653046668159\n",
      "[Epoch 7] done!\n",
      "Score of function: 12666.0060547\n",
      "Score of function: 12666.0417969\n",
      "Score of function: 0.671757334391\n",
      "Score of function: 0.671069778442\n",
      "[Epoch 8] done!\n",
      "Score of function: 12699.9949219\n",
      "Score of function: 12700.028776\n",
      "Score of function: 0.691459991455\n",
      "Score of function: 0.691284001668\n",
      "[Epoch 9] done!\n",
      "Training finished after: 270.61606288 seconds!\n",
      "Training of 15000 performed in: 277.947521925 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb8a03d08d0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8a07c5890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theano.config.mode='FAST_RUN'\n",
    "theano.config.profile=True\n",
    "\n",
    "learner = CRBM(3, 20, 0.001, 2)\n",
    "\n",
    "# add the observers for free energy (test and train)\n",
    "free_energy_observer = FreeEnergyObserver(learner, testingData)\n",
    "learner.addObserver(free_energy_observer)\n",
    "free_energy_observer_train = FreeEnergyObserver(learner, trainingData)\n",
    "learner.addObserver(free_energy_observer_train)\n",
    "\n",
    "# add the observers for reconstruction error (test and train)\n",
    "reconstruction_observer = ReconstructionErrorObserver(learner, testingData)\n",
    "learner.addObserver(reconstruction_observer)\n",
    "reconstruction_observer_train = ReconstructionErrorObserver(learner, trainingData)\n",
    "learner.addObserver(reconstruction_observer_train)\n",
    "\n",
    "print \"Data mat shape: \" + str(trainingData.shape)\n",
    "start = time.time()\n",
    "learner.trainMinibatch(trainingData, testingData, 10, 50, 1)\n",
    "print \"Training of \" + str(trainingData.shape[0]) + \" performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.ylabel('Free energy function')\n",
    "plt.xlabel('Number Of Epoch')\n",
    "plt.title('Free Energy')\n",
    "plt.plot(free_energy_observer.scores)\n",
    "plt.plot(free_energy_observer_train.scores)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.ylabel('Reconstruction error on dataset')\n",
    "plt.xlabel('Number Of Epoch')\n",
    "plt.title('Reconstruction Error')\n",
    "plt.plot(reconstruction_observer.scores)\n",
    "plt.plot(reconstruction_observer_train.scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test how one could implement the derivatives for both strands\n",
    "We want the derivative of the data and model to not be independent from each other.\n",
    "So we have to do the following:\n",
    "* Go through the different kernels and sum pairs of even and uneven kernels together (diff. strands)\n",
    "* Once that is done, we have to set the uneven rows to the reverse complement of the even rows\n",
    "* It all has to be in theano and efficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "idxes = T.ivector(\"indices\")\n",
    "output_model = T.matrix(\"output_model\")\n",
    "\n",
    "def sumWithNext(idx, output_model):\n",
    "    sub1 = output_model[idx]\n",
    "    sub2 = output_model[idx+1]\n",
    "    out1 = T.set_subtensor(sub1, sub1 + sub2)\n",
    "    return out1\n",
    "\n",
    "\n",
    "result, updates = theano.scan(fn=sumWithNext,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "sumItUp = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "def setToReverseComplement(idx, output_model):\n",
    "    sub1 = output_model[idx]\n",
    "    revCom = output_model[idx-1][::-1]\n",
    "    return T.set_subtensor(sub1, revCom)\n",
    "\n",
    "result, updates = theano.scan(fn=setToReverseComplement,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "revertIt = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "# test\n",
    "test_locations = np.asarray([0, 2], dtype=np.int32)\n",
    "test_output_model = np.eye(4, 5, dtype=np.float32)\n",
    "x = sumItUp(test_locations, test_output_model)[-1]\n",
    "#print x\n",
    "res = revertIt(test_locations + 1, x)[-1]\n",
    "print res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do this for the correct dimensionality (tensor4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.53  1.49  1.17  1.7   1.18  1.39]\n",
      "   [ 1.28  0.46  1.2   0.85  0.29  0.91]\n",
      "   [ 0.14  0.29  1.26  0.85  1.    0.93]\n",
      "   [ 0.62  1.38  1.38  1.    0.72  1.76]]\n",
      "\n",
      "  [[ 1.76  0.72  1.    1.38  1.38  0.62]\n",
      "   [ 0.93  1.    0.85  1.26  0.29  0.14]\n",
      "   [ 0.91  0.29  0.85  1.2   0.46  1.28]\n",
      "   [ 1.39  1.18  1.7   1.17  1.49  0.53]]\n",
      "\n",
      "  [[ 0.33  0.79  1.04  0.39  0.9   0.59]\n",
      "   [ 1.26  0.73  1.12  1.3   0.49  1.05]\n",
      "   [ 1.45  0.85  1.03  1.23  0.64  0.91]\n",
      "   [ 1.14  0.87  0.98  0.32  1.09  0.41]]\n",
      "\n",
      "  [[ 0.41  1.09  0.32  0.98  0.87  1.14]\n",
      "   [ 0.91  0.64  1.23  1.03  0.85  1.45]\n",
      "   [ 1.05  0.49  1.3   1.12  0.73  1.26]\n",
      "   [ 0.59  0.9   0.39  1.04  0.79  0.33]]]\n",
      "\n",
      "\n",
      " [[[ 1.74  1.05  0.92  1.12  0.45  0.62]\n",
      "   [ 0.91  0.21  1.72  0.92  0.54  0.76]\n",
      "   [ 1.66  1.19  0.87  1.77  1.31  1.64]\n",
      "   [ 1.42  1.05  0.66  0.81  0.73  0.94]]\n",
      "\n",
      "  [[ 0.94  0.73  0.81  0.66  1.05  1.42]\n",
      "   [ 1.64  1.31  1.77  0.87  1.19  1.66]\n",
      "   [ 0.76  0.54  0.92  1.72  0.21  0.91]\n",
      "   [ 0.62  0.45  1.12  0.92  1.05  1.74]]\n",
      "\n",
      "  [[ 0.26  0.6   1.85  0.94  0.74  1.12]\n",
      "   [ 0.14  1.66  1.33  1.07  0.58  1.46]\n",
      "   [ 1.16  1.51  1.1   1.65  1.79  0.3 ]\n",
      "   [ 0.61  1.37  0.8   1.02  0.52  1.2 ]]\n",
      "\n",
      "  [[ 1.2   0.52  1.02  0.8   1.37  0.61]\n",
      "   [ 0.3   1.79  1.65  1.1   1.51  1.16]\n",
      "   [ 1.46  0.58  1.07  1.33  1.66  0.14]\n",
      "   [ 1.12  0.74  0.94  1.85  0.6   0.26]]]]\n"
     ]
    }
   ],
   "source": [
    "idxes = T.ivector(\"indices\")\n",
    "output_model = T.tensor4(\"output_model\")\n",
    "\n",
    "def sumWithNext(idx, output_model):\n",
    "    sub1 = output_model[:,idx,:,:]\n",
    "    sub2 = output_model[:,idx+1,:,:]\n",
    "    added = sub1 + sub2\n",
    "    out1 = T.set_subtensor(sub1, added)\n",
    "    return out1\n",
    "\n",
    "\n",
    "result, updates = theano.scan(fn=sumWithNext,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "sumItUp = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "def setToReverseComplement(idx, output_model):\n",
    "    sub1 = output_model[:,idx,:,:]\n",
    "    revCom = output_model[:,idx-1,:,:]\n",
    "    revCom = revCom[:,::-1,::-1]\n",
    "    return T.set_subtensor(sub1, revCom)\n",
    "\n",
    "result, updates = theano.scan(fn=setToReverseComplement,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "revertIt = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "# test\n",
    "test_locations = np.asarray([0, 2], dtype=np.int32)\n",
    "test_output_model = np.random.rand(2, 4, 4, 6).astype(np.float32)\n",
    "x = sumItUp(test_locations, test_output_model)[-1]\n",
    "#print x\n",
    "res = revertIt(test_locations + 1, x)[-1]\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 4, 4)\n",
      "[[[[ 0.84  0.71  0.38  0.18]\n",
      "   [ 0.04  0.27  0.87  0.47]\n",
      "   [ 0.97  0.06  0.35  0.58]\n",
      "   [ 0.15  0.07  0.76  0.89]]\n",
      "\n",
      "  [[ 0.03  0.53  0.12  0.43]\n",
      "   [ 0.96  0.21  0.36  0.68]\n",
      "   [ 0.46  0.72  0.11  0.27]\n",
      "   [ 0.72  0.17  0.42  0.52]]\n",
      "\n",
      "  [[ 0.55  0.71  0.26  0.88]\n",
      "   [ 0.53  0.37  0.83  0.81]\n",
      "   [ 0.28  0.48  0.07  0.32]\n",
      "   [ 0.28  0.77  0.79  0.08]]\n",
      "\n",
      "  [[ 0.05  0.43  0.16  0.47]\n",
      "   [ 0.04  0.92  0.54  0.07]\n",
      "   [ 0.21  0.82  0.91  0.07]\n",
      "   [ 0.41  0.62  0.19  0.88]]]]\n",
      "[0 2]\n",
      "[1 3]\n",
      "RESULT\n",
      "[[[[ 0.87  1.24  0.5   0.61]\n",
      "   [ 1.    0.48  1.23  1.15]\n",
      "   [ 1.43  0.78  0.45  0.85]\n",
      "   [ 0.87  0.24  1.18  1.41]]\n",
      "\n",
      "  [[ 1.41  1.18  0.24  0.87]\n",
      "   [ 0.85  0.45  0.78  1.43]\n",
      "   [ 1.15  1.23  0.48  1.  ]\n",
      "   [ 0.61  0.5   1.24  0.87]]\n",
      "\n",
      "  [[ 0.6   1.14  0.42  1.35]\n",
      "   [ 0.57  1.29  1.38  0.89]\n",
      "   [ 0.49  1.3   0.99  0.39]\n",
      "   [ 0.69  1.39  0.97  0.96]]\n",
      "\n",
      "  [[ 0.96  0.97  1.39  0.69]\n",
      "   [ 0.39  0.99  1.3   0.49]\n",
      "   [ 0.89  1.38  1.29  0.57]\n",
      "   [ 1.35  0.42  1.14  0.6 ]]]]\n"
     ]
    }
   ],
   "source": [
    "test = CRBM(4, 2, 0.01, 1)\n",
    "#derivatives = np.tile(np.eye(4,4), [1,4,1,1])\n",
    "derivatives = np.random.rand(1,4,4,4)\n",
    "print derivatives.shape\n",
    "print derivatives\n",
    "k=2\n",
    "print np.arange(start=0, stop=2*k, step=2)\n",
    "print np.arange(start=1, stop=2*k, step=2)\n",
    "\n",
    "der = T.tensor4('derivatives')\n",
    "x = test.makeDerivativesStrandCompliant(der)\n",
    "f = theano.function([der], x, allow_input_downcast=True)\n",
    "result = f(derivatives)\n",
    "print \"RESULT\"\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "[1 3]\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "print np.arange(start=0, stop=2*k, step=2)\n",
    "print np.arange(start=1, stop=2*k, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  1.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      "   [ -3.44700809e-03   1.00000000e+00   0.00000000e+00]\n",
      "   [  5.47764311e-03   3.56943603e-03   1.00480831e+00]\n",
      "   [ -6.69240952e-04  -2.20805407e-03  -3.44700809e-03]]]\n",
      "\n",
      "\n",
      " [[[ -3.44700809e-03  -2.20805407e-03  -6.69240952e-04]\n",
      "   [  1.00480831e+00   3.56943603e-03   5.47764311e-03]\n",
      "   [  0.00000000e+00   1.00000000e+00  -3.44700809e-03]\n",
      "   [  0.00000000e+00   0.00000000e+00   1.00000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "# test loading\n",
    "with open('test.pkl', 'r') as f:\n",
    "    test = cPickle.load(f)\n",
    "    \n",
    "print test.motifs.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

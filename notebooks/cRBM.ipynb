{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional RBM on the GPU (cRBM)\n",
    "In this notebook, a general implementation of the convolutional Restricted Boltzmann Machine is given.\n",
    "The code focusses on speed on GPUs (graphics cards) and therefore, the relevant parts are written in Theano.\n",
    "\n",
    "The first parts of the notebook provide methods to read in the DNA sequences while the actual training algorithm is given in section 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Importing all relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '25179' (I am process '27730')\n",
      "WARNING:theano.gof.compilelock:Overriding existing lock by dead process '25179' (I am process '27730')\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.0: cannot open shared object file: No such file or directory\n",
      "ERROR:theano.sandbox.cuda:Failed to compile cuda_ndarray.cu: libcublas.so.7.0: cannot open shared object file: No such file or directory\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n",
      "WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Theano imports\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet.conv as conv\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RS\n",
    "from theano import pp\n",
    "\n",
    "# numpy and python classics\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# biopython stuff\n",
    "import Bio.SeqIO as sio\n",
    "import Bio.motifs.matrix as mat\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio import motifs\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading the data and converting it to various forms of matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes to read biological files (such as FASTA or JASPAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This class reads sequences from fasta files.\n",
    "To use it, create an instance of that object and use\n",
    "the function readSequencesFromFile.\n",
    "\"\"\"\n",
    "class FASTAReader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        dhsSequences = []\n",
    "        for dhs in sio.parse(open(filename), 'fasta', IUPAC.unambiguous_dna):\n",
    "            dhsSequences.append(dhs.seq)\n",
    "        return dhsSequences\n",
    "    \n",
    "    \n",
    "class JASPARReader:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        pass\n",
    "    \n",
    "    def readSequencesFromFile (self, filename):\n",
    "        matrices = []\n",
    "        for mat in motifs.parse(open(filename), 'jaspar'):\n",
    "            matrices.append(mat.pwm)\n",
    "        return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading that information to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matReader = JASPARReader()\n",
    "pwms = matReader.readSequencesFromFile('data/jaspar_matrices.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqReader = FASTAReader()\n",
    "allSeqs = seqReader.readSequencesFromFile('data/wgEncodeAwgDnaseUwAg10803UniPk.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the DNA sequences to matrices\n",
    "Each DNA sequence is transformed into a 4 x seqLength dimensional matrix. That way, each row represents one of the four letters in the genomic alphabet and in every column, exactly one of the four equals one, while the rest is set to zero.\n",
    "\n",
    "\n",
    "\n",
    "#### So, the sequence **ACGTGGGG** would look like this:\n",
    "| Letter | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n",
    "|--|------------------------------|\n",
    "| A | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| C | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| G | 0 | 0 | 1 | 0 | 1 | 1 | 1 | 1 |\n",
    "| T | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getIntToLetter (letter):\n",
    "    if letter == 'A' or letter == 'a':\n",
    "        return 0\n",
    "    elif letter == 'C' or letter == 'c':\n",
    "        return 1\n",
    "    elif letter == 'G' or letter == 'g':\n",
    "        return 2\n",
    "    elif letter == 'T' or letter == 't':\n",
    "        return 3\n",
    "    else:\n",
    "        print \"ERROR. LETTER \" + letter + \" DOES NOT EXIST!\"\n",
    "        return -1\n",
    "\n",
    "def getMatrixFromSeq (seq):\n",
    "    m = len(seq.alphabet.letters)\n",
    "    n = len(seq)\n",
    "    result = np.zeros((1, m, n), dtype=np.float32)\n",
    "    revSeq = seq.reverse_complement()\n",
    "    for i in range(len(seq)):\n",
    "        result[0,getIntToLetter(seq[i]),i] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 15000\n",
      "Test set size: 5000\n",
      "Conversion of test set in (in ms): 3162.98818588\n"
     ]
    }
   ],
   "source": [
    "data = [allSeqs[random.randrange(0,len(allSeqs))] for i in range(20000)]\n",
    "train_set, test_set = train_test_split(data, test_size=0.25)\n",
    "print \"Training set size: \" + str(len(train_set))\n",
    "print \"Test set size: \" + str(len(test_set))\n",
    "\n",
    "start = time.time()\n",
    "trainingData = np.array([getMatrixFromSeq(t) for t in train_set])\n",
    "testingData = np.array([getMatrixFromSeq(t) for t in test_set])\n",
    "print \"Conversion of test set in (in ms): \" + str((time.time()-start)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Borrowing Ian Goodfellow's implementation of the probabilistic max pooling layer\n",
    "This implementation is now part of the pylearn2 library which is licensed under the 3-claused BSD license.\n",
    "Source code is available here: https://github.com/lisa-lab/pylearn2/blob/master/pylearn2/expr/probabilistic_max_pooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from theano.gof.op import get_debug_values\n",
    "\n",
    "def max_pool(z, pool_shape, top_down=None, theano_rng=None):\n",
    "    \"\"\"\n",
    "    Probabilistic max-pooling\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : theano 4-tensor\n",
    "        a theano 4-tensor representing input from below\n",
    "    pool_shape : tuple\n",
    "        tuple of ints. the shape of regions to be pooled\n",
    "    top_down : theano 4-tensor, optional\n",
    "        a theano 4-tensor representing input from above\n",
    "        if None, assumes top-down input is 0\n",
    "    theano_rng : MRG_RandomStreams, optional\n",
    "        Used for random numbers for sampling\n",
    "    Returns\n",
    "    -------\n",
    "    p : theano 4-tensor\n",
    "        the expected value of the pooling layer p\n",
    "    h : theano 4-tensor\n",
    "        the expected value of the detector layer h\n",
    "    p_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the pooling layer\n",
    "    h_samples : theano 4-tensor, only returned if theano_rng is not None\n",
    "        samples of the detector layer\n",
    "    Notes\n",
    "    ------\n",
    "    all 4-tensors are formatted with axes ('b', 'c', 0, 1).\n",
    "    This is for maximum speed when using theano's conv2d\n",
    "    to generate z and top_down, or when using it to infer conditionals of\n",
    "    other layers using the return values.\n",
    "    Detailed description:\n",
    "    Suppose you have a variable h that lives in a Conv2DSpace h_space and\n",
    "    you want to pool it down to a variable p that lives in a smaller\n",
    "    Conv2DSpace p.\n",
    "    This function does that, using non-overlapping pools.\n",
    "    Specifically, consider one channel of h. h must have a height that is a\n",
    "    multiple of pool_shape[0] and a width that is a multiple of pool_shape[1].\n",
    "    A channel of h can thus be broken down into non-overlapping rectangles\n",
    "    of shape pool_shape.\n",
    "    Now consider one rectangular pooled region within one channel of h.\n",
    "    I now use 'h' to refer just to this rectangle, and 'p' to refer to\n",
    "    just the one pooling unit associated with that rectangle.\n",
    "    We assume that the space that h and p live in is constrained such\n",
    "    that h and p are both binary and p = max(h). To reduce the state-space\n",
    "    in order to make probabilistic computations cheaper we also\n",
    "    constrain sum(h) <= 1.\n",
    "    Suppose h contains k different units. Suppose that the only term\n",
    "    in the model's energy function involving h is -(z*h).sum()\n",
    "    (elemwise multiplication) and the only term in\n",
    "    the model's energy function involving p is -(top_down*p).sum().\n",
    "    Then P(h[i] = 1) = softmax( [ z[1], z[2], ..., z[k], -top_down] )[i]\n",
    "    and P(p = 1) = 1-softmax( [z[1], z[2], ..., z[k], -top_down])[k]\n",
    "    This variation of the function assumes that z, top_down, and all\n",
    "    return values use Conv2D axes ('b', 'c', 0, 1).\n",
    "    This variation of the function implements the softmax using a\n",
    "    theano graph of exp, maximum, sub, and div operations.\n",
    "    \"\"\"\n",
    "\n",
    "    z_name = z.name\n",
    "    if z_name is None:\n",
    "        z_name = 'anon_z'\n",
    "\n",
    "    batch_size, ch, zr, zc = z.shape\n",
    "\n",
    "    r, c = pool_shape\n",
    "\n",
    "    zpart = []\n",
    "\n",
    "    mx = None\n",
    "\n",
    "    if top_down is None:\n",
    "        t = 0.\n",
    "    else:\n",
    "        t = - top_down\n",
    "        t.name = 'neg_top_down'\n",
    "\n",
    "    for i in xrange(r):\n",
    "        zpart.append([])\n",
    "        for j in xrange(c):\n",
    "            cur_part = z[:, :, i:zr:r, j:zc:c]\n",
    "            if z_name is not None:\n",
    "                cur_part.name = z_name + '[%d,%d]' % (i, j)\n",
    "            zpart[i].append(cur_part)\n",
    "            if mx is None:\n",
    "                mx = T.maximum(t, cur_part)\n",
    "                if cur_part.name is not None:\n",
    "                    mx.name = 'max(-top_down,' + cur_part.name + ')'\n",
    "            else:\n",
    "                max_name = None\n",
    "                if cur_part.name is not None:\n",
    "                    mx_name = 'max(' + cur_part.name + ',' + mx.name + ')'\n",
    "                mx = T.maximum(mx, cur_part)\n",
    "                mx.name = mx_name\n",
    "    mx.name = 'local_max(' + z_name + ')'\n",
    "\n",
    "    pt = []\n",
    "\n",
    "    for i in xrange(r):\n",
    "        pt.append([])\n",
    "        for j in xrange(c):\n",
    "            z_ij = zpart[i][j]\n",
    "            safe = z_ij - mx\n",
    "            safe.name = 'safe_z(%s)' % z_ij.name\n",
    "            cur_pt = T.exp(safe)\n",
    "            cur_pt.name = 'pt(%s)' % z_ij.name\n",
    "            pt[-1].append(cur_pt)\n",
    "\n",
    "    off_pt = T.exp(t - mx)\n",
    "    off_pt.name = 'p_tilde_off(%s)' % z_name\n",
    "    denom = off_pt\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            denom = denom + pt[i][j]\n",
    "    denom.name = 'denom(%s)' % z_name\n",
    "\n",
    "    off_prob = off_pt / denom\n",
    "    p = 1. - off_prob\n",
    "    p.name = 'p(%s)' % z_name\n",
    "\n",
    "    hpart = []\n",
    "    for i in xrange(r):\n",
    "        hpart.append([pt_ij / denom for pt_ij in pt[i]])\n",
    "\n",
    "    h = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "    for i in xrange(r):\n",
    "        for j in xrange(c):\n",
    "            h.name = 'h_interm'\n",
    "            h = T.set_subtensor(h[:, :, i:zr:r, j:zc:c], hpart[i][j])\n",
    "\n",
    "    h.name = 'h(%s)' % z_name\n",
    "\n",
    "    if theano_rng is None:\n",
    "        return p, h\n",
    "    \n",
    "    ### --------------------- DONE IF NO SAMPLES ARE GENERATED ---------------------------###\n",
    "    else:\n",
    "        events = []\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                events.append(hpart[i][j])\n",
    "        events.append(off_prob)\n",
    "\n",
    "        events = [event.dimshuffle(0, 1, 2, 3, 'x') for event in events]\n",
    "\n",
    "        events = tuple(events)\n",
    "\n",
    "        stacked_events = T.concatenate(events, axis=4)\n",
    "\n",
    "        rows = zr // pool_shape[0]\n",
    "        cols = zc // pool_shape[1]\n",
    "        outcomes = pool_shape[0] * pool_shape[1] + 1\n",
    "        assert stacked_events.ndim == 5\n",
    "        for se, bs, r, c, chv in get_debug_values(stacked_events, batch_size,\n",
    "                                                  rows, cols, ch):\n",
    "            assert se.shape[0] == bs\n",
    "            assert se.shape[1] == r\n",
    "            assert se.shape[2] == c\n",
    "            assert se.shape[3] == chv\n",
    "            assert se.shape[4] == outcomes\n",
    "        reshaped_events = stacked_events.reshape((\n",
    "            batch_size * rows * cols * ch, outcomes))\n",
    "\n",
    "        multinomial = theano_rng.multinomial(pvals=reshaped_events,\n",
    "                                             dtype=p.dtype)\n",
    "\n",
    "        reshaped_multinomial = multinomial.reshape((batch_size, ch, rows,\n",
    "                                                    cols, outcomes))\n",
    "\n",
    "        h_sample = T.alloc(0., batch_size, ch, zr, zc)\n",
    "\n",
    "        idx = 0\n",
    "        for i in xrange(r):\n",
    "            for j in xrange(c):\n",
    "                h_sample = T.set_subtensor(h_sample[:, :, i:zr:r, j:zc:c],\n",
    "                                           reshaped_multinomial[:, :, :, :,\n",
    "                                           idx])\n",
    "                idx += 1\n",
    "\n",
    "        p_sample = 1 - reshaped_multinomial[:, :, :, :, -1]\n",
    "\n",
    "        return p, h, p_sample, h_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: The implementation of a convolutional RBM on the GPU\n",
    "And finally, here it is. A class that lets us train a cRBM on the GPU.\n",
    "The algorithm should feature various variantes of the classical learning algorithms such as:\n",
    "\n",
    "* Persistent Contrastive Divergence\n",
    "* Dropout to enforce sparsity\n",
    "* **Probabilistic Max-Pooling units in the hidden layer**\n",
    "* Regularization\n",
    "* Stochastic Gradient Descent with momentum & Simulated Annealing\n",
    "\n",
    "However, only the procedures printed in **bold** are allready functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PART 3: Optimizing theano to do it all on the GPU\n",
    "\n",
    "\"\"\"\n",
    "This is the actual implementation of our convolutional RBM.\n",
    "The class implements only contrastive divergence learning so far\n",
    "but the number of runs for Gibbs Sampling can be varied.\n",
    "Furthermore, the beforementioned implementation of probabilistic max pooling\n",
    "computes probabilities for and samples of the hidden layer distribution.\n",
    "\"\"\"\n",
    "class CRBM:\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize the cRBM. The parameters here are global params that should not change\n",
    "    during the execution of training or testing and characterize the network.\n",
    "    \n",
    "    Parameters:\n",
    "    _motifLength:    How long are the motifs (position weight matrices PWM). This\n",
    "                     This is equivalent to ask what the number of k-mers is.\n",
    "                     The current approach only deals with one fixed motif length.\n",
    "                     \n",
    "    _numMotifs:      How many motifs are applied to the sequence, that is how many\n",
    "                     hidden units does the network have. Each hidden unit consists\n",
    "                     of a vector of size (sequenceLength-motifLength+1)\n",
    "                     \n",
    "    _poolingFactor:  How many units from the hidden layer are pooled together.\n",
    "                     Note that the number has to divide evenly to the length of\n",
    "                     the hidden units, that is:\n",
    "                     mod(sequenceLength-motifLength+1, poolingFactor) == 0\n",
    "                     (1 = equivalent to sigmoid activation)\n",
    "    \"\"\"\n",
    "    def __init__ (self, _motifLength, _numMotifs, _learningRate=0.1, _poolingFactor=1):\n",
    "        # parameters for the motifs\n",
    "        self.motifLength = _motifLength\n",
    "        self.numMotifs = _numMotifs\n",
    "        self.initializeMotifs()\n",
    "        \n",
    "        # cRBM parameters (2*x to respect both strands of the DNA)\n",
    "        b = np.random.rand(1, 2*self.numMotifs).astype(np.float32)\n",
    "        c = np.random.rand(1, 4).astype(np.float32)\n",
    "        self.bias = theano.shared(value=b, name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=c, name='c', borrow=True)\n",
    "        self.poolingFactor = _poolingFactor\n",
    "        self.learningRate = _learningRate\n",
    "        \n",
    "        # infrastructural parameters\n",
    "        self.theano_rng = RS(seed=1234)\n",
    "        self.params = [self.motifs, self.bias, self.c]\n",
    "        self.debug = False\n",
    "    \n",
    "    \n",
    "    def initializeMotifs (self):\n",
    "        # create random motifs (2*self.numMotifs to respect both strands)\n",
    "        x = np.random.rand(2 * self.numMotifs, 1, 4, self.motifLength).astype(np.float32)\n",
    "        \n",
    "        # create reverse complement\n",
    "        for i in range(0, 2*self.numMotifs, 2):\n",
    "            x[i+1] = x[i,:,::-1,::-1]\n",
    "            \n",
    "        self.motifs = theano.shared(value=x, name='W', borrow=True)\n",
    "        \n",
    "        \n",
    "    def setCustomKernels (self, customKernels):\n",
    "        if len(customKernels.shape) != 4 or customKernels.shape[1] != 1:\n",
    "            print \"New motifs must be a 4D matrix with dims: (K x 1 x numOfLetters(4) x numOfKMers)\"\n",
    "            return\n",
    "        \n",
    "        self.numMotifs = (customKernels.shape[0] / 2)\n",
    "        self.motifLength = customKernels.shape[3]\n",
    "        #b = np.random.rand(1, self.numMotifs).astype(np.float32)\n",
    "        \n",
    "        if self.debug:\n",
    "            b = np.zeros((1, 2*self.numMotifs)).astype(np.float32)\n",
    "            c = np.zeros((1, 4)).astype(np.float32)\n",
    "        else:\n",
    "            b = np.random.rand(1, 2*self.numMotifs).astype(np.float32)\n",
    "            c = np.random.rand(1, 4).astype(np.float32)\n",
    "\n",
    "        self.bias = theano.shared(value=b, name='bias', borrow=True)\n",
    "        self.c = theano.shared(value=c, name='c', borrow=True)\n",
    "        \n",
    "        self.motifs = theano.shared(value=customKernels.astype(np.float32))\n",
    "        self.params = [self.motifs, self.bias, self.c]\n",
    "        print \"New motifs set. # Motifs: \" + str(self.numMotifs) + \" K-mer-Length: \" + str(self.motifLength)\n",
    "\n",
    "        \n",
    "### ------------------------------THE TOUGH STUFF-------------------------------- ###\n",
    "### ----------------------------------------------------------------------------- ###\n",
    "\n",
    "    def forwardBatch (self, data):\n",
    "        out = conv.conv2d(data, self.motifs[:,:,::-1,::-1])\n",
    "        if self.debug:\n",
    "            out = theano.printing.Print('Convolution result forward: ')(out)\n",
    "        bMod = self.bias\n",
    "        bMod = bMod.dimshuffle('x', 1, 0, 'x') # add dims to the bias until it works\n",
    "        out = out + bMod\n",
    "        pooled = max_pool(out.dimshuffle(0,2,1,3), pool_shape=(2, self.poolingFactor), theano_rng=self.theano_rng)\n",
    "        H = pooled[1]\n",
    "        S = pooled[3]\n",
    "        if self.debug:\n",
    "            H = theano.printing.Print('Hidden Probabilites: ')(H)\n",
    "            S = theano.printing.Print('prob max pooled layer: ')(S)\n",
    "        return [H,S] #only return pooled layer and probs\n",
    "\n",
    "\n",
    "    def backwardBatch (self, H_sample):\n",
    "        K = self.motifs.dimshuffle(1, 0, 2, 3)[:,:,::-1,::-1] # kernel is flipped prior to convolution\n",
    "        H_shuffled = H_sample.dimshuffle(0, 2, 1, 3) # interpret the kernels as channels (will be summed automatically)\n",
    "        C = conv.conv2d(H_shuffled, K, border_mode='full')[:,:,::-1,:]\n",
    "        if self.debug:\n",
    "            C = theano.printing.Print('Pre sigmoid visible layer: ')(C)\n",
    "        out = T.sum(C, axis=1, keepdims=True) # sum over all K\n",
    "        c_bc = self.c\n",
    "        c_bc = c_bc.dimshuffle('x', 0, 1, 'x')\n",
    "        out = out + c_bc\n",
    "        res = self.softmax(out)\n",
    "        return res\n",
    "\n",
    "    \n",
    "    def makeDerivativesStrandCompliant (self, derivatives):\n",
    "        # scan over the even kernels and sum them together with the next\n",
    "        # one (k[0] + k[1] etc)\n",
    "        def sumWithNext(idx, output_model):\n",
    "            sub1 = output_model[:,idx,:,:]\n",
    "            sub2 = output_model[:,idx+1,:,:]\n",
    "            added = sub1 + sub2\n",
    "            out = T.set_subtensor(sub1, added)\n",
    "            return out\n",
    "        result, updates = theano.scan(fn=sumWithNext,\n",
    "                                      outputs_info=derivatives,\n",
    "                                      sequences=[T.arange(start=0, stop=2*self.numMotifs, step=2)])\n",
    "        result = result[-1] # only take the last one\n",
    "        \n",
    "        # now scan over the unevens and set their derivative to the reverse complement\n",
    "        # of the evens\n",
    "        def setToReverseComplement(idx, output_model):\n",
    "            sub1 = output_model[:,idx,:,:]\n",
    "            revCom = output_model[:,idx-1,:,:]\n",
    "            revCom = revCom[:,::-1,::-1]\n",
    "            return T.set_subtensor(sub1, revCom)\n",
    "        result, updates = theano.scan(fn=setToReverseComplement,\n",
    "                                      outputs_info=result,\n",
    "                                      sequences=[T.arange(start=1, stop=2*self.numMotifs, step=2)])\n",
    "        \n",
    "        return result[-1]\n",
    "        \n",
    "\n",
    "    def expectedDerivative (self, hiddenProbs, data):\n",
    "        mean = T.mean(hiddenProbs, axis=0, keepdims=True) # sum over all training data to get avg (but keep dim)\n",
    "        H_reshaped = mean.dimshuffle(2, 0, 1, 3)\n",
    "        # TODO: Capture the 1 <-> 1 relation between samples in H and D\n",
    "        # Currently, this is done by mean (1st row) but that's not good at all\n",
    "        out = conv.conv2d(data, H_reshaped)\n",
    "        # TODO: perform scan here and sum even ones while setting unevens to 0.\n",
    "        # TODO: Don't mean over all then, but use sum and divide by K (not 2*K like in this case)\n",
    "        out = self.makeDerivativesStrandCompliant(out)\n",
    "        \n",
    "        der_Motifs = T.sum(out, axis=0, keepdims=True) / self.numMotifs # mean over training examples\n",
    "        der_Motifs = der_Motifs.dimshuffle(1, 0, 2, 3) # bring back to former shape\n",
    "        der_bias = T.mean(T.sum(hiddenProbs, axis=3), axis=0)\n",
    "        der_c = T.mean(T.sum(data, axis=3), axis=0)\n",
    "        return (der_Motifs, der_bias, der_c)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def train_model (self, D, numOfCDs):\n",
    "        # calculate the data gradient for weights (motifs) and bias\n",
    "        [H_data, S_data] = self.forwardBatch(D)\n",
    "        if self.debug:\n",
    "            H_data = theano.printing.Print('Hidden Layer Probabilities: ')(H_data)\n",
    "        # calculate data gradients\n",
    "        G_motif_data, G_bias_data, G_c_data = self.expectedDerivative(H_data, D)\n",
    "        \n",
    "        if self.debug:\n",
    "            G_motif_data = theano.printing.Print('Gradient for motifs (data): ')(G_motif_data)\n",
    "        # calculate model probs\n",
    "        S_H = S_data\n",
    "        for i in range(numOfCDs):\n",
    "            V_model = self.backwardBatch(S_H)\n",
    "            S_V_model = self.sampleVisibleLayer(V_model)\n",
    "            [H_model, S_H] = self.forwardBatch(S_V_model)\n",
    "        \n",
    "        # compute the model gradients\n",
    "        G_motif_model, G_bias_model, G_c_model = self.expectedDerivative(H_model, D)\n",
    "        \n",
    "        if self.debug:\n",
    "            G_motif_model = theano.printing.Print('Gradient for motifs (model): ')(G_motif_model)\n",
    "        \n",
    "        # update the parameters\n",
    "        new_motifs = self.motifs + self.learningRate * (G_motif_data - G_motif_model)\n",
    "        new_bias = self.bias + self.learningRate * (G_bias_data - G_bias_model)\n",
    "        new_c = self.c + self.learningRate * (G_c_data - G_c_model)\n",
    "        \n",
    "        #score = self.getDataReconstruction(D)\n",
    "        updates = [(self.motifs, new_motifs), (self.bias, new_bias), (self.c, new_c)]\n",
    "\n",
    "        return updates\n",
    "    \n",
    "    \n",
    "    def trainMinibatch (self, trainData, testData, epochs, batchSize, numOfCDs):\n",
    "        \n",
    "        # assert that pooling can be done without rest to the division\n",
    "        assert (((trainData.shape[3] - self.motifLength + 1) % self.poolingFactor) == 0)\n",
    "        assert (((testData.shape[3] - self.motifLength + 1) % self.poolingFactor) == 0)\n",
    "        \n",
    "        # some debug printing\n",
    "        itPerEpoch = trainData.shape[0] / batchSize\n",
    "        print \"BatchSize: \" + str(batchSize)\n",
    "        print \"Num of iterations per epoch: \" + str(itPerEpoch)\n",
    "        start = time.time()\n",
    "        \n",
    "        # compile training function\n",
    "        \n",
    "        train_set = theano.shared(value=trainData, borrow=True, name='trainData')\n",
    "        \n",
    "        index = T.lscalar()\n",
    "        D = T.tensor4('data')\n",
    "        updates = self.train_model(D, numOfCDs)\n",
    "        trainingFun = theano.function(\n",
    "              [index],\n",
    "              None,\n",
    "              updates = updates,\n",
    "              allow_input_downcast=True,\n",
    "              givens={\n",
    "                D: train_set[index*batchSize:(index+1)*batchSize]\n",
    "              },\n",
    "              name='train_CRBM'\n",
    "        )\n",
    "\n",
    "        reconFun = self.getFreeEnergyFunction()\n",
    "        print \"Compilation of theano function finished in \" + str(time.time()-start) + \" seconds\"\n",
    "        print \"Start training...\"\n",
    "        start = time.time()\n",
    "        allScores = []\n",
    "        allScores.append(reconFun(testData))\n",
    "        print \"Initial Reconstruction Error: \" + str(allScores[-1])\n",
    "        for epoch in range(epochs):\n",
    "            smallScores = []\n",
    "            for batchIdx in range(itPerEpoch):\n",
    "                trainingFun(batchIdx)\n",
    "            allScores.append(reconFun(testData))\n",
    "            print \"[Epoch \" + str(epoch) + \"] Reconstruction Error: \" + str(allScores[-1])\n",
    "        print \"Training finished after: \" + str(time.time()-start) + \" seconds!\"\n",
    "        return allScores\n",
    "\n",
    "    def getReconFun (self):\n",
    "        D = T.tensor4('data')\n",
    "        score = self.getDataReconstruction(D)\n",
    "        return theano.function([D], score, allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "    def getDataReconstruction (self, D):\n",
    "        [H, S_H] = self.forwardBatch(D)\n",
    "        V = self.backwardBatch(S_H)\n",
    "        S_V = self.sampleVisibleLayer(V)\n",
    "        sames = S_V * D # elements are 1 if they have the same letter...\n",
    "        count = T.sum(T.mean(sames, axis=0)) # mean over samples, sum over rest\n",
    "        return score\n",
    "    \n",
    " \n",
    "    def getFreeEnergyFunction (self):\n",
    "        D = T.tensor4('data')\n",
    "        free_energy = self.calculateFreeEnergy(D)\n",
    "        return theano.function([D], free_energy, allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "    def calculateFreeEnergy (self, D):\n",
    "        # firstly, compute hidden part of free energy\n",
    "        C = conv.conv2d(D, self.motifs)\n",
    "        bMod = self.bias # to prevent member from being shuffled\n",
    "        bMod = bMod.dimshuffle('x', 1, 0, 'x') # add dims to the bias on both sides\n",
    "        C = C + bMod\n",
    "        hiddenPart = T.sum(T.log(1. + T.exp(C)), axis=1) # dim: N_batch x 1 x N_h after sum over K\n",
    "        hiddenPart = T.sum(T.mean(hiddenPart, axis=0)) # mean over all samples and sum over units\n",
    "        \n",
    "        # compute the visible part\n",
    "        cMod = self.c\n",
    "        cMod = cMod.dimshuffle('x', 0, 1, 'x') # make it 4D and broadcastable there\n",
    "        visiblePart = T.mean(D * cMod, axis=0) # dim: 1 x 4 x N_v\n",
    "        visiblePart = T.sum(visiblePart)\n",
    "        \n",
    "        return hiddenPart + visiblePart # don't return the negative because it's more difficult to plot\n",
    "        \n",
    "        \n",
    "    def sampleVisibleLayer (self, V):\n",
    "        reshaped = V.dimshuffle(0, 1, 3, 2).reshape((V.shape[0]*V.shape[3], V.shape[2]))\n",
    "        S_reshaped = self.theano_rng.multinomial(n=1,pvals=reshaped)\n",
    "        S = S_reshaped.reshape((V.shape[0], 1, V.shape[3], V.shape[2])).dimshuffle(0, 1, 3, 2)\n",
    "        S = S.astype('float32')\n",
    "        if self.debug:\n",
    "            S = theano.printing.Print('Visible Sample: ')(S)\n",
    "        return S\n",
    "    \n",
    "    def softmax (self, x):\n",
    "        return T.exp(x) / T.exp(x).sum(axis=2, keepdims=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4b: Create the theano functions neccessary for training (compile to C)\n",
    "Theano optimizes the function graph heavily when aiming for maximum performance. Thus, the package spends a long time setting up the whole system and not so much time with the actual training of the data.\n",
    "\n",
    "By generating the function in it's own cell, we can do training seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set some config parameters to make debugging simpler\n",
    "debug = False\n",
    "if debug:\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    theano.config.exception_verbosity='high'\n",
    "    theano.config.optimizer='None'\n",
    "    theano.config.compute_test_value='ignore'\n",
    "    theano.config.profile=True\n",
    "else:\n",
    "    theano.config.exception_verbosity='low'\n",
    "    theano.config.mode='FAST_RUN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our solution on toy data to verify correctness of calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motifs:\n",
      "[[[[ 0.82231867  0.46193919  0.07041538  0.1548268   0.24369512]\n",
      "   [ 0.5861975   0.85514748  0.03433696  0.75250649  0.25983828]\n",
      "   [ 0.78535199  0.73120677  0.38818511  0.78280991  0.68588072]\n",
      "   [ 0.11924195  0.66405928  0.7023533   0.83667588  0.75194484]]]\n",
      "\n",
      "\n",
      " [[[ 0.75194484  0.83667588  0.7023533   0.66405928  0.11924195]\n",
      "   [ 0.68588072  0.78280991  0.38818511  0.73120677  0.78535199]\n",
      "   [ 0.25983828  0.75250649  0.03433696  0.85514748  0.5861975 ]\n",
      "   [ 0.24369512  0.1548268   0.07041538  0.46193919  0.82231867]]]\n",
      "\n",
      "\n",
      " [[[ 0.70954186  0.35176599  0.99520016  0.38906303  0.93742794]\n",
      "   [ 0.01836719  0.29936498  0.35476893  0.41925749  0.46542466]\n",
      "   [ 0.241072    0.02306824  0.7707544   0.3959882   0.10944228]\n",
      "   [ 0.34072465  0.5082221   0.24138051  0.09396768  0.19537482]]]\n",
      "\n",
      "\n",
      " [[[ 0.19537482  0.09396768  0.24138051  0.5082221   0.34072465]\n",
      "   [ 0.10944228  0.3959882   0.7707544   0.02306824  0.241072  ]\n",
      "   [ 0.46542466  0.41925749  0.35476893  0.29936498  0.01836719]\n",
      "   [ 0.93742794  0.38906303  0.99520016  0.35176599  0.70954186]]]]\n",
      "Kernel: [[[[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]]]\n",
      "Data shape: (1, 1, 4, 8)\n",
      "New motifs set. # Motifs: 1 K-mer-Length: 3\n",
      "[[[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  1.  0.  1.  1.  1.  1.]\n",
      "   [ 0.  0.  0.  1.  0.  0.  0.  0.]]]]\n",
      "BatchSize: 1\n",
      "Num of iterations per epoch: 1\n",
      "Compilation of theano function finished in 3.63555502892 seconds\n",
      "Start training...\n",
      "Initial Reconstruction Error: 28.8566551208\n",
      "[Epoch 0] Reconstruction Error: 28.7930850983\n",
      "Training finished after: 0.00122404098511 seconds!\n",
      "Training (with compilation) performed in: 3.63798809052 seconds.\n",
      "Result from training: \n",
      "----------------------\n",
      "Learned Motif: \n",
      "[[[[ 1.          0.          0.        ]\n",
      "   [-0.00413892  1.          0.        ]\n",
      "   [ 0.00320702 -0.00236993  1.00045943]\n",
      "   [-0.00274755 -0.00130951 -0.00413892]]]\n",
      "\n",
      "\n",
      " [[[-0.00413892 -0.00130951 -0.00274755]\n",
      "   [ 1.00045943 -0.00236993  0.00320702]\n",
      "   [ 0.          1.         -0.00413892]\n",
      "   [ 0.          0.          1.        ]]]]\n",
      "Learned Bias (b): \n",
      "[[ 0.41219816  0.93809408]]\n",
      "Learned Constant (c): \n",
      "[[ 0.08033095  0.75251955  0.73568124  0.61502761]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYnfP9//HnK5tdWkoQe8SSSCRBxJaMPakS5VKiKD9r\nia1UQqvSHS21hKKU8m0lrVKhqC1Da41sIouE2hW1xNYikvfvj889cUxnOTOZc+4zZ16P6zqXc9/n\nc+77PUfmvOezKyIwMzMrVqe8AzAzs/bFicPMzFrEicPMzFrEicPMzFrEicPMzFrEicPMzFrEicOs\nTCQtJ2mJpHXyjsVsWThxWIcj6QNJ72ePxZL+U3BuVIlvX9TEKUmbSVpU4ljMWqVL3gGYlVtErFL3\nXNI/gaMiYnKZbq8WlPPsXKtIrnFYRyfqfZlLWl7S5ZJek/SSpAskdc5eWyBpt4Kyy0laKGmzBi8u\nfU/S65JeAg6lIBlI2k/SDEnvSXpB0lkFb30Q6FxQE9oqq4VMlvS2pDckXS9ppTb8LMyK0iESR/aL\nPzf7Jf2zpFUbKXeWpNmSnpL0e0ndsvMTJE3LHs9LmpadX07SH7LysyWNLSKWE7Mvn8WSVmvbn9Ta\nyI+ALYG+wNZADXBm9toNwGEFZUcCz0TEM/UvImk/4HhgZ2BzYES9Iu8BoyKiO7AfcLqkPbPXhgKL\nI2KViFg1ImZm538IrAn0AzYFvrcMP6dZq1Rd4pA0TNJ19U7fA/SNiAHAAuCsBt63AXAMMDAi+pOa\n8Q4GiIiDI2JQRAwC/gzckr2t7vX+wDbAcZLWbybEfwC7AS+25uezsjgE+EFEvBsR/wZ+wufJ4kZg\nP0nLZceHZecaciDwm4hYEBH/IX3pLxURkyNibvZ8BvAnYFhjQUXEMxFRGxGLI+JN4JKmypuVStUl\njswX2oYj4r6IWJIdPgas28B73gc+BVaS1AVYEXitgXLfAG7Knr+ele+clf8kuw6S9pD0iKQnJU2U\ntGIWy8yIeIni27qt/NYCXio4fhHoCRARLwDTScnjK8CuwIRGrrMO8HK96yz9/y5pR0m1kt6UtBD4\nFvCVxoKStLakP0p6JSt/TVPlzUqlWhNHU1/K/w+4q/7JiHgXuJD0hfEqsDAi7vvCRaWdgdcj4rns\nPX8jJYp/AS8Av4yIhZJWB74P7BYR2wBTgdOX9YeysvkXsEHB8QakfxN16pqrDgbuj4i3mrjOevWu\nU/hHzUTSHyE9I+JLwO/4/N9uQx3jvwA+BPpk5Y/Gf4BYDqomcUh6LOt7uAbYp6BPYo+CMt8DFkXE\nHxp4/8bAaaRf7nWAlSUdUq/YKD6vbSDpm8AKpL9QNwbOkLQhMAToAzwsaTpwONBcE5ZVjgnAuZJW\nk7QmcDZfbI76E7ATqf/ihiau80fgaEm9Ja0MnFPv9ZWAdyJikaQdSE1bdd4kdY4XJp5VSInjw6xJ\n9Dut+NnMllnVJI6IGJL1QRwNTKrrk4iIewEkHQF8ldR+3ZBtgIcj4p2IWEzqx9ih7sWsOWp/0l+J\ndXYEbo2IJVlb+MPZdQTck91/YERsGRHH1A95WX9maxMN/X/4ATAHmA1MA/5O+ms/vSHiQ+AO0h8Y\nkxq9cMRfgKuz988B7q5X5HjgQknvAWeQEk3dexcCFwBTJb0jqX8W187AQlJf280t+UHN2kxElPQB\nDAfmAfOBMY2UuZTUaT0DGFBw/izSL+9TwO+BbkXcbxjw2wZimA2s3sT7tgJmAcuTvvivB06sd43J\n9d5zct29SH89ziaNxvkKqemqV/baikDveu99vql4/KjsB6nD/Oq84/DDjzweJa1xSOoEjAf2Ig1t\nHCVp83plRmRfsL2B44Ars/ONjnJqhcuAlYF7s+arK7J7rC3pDkid1qRmh6nATFLyuLrgGgdR0EyV\nuQroJmkW8DhwbUQ8HanN+wjgJkkzgUeAzbJ7niTpZVJn60xJV2PtiqQ1SP9//f/OOiRFlK7FRNIQ\n4NyIGJEdjwUiIs4vKHMl6S/5idnxXNK4+U+BR4HtgQ+AW4FLol6HtVk5SToROJ9U23Afg3VIpe7j\n6MkXhyO+kp1rqsyrpFEmzY5yMiu3iLg8IlZ20rCOrGI7x4sc5WRmZmVW6kUOX+WLw1DX5Yvj4evK\nrNdAmWFko5wAJNWNcmpoKK1HKJmZtVBEtGoeUKlrHFOATSRtkK37dDD/O3xxEmmeQ12fyMKIeAN4\nBhiSLTgn0jIdcxu7Ud6jDCrlce655+YeQyU8/Dn4s/Bn0fRjWZS0xhERiyWNJq0V1Yk06miupOPS\ny3F1RNwp6auSngU+Ao7M3jtTUt0op8WkZR48isXMLGcl348jIu4mG4pacO6qesejG3nvLyiYeGVm\nZvmr2M5xa52ampq8Q6gI/hw+58/ic/4s2kZJ53GUi6Sohp/DzKxcJBEV2jluZmZVxonDzMxaxInD\nzMxaxInDzMxapGoSx6xZeUdgZtYxVE3i2G03OP10+OCDvCMxM6tuVZM4nn4a3nkHttgCJk4Ej841\nMyuNqpvH8fDDcMIJsOaaMH48bLZZM282M+uAPI+jwI47wtSpsPfe6fnZZ8NHH+UdlZlZ9ai6xAHQ\npQuceio89RS88AL07Qt/+Yubr8zM2kLVNVU15IEH4MQTYeON4dJLoVevMgZnZlaB3FTVjF13hZkz\nYehQ2G47+OEP4eOP847KzKx96hCJA6BbNxgzBqZNS3M+ttwS7ror76jMzNqfDtFU1ZC774bRo6F/\nf7j4Ylh//ebfY2ZWLdxU1QrDh6e5HwMGwKBBcN558OmneUdlZlb5OmyNo9A//wknnwzPPQeXX576\nRMzMqtmy1DicODIRMGkSnHIKbL89XHghrLNOGwVoZlZh3FTVBiQYORLmzEnDdvv3h4sugkWL8o7M\nzKyyuMbRiPnzU+f566/DFVfATju16eXNzHLlpqoS7TkeATffDKedBrvvDhdckNbAMjNr79xUVSIS\nHHggzJ0LX/lKmvtxxRWweHHekZmZ5afkiUPScEnzJM2XNKaRMpdKWiBphqQB2blNJU2XNC3773uS\nTi51vA1ZZRX45S/T0iUTJ6bZ5088kUckZmb5K2lTlaROwHxgN+A1YApwcETMKygzAhgdEXtL2g64\nJCKGNHCdV4DtIuLlBu5TkqaqhkTA//1fmoW+zz7ws5/B6quX5dZmZm2mkpuqBgMLIuLFiFgETABG\n1iszErgBICIeB7pL6lGvzO7Acw0ljXKT4LDD0uir5ZaDPn3gmmtgyZK8IzMzK49SJ46eQOGX/SvZ\nuabKvNpAmYOAm9o8umXwpS+llXbvvhuuvTbt/TF9et5RmZmVXpe8A2iOpK7AvsDYpsqNGzdu6fOa\nmhpqampKGledgQPTroPXXZeWMTnoIPjxj6F797Lc3sysKLW1tdTW1rbJtUrdxzEEGBcRw7PjsUBE\nxPkFZa4EJkfExOx4HjAsIt7IjvcFTqi7RiP3KVsfR1PefhvOOgvuuCMN3f3mN1PTlplZpankPo4p\nwCaSNpDUDTgYmFSvzCTgcFiaaBbWJY3MKCqsmaoxq68OV18Nt94Kv/oV7LILzJ6dd1RmZm2rpIkj\nIhYDo4F7gNnAhIiYK+k4ScdmZe4Enpf0LHAVcELd+yWtSOoYv6WUcba1uuG63/gG1NTAGWfABx/k\nHZWZWdvwzPESe/NNOPNMuP/+tHDigQe6+crM8uclRyo4cdT5+9/TvudrrQWXXQabbZZ3RGbWkVVy\nH4dldt4Zpk6FESPS0N3vfx/+85+8ozIzazknjjLq2jUtmPjUU2nTqL590x4gZmbtiZuqcnT//an5\nqndvuOSStA+ImVk5uKmqndptt1T72HFHGDwYfvQj+PjjvKMyM2uaE0fOunWDsWNh2jSYMQP69UvL\nmJiZVSo3VVWYu+6Ck06CrbaCiy+G9dbLOyIzq0ZuqqoiI0bA00+nPc8HDoTzz4dPP807KjOzz7nG\nUcGeew5OPhmefx4uvzwtYWJm1hY8AbBKEwekjaNuuw1OOSV1ol94Iay9dt5RmVl756aqKibBfvul\njaM23DA1YV18MXz2Wd6RmVlH5RpHOzNvHoweDf/+N1xxRaqFmJm1lJuqOlDigNR89cc/wumnwx57\npA70NdfMOyoza0/cVNXBSGmnwblzYbXVYMst4de/hsWL847MzDoC1ziqwKxZcMIJadb5FVfAttvm\nHZGZVTrXODq4fv3goYfSxMF994Xjj4d33sk7KjOrVk4cVUKCww9PzVddukCfPvDb38KSJXlHZmbV\nxk1VVWraNPj2t1MSufxyGDAg74jMrJK4qcr+x6BB8OijcMQRsNdeaQLhe+/lHZWZVQMnjirWqRMc\ncwzMnp12G9xiC/j979NwXjOz1nJTVQfy2GNp9FX37qn5qk+fvCMys7y4qcqKMmQITJkCBxwAw4bB\nmWfChx/mHZWZtTdOHB1M585pyZKnn4bXX0+1jptvdvOVmRWv5IlD0nBJ8yTNlzSmkTKXSlogaYak\nAQXnu0v6k6S5kmZL2q7U8XYUPXrADTfA//0fjBsHw4fDggV5R2Vm7UGziUPSLZL2ltTiJJO9Zzyw\nF9AXGCVp83plRgC9IqI3cBxwZcHLlwB3RsQWwFbA3JbGYE0bOhSmT4c994Ttt4dzzkkd6WZmjSkm\nGVwBHAIskHSepM1acP3BwIKIeDEiFgETgJH1yowEbgCIiMeB7pJ6SFoV2Dkirste+ywi3m/Bva1I\nXbumBRNnzoT586FvX7j99ryjMrNK1WziiIj7IuKbwCDgBeA+SY9IOlJS12be3hN4ueD4lexcU2Ve\nzc5tBLwl6TpJ0yRdLWmF5uK11uvZEyZOhN/8Bs44Iy1f8vzzeUdlZpWmSzGFJK0OHAocBkwHfg/s\nBHwLqClhbIOAEyPiSUkXA2OBcxsqPG7cuKXPa2pqqKkpVVjVb/fd4amn0m6D224Lp54K3/0uLLdc\n3pGZWWvV1tZSW1vbJtdqdh6HpFuBzYAbgesj4l8Frz0ZEds08d4hwLiIGJ4djwUiIs4vKHMlMDki\nJmbH84Bh2cuPRsTG2fmdgDERsU8D9/E8jhJ54YWUOObMgfHjU1+ImbV/pZ7HcWlE9ImInxcmDYCm\nkkZmCrCJpA0kdQMOBibVKzMJOByWJpqFEfFGRLwBvCxp06zcbsCcIuK1NrThhvCXv8CvfpVW3T3w\nQHjllbyjMrM8FVPj2L+B0+8BsyLizWZvIA0njY7qBFwbEedJOo5U87g6KzMeGA58BBwZEdOy81sB\n1wBdgX9mr/3PikuucZTHf/8L552XZp2PGZNqIl2b6+Uys4pU0q1jJf0V2B6YnJ2qAaaSOq9/FBE3\ntubGbcmJo7yefTbt/fHSS2njqGHDmn+PmVWWUieOe4DDsqYjJPUgDZ8dBTwUEVu25sZtyYmj/CLg\n1ltTrWPoUPjlL2GttfKOysyKVeo+jnXrkkbmTWC9iHgHWNSam1r7J8H++6eNo9ZdN+1CeOml8Nln\neUdmZqVWTI3jCmB94E/ZqQNI8zG+C9wREbuUNMIiuMaRv7lz4cQT4d13U/PV9tvnHZGZNaXUTVUC\n9ifN2wB4GPhzJX1TO3FUhgiYMCFNHhw+PHWkr7FG3lGZWUNK1lQlqTPwQET8OSJOyx43+1vaGiLB\nqFGp9rHqqmnpkquugsWL847MzNpSMTWO+4H9GxoGWylc46hMTz2VNo769NPUfLVNc7N+zKxsSt1U\ndRswELiXNM8CgIg4uTU3LAUnjsq1ZElavn3s2NSZ/tOfwpe/nHdUZlbqUVW3AOcAD5Hmb9Q9zJrV\nqRMccURqvoK0cdT116eEYmbtU1F7jmer0q4fEc+UPqSWc42j/XjyydR81a1bar7q3z/viMw6ppLW\nOCTtA8wA7s6OB0iqv96UWVG22QYefRQOOyytwnvaafC+d1kxa1eKaaoaR9qQaSFARMwANi5hTFbl\nOneG446D2bNT0thiC7jpJu97btZeFJM4FjUwosot1LbM1lgDrr0W/vQnOP982G23z/tCzKxyFZM4\nZks6BOgsqbeky4BHShyXdSA77JD6PvbbL617NXYsfPRR8+8zs3wUkzhOAvoCnwA3Ae8Dp5YyKOt4\nunSBk0+GWbPSfh99+sAtt7j5yqwSFTWqqtJ5VFX1qa1Na1+tvz5cdhlsskneEZlVl1KPqtpU0tWS\n7pH0QN2jNTczK1ZNDcyYAbvuCkOGwLnnpo2kzCx/xcwcnwlcSZr0t3TVoYiomEmArnFUt1deScN2\np01LS7fvvXfeEZm1f6VecmRqRGzdqsjKxImjY7jnHhg9OvV/XHxx2g/dzFqn1EuO3C7pBElrS1qt\n7tGam5ktiz33TJ3n226bJhL+7GfwySd5R2XW8RRT43i+gdMRERUzCdA1jo7n+efhlFPgmWfg8svT\nLHQzK15Jm6raAyeOjuv229Mw3sGD4aKLoGfPvCMyax9K0lQl6cyC5wfWe+1nrbmZWVvbZ5+0dMmm\nm8JWW8GFF8KiRXlHZVbdGq1xSJoWEYPqP2/oOG+ucRjAggWp8/zVV9PKu0OH5h2RWeUqVee4Gnne\n0HHjF5GGS5onab6kMY2UuVTSAkkzJA0sOP+CpJmSpkt6oth7WsfUuzfcfTf88Idw6KFpBd7XX887\nKrPq01TiiEaeN3TcIEmdgPHAXqRlS0ZJ2rxemRFAr4joDRwH/Lrg5SVATUQMjIjBxdzTOjYJDjgA\n5syBddaBfv1g/Hjve27WlppKHFtJel/SB0D/7Hndcb8irz8YWBARL0bEImACMLJemZHADQAR8TjQ\nXVKP7DU1E6NZg1ZeOa24++CDcPPNaQjvY4/lHZVZdWj0SzkiOkfEqhGxSkR0yZ7XHXct8vo9gZcL\njl/JzjVV5tWCMgHcK2mKpGOKvKfZUn36wOTJcPrpac/zY46Bt97KOyqz9q1L3gE0Y8eI+JekNUgJ\nZG5E/KOhguPGjVv6vKamhpqamvJEaBVPgm9+E772NfjBD6BvX/jJT+Coo9Ke6GYdQW1tLbW1tW1y\nrZLO45A0BBgXEcOz47GkyYPnF5S5EpgcEROz43nAsIh4o961zgU+iIiLGriPR1VZ0WbMSPueL16c\nRl9tXdEL6piVRqmXHFkWU4BNJG0gqRtwMFB/v/JJwOGwNNEsjIg3JK0oaeXs/ErAnsDTJY7XOoAB\nA+Af/4Djj08LJp54Irz7bt5RmbUfRSWO7It/9+z5CpJWKeZ9EbEYGA3cA8wGJkTEXEnHSTo2K3Mn\n8LykZ4GrgBOyt/cA/iFpOvAYcHtE3NOCn82sUZ06wZFHptFXS5akvpAbbvDGUWbFKGatqmOAY4HV\nIqKXpN7AlRGxWzkCLIabqmxZTZkC3/42rLhiWvuqX7HjBs3aqVI3VZ0I7EjaMpaIWACs2ZqbmVWq\nbbeFxx+HUaNgt93SKKwPPsg7KrPKVEzi+CQiPq07kNSFIicAmrUnnTunWsfTT8M778AWW8CECW6+\nMquvmKaqC4CFpA7sk0h9EHMi4nulD684bqqyUnj44TT6ao010uzzzTdv/j1m7UWpm6rGAv8GZpGW\nBLkT+H5rbmbWnuy4I0ydmlbg3XlnOOss+OijvKMyy19R8zgkrQCsHxHPlD6klnONw0rtX/+CM85I\nw3gvuQRGjkwTC83aq1LvOb4v8AugW0RsJGkA8KOI2Lc1NywFJw4rl8mT07yPjTaCSy+FXr3yjsis\ndUrdVHUuabHChQARMQPYqDU3M2vvdtklzTwfOhS22y4t4f7xx3lHZVZexSSORRHxXr1z/vPeOqxu\n3WDMGJg2DWbNgi23hDvvzDsqs/IpJnHMlnQI0FlSb0mXAY+UOC6zirf++mnJ9vHj4ZRT4Otfhxdf\nzDsqs9IrJnGcRNqE6RPgD8B7wKmlDMqsPRk+PNU8Bg1KCyb+/Ofw6afNv8+svWqyc1xSZ+D8iDij\nfCG1nDvHrVL885+p9rFgQVq6ZLeKWZjH7ItKParqsYgY0qrIysSJwyrNpElw8skwZAhcdFHaxtas\nkpR6VNV0SZMkHSZp/7pHa25m1lHsu29aebdXL+jfPyWPRYvyjsqsbRRT47iugdMREf+vNCG1nGsc\nVsnmz4fRo+H111Pz1c475x2RWYmbqtoDJw6rdBFpBNZ3vgO77goXXAA9euQdlXVkJWmqknRPwfOz\nWnNxM0skOPDA1Hy15ppp7sfll6fta83am0ZrHJKmR8TA7Pm0iBhU1shawDUOa29mz04r7374Ydr3\nfLvt8o7IOppSdY77m9isRPr2hdpaOO20NHHw2GPh7bfzjsqsOE0ljo2z0VS3Fzxf+ihXgGbVSoJD\nD03NV8svn/Y9v+aatAe6WSVrqqlqWFNvjIgHSxJRK7ipyqrB9Omp+QpS89XAgfnGY9XNo6qcOKxK\nLFkC110HZ58N3/gG/PjH8KUv5R2VVaNSTwA0szLp1AmOOio1X336aWq+uvFG73tulcU1DrMK9sQT\n8O1vw8orp+G7W26Zd0RWLcpS45C0YmtuIGm4pHmS5ksa00iZSyUtkDQj22Gw8LVOkqa5Q946osGD\nU/I46KA0cfCMM+CDD/KOyjq6ZhOHpB0kzQHmZcdbSbqimItL6gSMB/YiLc0+StLm9cqMAHpFRG/g\nOODKepc5BZhTzP3MqlHnzqnT/Omn4a23UvPVH//o5ivLTzE1jl+RvvjfBoiImcDQIq8/GFgQES9G\nxCJgAjCyXpmRwA3ZtR8HukvqASBpXeCrwDVF3s+saq25Jlx/PfzhD/CTn8Bee8Ezz+QdlXVERTVV\nRcTL9U4Vu1BCT6Dwva9k55oq82pBmV8B38WTEc2W2nlnmDoVRoyAHXeE730P/vOfvKOyjqRLEWVe\nlrQDEJK6kpqO5pY2LJC0N/BGRMyQVAM02Ykzbty4pc9ramqoqakpZXhmueraNc06P+ggOP301Hx1\nySVpOXe1qrvTql1tbS21tbVtcq1illX/CnAJsDvpy/se4JSIaHaBBElDgHERMTw7Hktakv38gjJX\nApMjYmJ2PA8YRkpQhwKfASsAqwC3RMThDdzHo6qsQ7v//rR0e69ecOmlsPHGeUdkla6ko6oi4q2I\n+GZE9IiINSPi0GKSRmYKsImkDSR1Aw4G6o+OmgQcDksTzcKIeCMizo6I9SNi4+x9DzSUNMwsbVE7\ncybstFMaifWjH8HHH+cdlVWrZpuqJF3awOn3gCcj4ram3hsRiyWNJtVSOgHXRsRcScell+PqiLhT\n0lclPQt8BBzZ8h/DzLp1g7Fj4ZBD4NRToV8/uOwyGD4878is2hTTVHU1sDnwp+zUAcDzwOrAPyPi\n1JJGWAQ3VZn9r7vugpNOgq22gosvhvXWyzsiqySlngDYH9glIi6LiMtIfR2bA18H9mzNTc2s9EaM\nSHM/+vdPCyaef35axsRsWRWTOL4MrFxwvBKwWkQsBj4pSVRm1iaWXx7OPRcefxweeggGDIDJk/OO\nytq7YobjXgDMkFRLGlU1FPiZpJWA+0oYm5m1kV694I474Lbb4MgjYYcd4MILYe21847M2qOiFjmU\ntDZpFjjAlIh4raRRtZD7OMyK99FH8NOfwm9+kyYPjh4NXYr5E9KqSsn345D0ZaA3sHzduYh4qDU3\nLAUnDrOWmzcvJY1//zttHLXjjnlHZOVU0sQh6WjSZLx1gRnAEODRiNi1NTcsBScOs9aJSAsmnn46\n7LFH6kBfc828o7JyKPWoqlOAbYEXI2IXYCCwsDU3M7PKIqVlS+bOhdVWS/t9/PrXsLjY1eisQyom\ncXwcER8DSFouIuYBm5U2LDMrp1VWSZ3l998PN90EQ4bAlCl5R2WVqpjE8YqkLwF/Ae6VdBvwYmnD\nMrM89OsHDz6YJg7uuy8cfzy8807eUVmladHWsZKGAd2BuyOiYqYSuY/DrO0tXAjf/z7cfDP87Gdw\nxBFpT3SrDiXrHJfUGZgdEZs3WqgCOHGYlc60aWnf8y5d0r7nAwY0/x6rfCXrHM9mhz8jaf1WRWZm\n7d6gQfDoo6nGsddecMop8N57eUdleSp2yZHZku6XNKnuUerAzKxydOoExxwDs2en3Qa32AJ+/3vv\ne95RFTOPY1hD5yPiwZJE1ApuqjIrr8cegxNOgO7dU/NVnz55R2QtVeqNnB4EXgC6Zs+nANNaczMz\nqw51w3UPOACGDYMzz4QPP8w7KiuXZhOHpGOAm4GrslM9SUNzzawD69w5LVny9NPw+uup1nHzzW6+\n6giKaaqaQVrg8PGIGJidmxUR/coQX1HcVGWWv4ceSs1XPXvC+PHQu3feEVlTSr3kyCeFczYkdQH8\nLW1mXzB0KEyfDnvuCdtvD+eckzrSrfoUkzgelHQ2sIKkPUhbyN5e2rDMrD3q2jUtmDhzJsyfD337\nwu3+tqg6xTRVdQKOIm0TK+BvwDWV1DbkpiqzynTffXDiibDZZnDJJbDRRnlHZHVKvaz6/sBfI6Ji\nt4l14jCrXJ98khZQvOgiOPVU+O53Ybnl8o7KSt3HsQ8wX9KNkr6W9XGYmRVlueXg7LPhySdh6tS0\nkOLf/pZ3VLYsit0BsCswAjgI2Am4NyKOLnFsRXONw6z9+Otf0+q7W28Nv/oVrLtu3hF1TKWucRAR\ni4C7gAnAVGC/FgQ3XNI8SfMljWmkzKWSFkiaIWlAdm45SY9Lmi5ptqSfFXtPM6tce++dli7p0yct\nmPiLX8CiRXlHZS1RzATAEZKuBxYABwDXAGsVc/GsY308sBfQFxglafN6ZUYAvSKiN3AccCVA1qey\nSzZ3pD+wqyTvimxWBVZYAX74w7R0yQMPpARSW5t3VFasYmoch5Nmim8WEUdExJ0R8VmR1x8MLIiI\nF7NaywRgZL0yI4EbACLicaC7pB7Zcd0o8OWyWN8t8r5m1g5ssgnceSf8+MfwrW/BoYemWehW2YpZ\nq2pURPylblSVpJ0kXV7k9XsCLxccv5Kda6rMq3VlJHWSNB14HaiNiDlF3tfM2gkJ9t8f5sxJ/R39\n+qWhu58V++eplV1RI6QkDQQOAQ4EngduKWVQdSJiCTBQ0qrAPZKGNbYq77hx45Y+r6mpoaamphwh\nmlkbWWniaMQeAAAPPElEQVQlOO+8VPMYPRquuw6uuAJ22CHvyKpDbW0ttW3UHtjoqCpJmwKjgIOB\nN0kzxr8bERsUfXFpCDAuIoZnx2OBiIjzC8pcCUyOiInZ8TxgWES8Ue9a5wD/iYgLG7iPR1WZVZEI\nmDgxzUIfPjwllDXWyDuq6lKqUVXzgK2BPSNiWESMBxa38PpTgE0kbSCpGykJ1d8EahKpH6Uu0SyM\niDckfUVS9+z8CsAewIwW3t/M2iEJDj4Y5s5Ne3707QtXXQWLW/oNZCXRVOLYH/gP8JCkKyXtSlpy\npGjZ1rOjgXuA2cCEiJgr6ThJx2Zl7gSel/Qsaen2E7K3rw1Mzvo4HgMmRcT9Lbm/mbVvq66aZpzf\ndx/ceGNaPPHJJ/OOyopZcmQl0sinUcCupBFQt0bEPaUPrzhuqjKrfkuWwA03wNixqTP9pz+FL385\n76jar1LvAPhRRPwhIvYB1gWmAw1O5DMzK5VOneCII1LzlZT2Pb/uupRQrLyKWnKk0rnGYdbxTJ2a\nNo7q2jXte77VVnlH1L6UfMkRM7NKs/XW8OijcPjhsMcecNpp8P77eUfVMThxmFm71akTHHtsmjz4\nwQep+eqmm7zveam5qcrMqsYjj6Tmq9VWS81XW2yRd0SVy01VZmakWeZPPgn77Zf2QB8zBj78MO+o\nqo8Th5lVlS5d4OSTYdYseO21tHz7n//s5qu25KYqM6tqDz6Ymq/WWw8uuwx69847osrgpiozs0YM\nGwYzZsDuu6eZ5+eeC//9b95RtW9OHGZW9bp2hTPOSAlk7lzYcsu0ha21jpuqzKzDueeetHR7nz5w\n8cWw4YZ5R1R+bqoyM2uBPfdMnefbbgvbbJPWvfrkk7yjaj+cOMysQ1puOfje99Lw3SeegP794d57\n846qfXBTlZkZcMcdaRjvNtukpdzXXTfviErLTVVmZsvoa1+D2bNh881hwAD45S9h0aK8o6pMrnGY\nmdWzYAGcdBK88kra93zo0LwjanvLUuNw4jAza0AE3HJLWnV32DD4xS9grbXyjqrtuKnKzKyNSXDA\nAWnl3XXWgX790szzzz7LO7L8ucZhZlaEOXPgxBNh4UL49a9hyJC8I1o2rnGYmZVYnz7wwAPw3e+m\nmsjRR8Nbb+UdVT6cOMzMiiTBIYek2sfKK0PfvnD11R1v33M3VZmZtdLMmWnl3c8+S6Ovtt4674iK\n56YqM7McbLUV/P3vcPzxsPfeqQ/k3Xfzjqr0Sp44JA2XNE/SfEljGilzqaQFkmZIGpCdW1fSA5Jm\nS5ol6eRSx2pm1lKdOsGRR6bmqyVLUl/I735X3RtHlbSpSlInYD6wG/AaMAU4OCLmFZQZAYyOiL0l\nbQdcEhFDJK0FrBURMyStDEwFRha+t+Aabqoys4owZUpqvlp++dR81a9f3hE1rJKbqgYDCyLixYhY\nBEwARtYrMxK4ASAiHge6S+oREa9HxIzs/IfAXKBnieM1M1sm224Ljz0G3/wm7LYbfOc78P77eUfV\ntkqdOHoCLxccv8L/fvnXL/Nq/TKSNgQGAI+3eYRmZm2sc+fU7zF7dpr30acPTJhQPc1XXfIOoDlZ\nM9XNwClZzaNB48aNW/q8pqaGmpqaksdmZtaUNdaA3/4WHn44NV9dcw2MH58WUiy32tpaamtr2+Ra\npe7jGAKMi4jh2fFYICLi/IIyVwKTI2JidjwPGBYRb0jqAtwB3BURlzRxH/dxmFlF++wzuPxy+MlP\n0uTB738fVlopv3gquY9jCrCJpA0kdQMOBibVKzMJOByWJpqFEfFG9tpvgTlNJQ0zs/agSxc45RR4\n6il46aXUfHXrre2z+arkEwAlDQcuISWpayPiPEnHkWoeV2dlxgPDgY+AIyJiuqQdgYeAWUBkj7Mj\n4u4G7uEah5m1K5Mnp3kfG26YFk/s1au89/ey6k4cZtYOffopXHwxXHABjB4NY8bACiuU596V3FRl\nZmaN6NYNzjwTpk+Hp5+GLbeEO+/MO6rmucZhZlYh/va3VPPYcstUE9lgg9LdyzUOM7MqsNdeMGsW\nDBqUFkz8+c9Tc1alceIwM6sgyy8P55wDTzwBjzwC/fvD/ffnHdUXuanKzKyCTZqUhvFutx1ceCH0\nbKOFl9xUZWZWpfbdNy1dsskmaRn3iy6CRYvyjck1DjOzdmL+/NR5/q9/pZV3d9659dfyPA4nDjPr\nICLg5pvTqru77prmgPTo0fLruKnKzKyDkODAA9PGUWuumYbuXn45LF5cxhiq4S911zjMrKOaPTut\nvPvhh6n5arvtinufaxxmZh1U375QWwunnQZf/zoceyy8/XZp7+nEYWbWzklw6KGp+Wr55dPKu9dc\nk/ZAL8n9qqGJx01VZmafmz49NV9Bar4aOPB/y7ipyszMlho4MO06ePTRMHw4nHRS2sK2rThxmJlV\noU6d4KijUvPVp5+m5qsbb2ybjaPcVGVm1gE88QR8+9uw8spp+G6/fm6qMjOzJgwenJLHQQeliYPL\nwjUOM7MO5s03oUcPLznixGFm1gIeVWVmZmXjxGFmZi3ixGFmZi1S8sQhabikeZLmSxrTSJlLJS2Q\nNEPSwILz10p6Q9JTpY7TzMyKU9LEIakTMB7YC+gLjJK0eb0yI4BeEdEbOA74dcHL12XvtSLV1tbm\nHUJF8OfwOX8Wn/Nn0TZKXeMYDCyIiBcjYhEwARhZr8xI4AaAiHgc6C6pR3b8D+DdEsdYVfyLkfhz\n+Jw/i8/5s2gbpU4cPYGXC45fyc41VebVBsqYmVmFcOe4mZm1SEknAEoaAoyLiOHZ8VggIuL8gjJX\nApMjYmJ2PA8YFhFvZMcbALdHRP8m7uPZf2ZmLdTaCYBd2jqQeqYAm2Rf/v8CDgZG1SszCTgRmJgl\nmoV1SSOj7NGo1v7wZmbWciVtqoqIxcBo4B5gNjAhIuZKOk7SsVmZO4HnJT0LXAWcUPd+SX8AHgE2\nlfSSpCNLGa+ZmTWvKtaqMjOz8mk3neOtmEg4oNwxlktzn4WkQyTNzB7/kNQvjzjLoZh/F1m5bSUt\nkrR/OeMrpyJ/R2okTZf0tKTJ5Y6xXIr4HVld0l3Zd8UsSUfkEGbJFTOJulXfmxFR8Q9SgnsW2ADo\nCswANq9XZgTw1+z5dsBjeced42cxBOiePR/ekT+LgnL3A3cA++cdd47/LrqTmox7ZsdfyTvuHD+L\nc4Gf130OwNtAl7xjL8FnsRMwAHiqkddb9b3ZXmocyzSRsMo0+1lExGMR8V52+BjVOy+mmH8XACcB\nNwNvljO4MivmszgE+HNEvAoQEW+VOcZyKeazeB1YJXu+CvB2RHxWxhjLIpqfRN2q7832kjg8kfBz\nxXwWhY4G7ippRPlp9rOQtA6wX0T8mmZG57Vzxfy72BRYTdJkSVMkHVa26MqrmM/iN0BfSa8BM4FT\nyhRbpWnV92aph+NajiTtAhxJqq52VBcDhW3c1Zw8mtMFGATsCqwEPCrp0Yh4Nt+wcnEWMDMidpHU\nC7hXUv+I+DDvwNqD9pI4XgXWLzheNztXv8x6zZSpBsV8FkjqD1wNDI+Ial3vq5jPYhtggiSR2rJH\nSFoUEZPKFGO5FPNZvAK8FREfAx9LegjYitQfUE2K+Sx2BH4KEBHPSXoe2Bx4siwRVo5WfW+2l6aq\npRMJJXUjTSSs/4s/CTgcls5Yrz+RsFo0+1lIWh/4M3BYRDyXQ4zl0uxnEREbZ4+NSP0cJ1Rh0oDi\nfkduA3aS1FnSiqTO0LlljrMcivks5gK7A2Rt+psC/yxrlOXT1CTqVn1vtosaR0QsllQ3kbATcG1k\nEwnTy3F1RNwp6avZRMKPSE00VaeYzwI4B1gNuCL7S3tRRAzOL+rSKPKz+MJbyh5kmRT5OzJP0t+A\np4DFwNURMSfHsEuiyH8XPweukzST9KV6ZkS8k1/UpZFNoq4BVpf0Emk0WTeW8XvTEwDNzKxF2ktT\nlZmZVQgnDjMzaxEnDjMzaxEnDjMzaxEnDjMzaxEnDjMzaxEnDmt3JC2R9IuC49Ml/aCNrn1dWy69\nLmlVSb/Llq1eIOl6SasWvP6LbFnv8+u971uS3pQ0LVsGfZqkzdswrnMlfaetrmcdixOHtUefAPtL\nWi3vQApJ6tzA6WuB5yKid0T0Bl4Aril4/Rigf0Q0tH/GhIgYFBEDs//Oa/uozVrOicPao89I63D9\nz1/M9WsMkj7I/jtMUq2kv0h6VtJ5kg6V9ES24dVGBZfZI1s9dp6kvbP3d5J0gaTHsw1vjim47kOS\nbiPtdVEYSy/SooI/Ljj9I2BrSRtl71kZmCrpwAZ+zv9ZJiK734OS7sjiu6LgtVGSnsoe5xWcHy5p\nahb3vQWX65utlPuspJMauL9Zg9rFkiNm9QRwOfA/TTyNlK3Tn7SQ3ULgeeA3ETFY0smkPTvqEtEG\nEbGtpE2AyVkC+BZpHZ/tsvWPHpZ0T1Z+INA3Il6qd+8+wIwoWJ4hIpZky1z0jYiRkt6PiEGNxH6Q\npB1JCSSA7bPz2wJbAC8Bf8sS5aPAeVksC0mrve4LPEJKsjtFxEuSvlRw/c1Iy1F0B56RdEVELG78\nozRLnDisXYqIDyX9jrSPwn+LfNuUiHgTIFub52/Z+VmkL9A6f8zu8ayk50jJZk+gX0HNYFWgN7AI\neKKBpFGsppZ5nxARJ3+hsER2vxez45tIy+Z/BkyuW29J0u+BocAS4MG6+CJiYcHl/pptXvS2pDeA\nHsBrrfw5rANx4rD27BJgGnBdwbnPyJpgswUeuxW89knB8yUFx0v44u9CYS2l7q99ASdFRGFTD5KG\nkRaHa8gc0radheWVnatr1mrNYnH13xMFMTaksfP1Pw9/H1hR3Mdh7ZEAsn1G/ggcVfDaC6Q9OCBt\ni9m1Fdc/UEkvYCPgGVLt5ARJXQAk9VZamrxR2ZL20yWdU3D6HGBqRDxf+LM0orHXBistGd4JOAj4\nB2kp8aGSVss66UcBtaStg3eWtEEW95ebitmsGP4Lw9qjwr+4LwROLDj3G+A2SdNJX/aN1Qaa+kv/\nJeAJ0l7Ux0XEp5KuATYEpmW1hjeB/YqI9ShgfNY0FqS+iMJE11Qc36jXx3FCdv5JYDywCfBARNwK\nIGksKVkA3BERd2TnjwVuLYh7rwbu5WWyrWheVt2sHcmaxk6PiH3zjsU6LjdVmZlZi7jGYWZmLeIa\nh5mZtYgTh5mZtYgTh5mZtYgTh5mZtYgTh5mZtYgTh5mZtcj/B5ZVQOhkCqumAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f2d4c6fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theano.config.profile=True\n",
    "\n",
    "#initialize the learner and set custom kernels\n",
    "x = CRBM(5, 2, .1, 1)\n",
    "print \"Motifs:\"\n",
    "print x.motifs.get_value()\n",
    "kernel1 = np.tile(np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,0]]), [1,1,1])\n",
    "kernel1_ = np.tile(np.flipud(np.fliplr(kernel1[0])),[1,1,1])\n",
    "kernel2 = np.tile(np.array([[0,0,0],[0,0,0],[1,1,1],[0,0,0]]), [1,1,1])\n",
    "kernel2_ = np.tile(np.flipud(np.fliplr(kernel2[0])), [1,1,1])\n",
    "kernel3 = np.random.rand(1,4,3)\n",
    "kernel3_ = np.tile(np.flipud(np.fliplr(kernel3[0])), [1,1,1])\n",
    "kernel = np.array([kernel1, kernel1_])#, kernel2, kernel2_, kernel3, kernel3_])\n",
    "#kernel = np.array([kernel3, kernel3_])\n",
    "print \"Kernel: \" + str(kernel)\n",
    "# initialize the data\n",
    "randSeq1 = getMatrixFromSeq(Seq(\"ACGTGGGG\", IUPAC.unambiguous_dna))\n",
    "randSeq2 = getMatrixFromSeq(Seq(\"ACGTACGT\", IUPAC.unambiguous_dna))\n",
    "data = np.array([randSeq1], dtype=np.float32)\n",
    "print \"Data shape: \" + str(data.shape)\n",
    "x.setCustomKernels(kernel)\n",
    "print data\n",
    "\n",
    "# perform training on our test data\n",
    "start = time.time()\n",
    "scores = x.trainMinibatch(data, data, 1, 1, 1)\n",
    "print \"Training (with compilation) performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "print \"Result from training: \"\n",
    "print \"----------------------\"\n",
    "print \"Learned Motif: \"\n",
    "print x.motifs.get_value()\n",
    "print \"Learned Bias (b): \"\n",
    "print x.bias.get_value()\n",
    "print \"Learned Constant (c): \"\n",
    "print x.c.get_value()\n",
    "plt.ylabel('Average Free Energy')\n",
    "plt.xlabel('Number Of Epoch')\n",
    "plt.title('Toy data')\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 1, 4, 150)\n",
      "11969.0039062\n"
     ]
    }
   ],
   "source": [
    "theano.config.mode='FAST_RUN'\n",
    "learner = CRBM(3, 20, 0.0000001, 2)\n",
    "f = learner.getFreeEnergyFunction()\n",
    "x = f(trainingData)\n",
    "print trainingData.shape\n",
    "print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 4: Test our GPU solution on the \"real\" training set\n",
    "It's time now to test on some real data to see how good the training is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mat shape: (15000, 1, 4, 150)\n",
      "BatchSize: 10\n",
      "Num of iterations per epoch: 1500\n",
      "Compilation of theano function finished in 4.32401514053 seconds\n",
      "Start training...\n",
      "Initial Reconstruction Error: 12184.5146484\n",
      "[Epoch 0] Reconstruction Error: 12112.5507812\n",
      "[Epoch 1] Reconstruction Error: 12003.9375\n",
      "[Epoch 2] Reconstruction Error: 11863.1064453\n",
      "[Epoch 3] Reconstruction Error: 11690.3857422\n",
      "[Epoch 4] Reconstruction Error: 11487.9355469\n",
      "[Epoch 5] Reconstruction Error: 11265.6923828\n",
      "[Epoch 6] Reconstruction Error: 11059.6523438\n",
      "[Epoch 7] Reconstruction Error: 10894.9042969\n",
      "[Epoch 8] Reconstruction Error: 10771.5976562\n",
      "[Epoch 9] Reconstruction Error: 10667.4111328\n",
      "[Epoch 10] Reconstruction Error: 10573.3310547\n",
      "[Epoch 11] Reconstruction Error: 10484.9335938\n",
      "[Epoch 12] Reconstruction Error: 10398.5214844\n",
      "[Epoch 13] Reconstruction Error: 10310.3974609\n",
      "[Epoch 14] Reconstruction Error: 10223.4375\n",
      "[Epoch 15] Reconstruction Error: 10135.3369141\n",
      "[Epoch 16] Reconstruction Error: 10043.3378906\n",
      "[Epoch 17] Reconstruction Error: 9949.96582031\n",
      "[Epoch 18] Reconstruction Error: 9852.84863281\n",
      "[Epoch 19] Reconstruction Error: 9752.03320312\n",
      "[Epoch 20] Reconstruction Error: 9647.18847656\n",
      "[Epoch 21] Reconstruction Error: 9538.31835938\n",
      "[Epoch 22] Reconstruction Error: 9429.27539062\n",
      "[Epoch 23] Reconstruction Error: 9321.45898438\n",
      "[Epoch 24] Reconstruction Error: 9219.80273438\n",
      "[Epoch 25] Reconstruction Error: 9128.58203125\n",
      "[Epoch 26] Reconstruction Error: 9046.81738281\n",
      "[Epoch 27] Reconstruction Error: 8972.69921875\n",
      "[Epoch 28] Reconstruction Error: 8905.24121094\n",
      "[Epoch 29] Reconstruction Error: 8838.97949219\n",
      "Training finished after: 457.51098299 seconds!\n",
      "Training of 15000 performed in: 461.858114958 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEZCAYAAADolEC/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc86VFE98zjnnSsr/B6OOkwl9kvkDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f2e4e2190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theano.config.mode='FAST_RUN'\n",
    "theano.config.profile=True\n",
    "\n",
    "learner = CRBM(3, 20, 0.001, 2)\n",
    "print \"Data mat shape: \" + str(trainingData.shape)\n",
    "start = time.time()\n",
    "scores = learner.trainMinibatch(trainingData, testingData, 30, 10, 1)\n",
    "print \"Training of \" + str(trainingData.shape[0]) + \" performed in: \" + str(time.time()-start) + \" seconds.\"\n",
    "plt.plot(scores)\n",
    "plt.ylabel('Average free energy over test set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('The free energy over training time and training data (huge overfitting)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test how one could implement the derivatives for both strands\n",
    "We want the derivative of the data and model to not be independent from each other.\n",
    "So we have to do the following:\n",
    "* Go through the different kernels and sum pairs of even and uneven kernels together (diff. strands)\n",
    "* Once that is done, we have to set the uneven rows to the reverse complement of the even rows\n",
    "* It all has to be in theano and efficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "idxes = T.ivector(\"indices\")\n",
    "output_model = T.matrix(\"output_model\")\n",
    "\n",
    "def sumWithNext(idx, output_model):\n",
    "    sub1 = output_model[idx]\n",
    "    sub2 = output_model[idx+1]\n",
    "    out1 = T.set_subtensor(sub1, sub1 + sub2)\n",
    "    return out1\n",
    "\n",
    "\n",
    "result, updates = theano.scan(fn=sumWithNext,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "sumItUp = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "def setToReverseComplement(idx, output_model):\n",
    "    sub1 = output_model[idx]\n",
    "    revCom = output_model[idx-1][::-1]\n",
    "    return T.set_subtensor(sub1, revCom)\n",
    "\n",
    "result, updates = theano.scan(fn=setToReverseComplement,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "revertIt = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "# test\n",
    "test_locations = np.asarray([0, 2], dtype=np.int32)\n",
    "test_output_model = np.eye(4, 5, dtype=np.float32)\n",
    "x = sumItUp(test_locations, test_output_model)[-1]\n",
    "#print x\n",
    "res = revertIt(test_locations + 1, x)[-1]\n",
    "print res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do this for the correct dimensionality (tensor4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.53  1.49  1.17  1.7   1.18  1.39]\n",
      "   [ 1.28  0.46  1.2   0.85  0.29  0.91]\n",
      "   [ 0.14  0.29  1.26  0.85  1.    0.93]\n",
      "   [ 0.62  1.38  1.38  1.    0.72  1.76]]\n",
      "\n",
      "  [[ 1.76  0.72  1.    1.38  1.38  0.62]\n",
      "   [ 0.93  1.    0.85  1.26  0.29  0.14]\n",
      "   [ 0.91  0.29  0.85  1.2   0.46  1.28]\n",
      "   [ 1.39  1.18  1.7   1.17  1.49  0.53]]\n",
      "\n",
      "  [[ 0.33  0.79  1.04  0.39  0.9   0.59]\n",
      "   [ 1.26  0.73  1.12  1.3   0.49  1.05]\n",
      "   [ 1.45  0.85  1.03  1.23  0.64  0.91]\n",
      "   [ 1.14  0.87  0.98  0.32  1.09  0.41]]\n",
      "\n",
      "  [[ 0.41  1.09  0.32  0.98  0.87  1.14]\n",
      "   [ 0.91  0.64  1.23  1.03  0.85  1.45]\n",
      "   [ 1.05  0.49  1.3   1.12  0.73  1.26]\n",
      "   [ 0.59  0.9   0.39  1.04  0.79  0.33]]]\n",
      "\n",
      "\n",
      " [[[ 1.74  1.05  0.92  1.12  0.45  0.62]\n",
      "   [ 0.91  0.21  1.72  0.92  0.54  0.76]\n",
      "   [ 1.66  1.19  0.87  1.77  1.31  1.64]\n",
      "   [ 1.42  1.05  0.66  0.81  0.73  0.94]]\n",
      "\n",
      "  [[ 0.94  0.73  0.81  0.66  1.05  1.42]\n",
      "   [ 1.64  1.31  1.77  0.87  1.19  1.66]\n",
      "   [ 0.76  0.54  0.92  1.72  0.21  0.91]\n",
      "   [ 0.62  0.45  1.12  0.92  1.05  1.74]]\n",
      "\n",
      "  [[ 0.26  0.6   1.85  0.94  0.74  1.12]\n",
      "   [ 0.14  1.66  1.33  1.07  0.58  1.46]\n",
      "   [ 1.16  1.51  1.1   1.65  1.79  0.3 ]\n",
      "   [ 0.61  1.37  0.8   1.02  0.52  1.2 ]]\n",
      "\n",
      "  [[ 1.2   0.52  1.02  0.8   1.37  0.61]\n",
      "   [ 0.3   1.79  1.65  1.1   1.51  1.16]\n",
      "   [ 1.46  0.58  1.07  1.33  1.66  0.14]\n",
      "   [ 1.12  0.74  0.94  1.85  0.6   0.26]]]]\n"
     ]
    }
   ],
   "source": [
    "idxes = T.ivector(\"indices\")\n",
    "output_model = T.tensor4(\"output_model\")\n",
    "\n",
    "def sumWithNext(idx, output_model):\n",
    "    sub1 = output_model[:,idx,:,:]\n",
    "    sub2 = output_model[:,idx+1,:,:]\n",
    "    added = sub1 + sub2\n",
    "    out1 = T.set_subtensor(sub1, added)\n",
    "    return out1\n",
    "\n",
    "\n",
    "result, updates = theano.scan(fn=sumWithNext,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "sumItUp = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "def setToReverseComplement(idx, output_model):\n",
    "    sub1 = output_model[:,idx,:,:]\n",
    "    revCom = output_model[:,idx-1,:,:]\n",
    "    revCom = revCom[:,::-1,::-1]\n",
    "    return T.set_subtensor(sub1, revCom)\n",
    "\n",
    "result, updates = theano.scan(fn=setToReverseComplement,\n",
    "                              outputs_info=output_model,\n",
    "                              sequences=[idxes])\n",
    "\n",
    "revertIt = theano.function(inputs=[idxes, output_model], outputs=result)\n",
    "\n",
    "# test\n",
    "test_locations = np.asarray([0, 2], dtype=np.int32)\n",
    "test_output_model = np.random.rand(2, 4, 4, 6).astype(np.float32)\n",
    "x = sumItUp(test_locations, test_output_model)[-1]\n",
    "#print x\n",
    "res = revertIt(test_locations + 1, x)[-1]\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 4, 4)\n",
      "[[[[ 0.84  0.71  0.38  0.18]\n",
      "   [ 0.04  0.27  0.87  0.47]\n",
      "   [ 0.97  0.06  0.35  0.58]\n",
      "   [ 0.15  0.07  0.76  0.89]]\n",
      "\n",
      "  [[ 0.03  0.53  0.12  0.43]\n",
      "   [ 0.96  0.21  0.36  0.68]\n",
      "   [ 0.46  0.72  0.11  0.27]\n",
      "   [ 0.72  0.17  0.42  0.52]]\n",
      "\n",
      "  [[ 0.55  0.71  0.26  0.88]\n",
      "   [ 0.53  0.37  0.83  0.81]\n",
      "   [ 0.28  0.48  0.07  0.32]\n",
      "   [ 0.28  0.77  0.79  0.08]]\n",
      "\n",
      "  [[ 0.05  0.43  0.16  0.47]\n",
      "   [ 0.04  0.92  0.54  0.07]\n",
      "   [ 0.21  0.82  0.91  0.07]\n",
      "   [ 0.41  0.62  0.19  0.88]]]]\n",
      "[0 2]\n",
      "[1 3]\n",
      "RESULT\n",
      "[[[[ 0.87  1.24  0.5   0.61]\n",
      "   [ 1.    0.48  1.23  1.15]\n",
      "   [ 1.43  0.78  0.45  0.85]\n",
      "   [ 0.87  0.24  1.18  1.41]]\n",
      "\n",
      "  [[ 1.41  1.18  0.24  0.87]\n",
      "   [ 0.85  0.45  0.78  1.43]\n",
      "   [ 1.15  1.23  0.48  1.  ]\n",
      "   [ 0.61  0.5   1.24  0.87]]\n",
      "\n",
      "  [[ 0.6   1.14  0.42  1.35]\n",
      "   [ 0.57  1.29  1.38  0.89]\n",
      "   [ 0.49  1.3   0.99  0.39]\n",
      "   [ 0.69  1.39  0.97  0.96]]\n",
      "\n",
      "  [[ 0.96  0.97  1.39  0.69]\n",
      "   [ 0.39  0.99  1.3   0.49]\n",
      "   [ 0.89  1.38  1.29  0.57]\n",
      "   [ 1.35  0.42  1.14  0.6 ]]]]\n"
     ]
    }
   ],
   "source": [
    "test = CRBM(4, 2, 0.01, 1)\n",
    "#derivatives = np.tile(np.eye(4,4), [1,4,1,1])\n",
    "derivatives = np.random.rand(1,4,4,4)\n",
    "print derivatives.shape\n",
    "print derivatives\n",
    "k=2\n",
    "print np.arange(start=0, stop=2*k, step=2)\n",
    "print np.arange(start=1, stop=2*k, step=2)\n",
    "\n",
    "der = T.tensor4('derivatives')\n",
    "x = test.makeDerivativesStrandCompliant(der)\n",
    "f = theano.function([der], x, allow_input_downcast=True)\n",
    "result = f(derivatives)\n",
    "print \"RESULT\"\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "[1 3]\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "print np.arange(start=0, stop=2*k, step=2)\n",
    "print np.arange(start=1, stop=2*k, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will implement a naive implementation\n",
    "This is for debugging purposes only, to see if the GPU implementation is correct or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# the underlying convRBM implementation\n",
    "sys.path.append(os.path.abspath('../code'))\n",
    "#from convRBM import CRBM\n",
    "import getData as dataRead\n",
    "\n",
    "# biopython stuff\n",
    "#import Bio.SeqIO as sio\n",
    "#import Bio.motifs.matrix as mat\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "#from Bio import motifs\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveCRBM:\n",
    "\n",
    "    def __init__ (self, motifLength=1, numMotifs=1, learningRate=0.1, poolingFactor=1):\n",
    "        self.numberOfKernels = numMotifs\n",
    "        self.kernelLength = motifLength\n",
    "        self.poolingFactor = poolingFactor\n",
    "        self.learningRate = learningRate\n",
    "        self.setParamsToZero = True\n",
    "        self.debug = True\n",
    "        if self.setParamsToZero:\n",
    "            self.kernels = np.zeros((self.numberOfKernels, 1, 4, self.kernelLength))\n",
    "            self.bias = np.zeros(self.numberOfKernels)\n",
    "        else:\n",
    "            self.kernels = np.random.rand(self.numberOfKernels, 1, 4, self.kernelLength)\n",
    "            self.bias = np.random.rand(self.numberOfKernels)\n",
    "    \n",
    "    def setCustomKernels (self, kernels):\n",
    "        self.numberOfKernels = kernels.shape[0]\n",
    "        self.kernelLength = kernels.shape[3]\n",
    "        self.kernels = kernels\n",
    "        if self.setParamsToZero:\n",
    "            self.bias = np.zeros(self.numberOfKernels)\n",
    "        else:\n",
    "            self.bias = np.random.rand(self.numberOfKernels)\n",
    "\n",
    "    def initializeMotifs (self):\n",
    "        pass\n",
    "        \n",
    "    def complement (self, kernelSlice):\n",
    "        return kernelSlice[::-1]\n",
    "\n",
    "    def forwardBatch (self, data):\n",
    "        N_h = data.shape[3]-self.kernelLength+1\n",
    "        H = np.zeros((data.shape[0], self.numberOfKernels, 1, N_h))\n",
    "        for sample in range(data.shape[0]):\n",
    "            for k in range(self.numberOfKernels):\n",
    "                for n in range(N_h):\n",
    "                    for m in range(self.kernelLength):\n",
    "                        # calculate the x_i, that is the cross-correlation\n",
    "                        x = data[sample,0,:,n+m].T.dot(self.kernels[k,0,:,m]) + self.bias[k]\n",
    "                        #cKernel = self.complement(self.kernels[k,0,:,self.kernelLength-m-1])\n",
    "                        #x_prime = data[sample,0,:,n+m].T.dot(cKernel) + self.bias[k]\n",
    "                        H[sample, k, 0, n] += x # + x_prime      \n",
    "        print \"Pre Max Pooling H:\"\n",
    "        print H\n",
    "\n",
    "        # perform prob max pooling\n",
    "        P = np.zeros(H.shape)\n",
    "        S = np.zeros(H.shape)\n",
    "        H_exp = np.exp(H)\n",
    "        numBins = N_h / self.poolingFactor\n",
    "        #print \"Number Of Bins: \" + str(numBins)\n",
    "        for sample in range(data.shape[0]):\n",
    "            for k_pos in range(0, self.numberOfKernels, 2):\n",
    "                print \"K_pos: \" + str(k_pos)\n",
    "                for unit in range(numBins):\n",
    "                    #print \"Doing unit: \" + str(unit)\n",
    "                    # calculate sum within unit\n",
    "                    sumInUnit = 0\n",
    "                    for cell in range(self.poolingFactor):\n",
    "                        curPos = unit*self.poolingFactor+cell\n",
    "                        sumInUnit += H_exp[sample,k_pos,0,curPos] + H_exp[sample,k_pos+1,0,curPos]\n",
    "                        \n",
    "                    # now, calculate the single positions in P\n",
    "                    arr = []\n",
    "                    for cell in range(self.poolingFactor):\n",
    "                        curPos = unit*self.poolingFactor+cell\n",
    "                        P[sample,k_pos,0,curPos] = H_exp[sample,k_pos,0,curPos] / (sumInUnit + 1)\n",
    "                        P[sample,k_pos+1,0,curPos] = H_exp[sample,k_pos+1,0,curPos] / (sumInUnit + 1)\n",
    "                        arr.append(P[sample,k_pos,0,curPos])\n",
    "                        arr.append(P[sample,k_pos+1,0,curPos])\n",
    "                    \n",
    "                    # finally, do the sampling step\n",
    "                    arr.append(1 / (sumInUnit+1))\n",
    "                    s = np.random.multinomial(n=1, pvals=np.array(arr),size=1)\n",
    "                    am = np.argmax(s)\n",
    "                    #print \"Argmax: \" + str(am)\n",
    "                    if am < self.poolingFactor*2:\n",
    "                        strand = am % 2\n",
    "                        pos = unit * self.poolingFactor + (am // 2)\n",
    "                        #print \"Strand: \" + str(strand) + \" Pos: \" + str(pos)\n",
    "                        S[sample,k_pos+strand,0,pos] = 1\n",
    "                    else:\n",
    "                        print \"5th element chosen\"\n",
    "        return [P,S]\n",
    "\n",
    "\n",
    "    def backwardBatch (self, H):\n",
    "        \n",
    "        # calculate full convolution (not valid, therefore padding is applied with zeros)\n",
    "        N_v = H.shape[3] + self.kernelLength - 1\n",
    "        pad = self.kernelLength-1\n",
    "        V = np.zeros((H.shape[0],1,4,N_v))\n",
    "        Y = np.zeros(V.shape)\n",
    "        H_pad = np.pad(H,[(0,0),(0,0),(0,0),(pad, pad)], 'constant',constant_values=(0,0))\n",
    "        for sample in range(H.shape[0]):\n",
    "            for k in range(self.numberOfKernels):\n",
    "                for n in range(N_v):\n",
    "                    for m in range(self.kernelLength):\n",
    "                        Y[sample,0,:,n] += self.kernels[k,0,:,m] * H_pad[sample,k,0,pad+n-m]\n",
    "                        \n",
    "        # calculate softmax on convolved data\n",
    "        P_V = self.softmax(Y)\n",
    "        print P_V\n",
    "        \n",
    "        # sample the visible layer from that\n",
    "        for sample in range(H.shape[0]):\n",
    "            for col in range(P_V.shape[3]):\n",
    "                V[sample,0,:,col] = np.random.multinomial(n=1,pvals=P_V[sample,0,:,col],size=1)\n",
    "        return V\n",
    "        \n",
    "\n",
    "\n",
    "    def expectedDerivative (self, H, data):\n",
    "        G = np.zeros(self.kernels.shape)\n",
    "        for sample in range(data.shape[0]):\n",
    "            for k in range(self.numberOfKernels):\n",
    "                for n_h in range(H.shape[3]):\n",
    "                    for m in range(self.kernelLength):\n",
    "                        G[k,0,:,m] += data[sample,0,:,n_h+m] * H[sample,k,0,n_h]\n",
    "        return G\n",
    "    \n",
    "    def train_model (self, D, numOfCDs):\n",
    "        # calculate the data gradient for weights (motifs) and bias\n",
    "        [H_data, S_data] = self.forwardBatch(D)\n",
    "        if self.debug:\n",
    "            print H_data\n",
    "\n",
    "        # calculate data gradients\n",
    "        G_motif_data = self.expectedDerivative(H_data, D)\n",
    "\n",
    "        if self.debug:\n",
    "            print G_motif_data\n",
    "\n",
    "        # calculate model probs\n",
    "        S_H = S_data\n",
    "        for i in range(numOfCDs):\n",
    "            V_model = self.backwardBatch(S_H)\n",
    "            [H_model, S_H] = self.forwardBatch(V_model)\n",
    "        \n",
    "        # compute the model gradients\n",
    "        G_motif_model = self.expectedDerivative(H_model, D)\n",
    "        \n",
    "        if self.debug:\n",
    "            print G_motif_model\n",
    "        \n",
    "        # update the parameters\n",
    "        new_motifs = self.kernels + self.learningRate * (G_motif_data - G_motif_model)\n",
    "        self.kernels = new_motifs\n",
    "        \n",
    "    def trainMinibatch (self, trainData, epochs, batchSize, numOfCDs):\n",
    "        iterations = trainData.shape[0] / batchSize\n",
    "        for epoch in range(epochs):\n",
    "            for batchIdx in range(iterations):\n",
    "                self.train_model(trainData[batchIdx*batchSize:(batchIdx+1)*batchSize], numOfCDs)\n",
    "        \n",
    "    def softmax (self, x):\n",
    "        return np.exp(x) / np.exp(x).sum(axis=2, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: [[[[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]]]\n",
      "Data shape: (1, 1, 4, 8)\n",
      "[[[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  1.  0.  1.  1.  1.  1.]\n",
      "   [ 0.  0.  0.  1.  0.  0.  0.  0.]]]]\n",
      "Start forward...\n",
      "Pre Max Pooling H:\n",
      "[[[[ 3.  0.  1.  1.  1.  1.]]\n",
      "\n",
      "  [[ 0.  3.  0.  1.  1.  1.]]]]\n",
      "K_pos: 0\n",
      "Hidden Probs:\n",
      "[[[[ 0.47  0.02  0.27  0.27  0.23  0.23]]\n",
      "\n",
      "  [[ 0.02  0.47  0.1   0.27  0.23  0.23]]]]\n",
      "Hidden Sample:\n",
      "[[[[ 1.  0.  0.  1.  1.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.  0.  0.]]]]\n",
      "Start backward...\n",
      "[[[[ 0.48  0.17  0.17  0.48  0.37  0.13  0.17  0.25]\n",
      "   [ 0.17  0.48  0.17  0.17  0.37  0.37  0.17  0.25]\n",
      "   [ 0.17  0.17  0.48  0.17  0.13  0.37  0.48  0.25]\n",
      "   [ 0.17  0.17  0.17  0.17  0.13  0.13  0.17  0.25]]]]\n",
      "Start gradient calc...\n",
      "Pre Max Pooling H:\n",
      "[[[[ 3.  0.  1.  1.  1.  1.]]\n",
      "\n",
      "  [[ 0.  3.  0.  1.  1.  1.]]]]\n",
      "K_pos: 0\n",
      "[[[[ 0.25  0.17  0.37  0.13  0.17  0.48  0.17  0.17]\n",
      "   [ 0.25  0.48  0.13  0.37  0.17  0.17  0.48  0.17]\n",
      "   [ 0.25  0.17  0.37  0.13  0.48  0.17  0.17  0.48]\n",
      "   [ 0.25  0.17  0.13  0.37  0.17  0.17  0.17  0.17]]]]\n",
      "Pre Max Pooling H:\n",
      "[[[[ 1.  2.  0.  2.  0.  2.]]\n",
      "\n",
      "  [[ 1.  1.  2.  0.  2.  0.]]]]\n",
      "K_pos: 0\n",
      "5th element chosen\n",
      "Pre Max Pooling H:\n",
      "[[[[ 3.1  -0.14  1.08  0.96  1.    1.  ]]\n",
      "\n",
      "  [[-0.05  3.11 -0.09  1.04  0.99  0.99]]]]\n",
      "K_pos: 0\n",
      "[[[[ 0.25  0.17  0.17  0.37  0.17  0.13  0.17  0.17]\n",
      "   [ 0.25  0.48  0.17  0.13  0.49  0.37  0.17  0.17]\n",
      "   [ 0.25  0.17  0.49  0.13  0.16  0.36  0.49  0.17]\n",
      "   [ 0.25  0.18  0.17  0.37  0.18  0.13  0.17  0.49]]]]\n",
      "Pre Max Pooling H:\n",
      "[[[[ 2.05 -0.14  1.08  0.96  1.    1.  ]]\n",
      "\n",
      "  [[-0.02  3.11 -0.09  1.04  0.99  0.99]]]]\n",
      "K_pos: 0\n",
      "Finished Training:\n",
      "[[[[ 1.05  0.    0.  ]\n",
      "   [-0.04  1.05  0.  ]\n",
      "   [ 0.02 -0.06  1.06]\n",
      "   [-0.01  0.02 -0.04]]]\n",
      "\n",
      "\n",
      " [[[-0.02  0.    0.  ]\n",
      "   [ 1.01 -0.02  0.  ]\n",
      "   [-0.03  1.03 -0.03]\n",
      "   [ 0.02 -0.03  1.01]]]]\n"
     ]
    }
   ],
   "source": [
    "#initialize the learner and set custom kernels\n",
    "naiveModel = NaiveCRBM(motifLength=3, numMotifs=4, learningRate=0.1, poolingFactor=2)\n",
    "\n",
    "# design data\n",
    "#print \"Motifs:\"\n",
    "#print x.motifs.get_value()\n",
    "kernel1 = np.tile(np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,0]]), [1,1,1])\n",
    "kernel1_ = np.tile(np.flipud(np.fliplr(kernel1[0])),[1,1,1])\n",
    "kernel2 = np.tile(np.array([[0,0,0],[0,0,0],[1,1,1],[0,0,0]]), [1,1,1])\n",
    "kernel2_ = np.tile(np.flipud(np.fliplr(kernel2[0])), [1,1,1])\n",
    "kernel3 = np.random.rand(1,4,3)\n",
    "kernel3_ = np.tile(np.flipud(np.fliplr(kernel3[0])), [1,1,1])\n",
    "kernel = np.array([kernel1, kernel1_])#, kernel2, kernel2_])#, kernel3, kernel3_])\n",
    "#kernel = np.array([kernel3, kernel3_])\n",
    "print \"Kernel: \" + str(kernel)\n",
    "\n",
    "# initialize the data\n",
    "randSeq1 = dataRead.getOneHotMatrixFromSeq(Seq(\"ACGTGGGG\", IUPAC.unambiguous_dna))\n",
    "randSeq2 = dataRead.getOneHotMatrixFromSeq(Seq(\"ACGTACGT\", IUPAC.unambiguous_dna))\n",
    "data = np.array([randSeq1], dtype=np.float32)\n",
    "print \"Data shape: \" + str(data.shape)\n",
    "print data\n",
    "\n",
    "# perform forward pass\n",
    "naiveModel.setCustomKernels(kernel)\n",
    "print \"Start forward...\"\n",
    "[P,S] = naiveModel.forwardBatch(data)\n",
    "print \"Hidden Probs:\"\n",
    "print P\n",
    "print \"Hidden Sample:\"\n",
    "print S\n",
    "print \"Start backward...\"\n",
    "V = naiveModel.backwardBatch(S)\n",
    "print \"Start gradient calc...\"\n",
    "naiveModel.expectedDerivative(P, data)\n",
    "\n",
    "naiveModel.debug = False\n",
    "naiveModel.trainMinibatch(data, 2, 1, 1)\n",
    "print \"Finished Training:\"\n",
    "print naiveModel.kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 1, 6)\n",
      "[[[[ 0.  0.  1.  1.  1.  1.  1.  1.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  1.  1.  1.  1.  1.  1.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "test = np.ones((2,1,1,6))\n",
    "print test.shape\n",
    "print np.pad(test,[(0,0),(0,0),(0,0),(2,2)],'constant', constant_values=(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
